[
  {
    "content": "# F\n\n## Page 1\n\nSpeech and Language Processing. Daniel Jurafsky & James H. Martin. Copyright \u00a92024. All\nrights reserved. Draft of January 12, 2025.\nCHAPTER\nFLogical Representations of\nSentence Meaning\nISHMAEL :Surely all this is not without meaning.\nHerman Melville, Moby Dick\nIn this chapter we introduce the idea that the meaning of linguistic expressions can\nbe captured in formal structures called meaning representations . Consider tasksmeaning\nrepresentations\nthat require some form of semantic processing, like learning to use a new piece of\nsoftware by reading the manual, deciding what to order at a restaurant by reading\na menu, or following a recipe. Accomplishing these tasks requires representations\nthat link the linguistic elements to the necessary non-linguistic knowledge of the\nworld . Reading a menu and deciding what to order, giving advice about where to\ngo to dinner, following a recipe, and generating new recipes all require knowledge\nabout food and its preparation, what people like to eat, and what restaurants are like.\nLearning to use a piece of software by reading a manual, or giving advice on using\nsoftware, requires knowledge about the software and similar apps, computers, and\nusers in general.\nIn this chapter, we assume that linguistic expressions have meaning representa-\ntions that are made up of the same kind of stuff that is used to represent this kind of\neveryday common-sense knowledge of the world. The process whereby such repre-\nsentations are created and assigned to linguistic inputs is called semantic parsing orsemantic\nparsing\nsemantic analysis , and the entire enterprise of designing meaning representations\nand associated semantic parsers is referred to as computational semantics .computational\nsemantics\n9e;y Having (e)^Haver (e;Speaker )^HadT hing (e;y)^Car(y)\nh / have-01c / cari / i arg0arg1(h / have-01        arg0: (i / i)        arg1: (c / car))Having:      Haver:  Speaker      HadThing:  Car\nFigure F.1 A list of symbols, two directed graphs, and a record structure: a sampler of\nmeaning representations for I have a car.\nConsider Fig. F.1, which shows example meaning representations for the sen-\ntence I have a car using four commonly used meaning representation languages.\nThe top row illustrates a sentence in First-Order Logic , covered in detail in Sec-\ntion F.3; the directed graph and its corresponding textual form is an example of an\nAbstract Meaning Representation (AMR) form (Banarescu et al., 2013), and on\nthe right is a frame-based orslot-\ufb01ller representation, discussed in Section F.5 and\nagain in Chapter 20.",
    "metadata": {
      "source": "F",
      "chunk_id": 0,
      "token_count": 587,
      "chapter_title": "F"
    }
  },
  {
    "content": "## Page 2\n\n2APPENDIX F \u2022 L OGICAL REPRESENTATIONS OF SENTENCE MEANING\nWhile there are non-trivial differences among these approaches, they all share\nthe notion that a meaning representation consists of structures composed from a\nset of symbols, or representational vocabulary. When appropriately arranged, these\nsymbol structures are taken to correspond to objects, properties of objects, and rela-\ntions among objects in some state of affairs being represented or reasoned about. In\nthis case, all four representations make use of symbols corresponding to the speaker,\na car, and a relation denoting the possession of one by the other.\nImportantly, these representations can be viewed from at least two distinct per-\nspectives in all of these approaches: as representations of the meaning of the par-\nticular linguistic input I have a car , and as representations of the state of affairs in\nsome world. It is this dual perspective that allows these representations to be used\nto link linguistic inputs to the world and to our knowledge of it.\nIn the next sections we give some background: our desiderata for a meaning\nrepresentation language and some guarantees that these representations will actually\ndo what we need them to do\u2014provide a correspondence to the state of affairs being\nrepresented. In Section F.3 we introduce First-Order Logic, historically the primary\ntechnique for investigating natural language semantics, and see in Section F.4 how\nit can be used to capture the semantics of events and states in English.\nF.1 Computational Desiderata for Representations\nLet\u2019s consider why meaning representations are needed and what they should do for\nus. To focus this discussion, let\u2019s consider a system that gives restaurant advice to\ntourists based on a knowledge base.\nVeri\ufb01ability\nConsider the following simple question:\n(F.1) Does Maharani serve vegetarian food?\nTo answer this question, we have to know what it\u2019s asking, and know whether what\nit\u2019s asking is true of Maharini or not. Veri\ufb01ability is a system\u2019s ability to compare veri\ufb01ability\nthe state of affairs described by a representation to the state of affairs in some world\nas modeled in a knowledge base. For example, we\u2019ll need some sort of representa-\ntion like Serves (Maharani ;VegetarianFood ), which a system can match against its\nknowledge base of facts about particular restaurants, and if it \ufb01nds a representation\nmatching this proposition, it can answer yes. Otherwise, it must either say Noif its\nknowledge of local restaurants is complete, or say that it doesn\u2019t know if it knows\nits knowledge is incomplete.\nUnambiguous Representations\nSemantics, like all the other domains we have studied, is subject to ambiguity. Words\nand sentences have different meaning representations in different contexts. Consider\nthe following example:\n(F.2) I wanna eat someplace that\u2019s close to ICSI.\nThis sentence can either mean that the speaker wants to eat atsome nearby location,\nor under a Godzilla-as-speaker interpretation, the speaker may want to devour some\nnearby location. The sentence is ambiguous; a single linguistic expression can have\none of two meanings. But our meaning representations itself cannot be ambiguous.",
    "metadata": {
      "source": "F",
      "chunk_id": 1,
      "token_count": 666,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 3\n\nF.1 \u2022 C OMPUTATIONAL DESIDERATA FOR REPRESENTATIONS 3\nThe representation of an input\u2019s meaning should be free from any ambiguity, so that\nthe system can reason over a representation that means either one thing or the other\nin order to decide how to answer.\nA concept closely related to ambiguity is vagueness : in which a meaning repre- vagueness\nsentation leaves some parts of the meaning underspeci\ufb01ed. Vagueness does not give\nrise to multiple representations. Consider the following request:\n(F.3) I want to eat Italian food.\nWhile Italian food may provide enough information to provide recommendations, it\nis nevertheless vague as to what the user really wants to eat. A vague representation\nof the meaning of this phrase may be appropriate for some purposes, while a more\nspeci\ufb01c representation may be needed for other purposes.\nCanonical Form\nThe doctrine of canonical form says that distinct inputs that mean the same thing canonical form\nshould have the same meaning representation. This approach greatly simpli\ufb01es rea-\nsoning, since systems need only deal with a single meaning representation for a\npotentially wide range of expressions.\nConsider the following alternative ways of expressing (F.1):\n(F.4) Does Maharani have vegetarian dishes?\n(F.5) Do they have vegetarian food at Maharani?\n(F.6) Are vegetarian dishes served at Maharani?\n(F.7) Does Maharani serve vegetarian fare?\nDespite the fact these alternatives use different words and syntax, we want them\nto map to a single canonical meaning representations. If they were all different,\nassuming the system\u2019s knowledge base contains only a single representation of this\nfact, most of the representations wouldn\u2019t match. We could, of course, store all\npossible alternative representations of the same fact in the knowledge base, but doing\nso would lead to enormous dif\ufb01culty in keeping the knowledge base consistent.\nCanonical form does complicate the task of semantic parsing. Our system must\nconclude that vegetarian fare ,vegetarian dishes , and vegetarian food refer to the\nsame thing, that having andserving are equivalent here, and that all these parse\nstructures still lead to the same meaning representation. Or consider this pair of\nexamples:\n(F.8) Maharani serves vegetarian dishes.\n(F.9) Vegetarian dishes are served by Maharani.\nDespite the different placement of the arguments to serve , a system must still assign\nMaharani andvegetarian dishes to the same roles in the two examples by draw-\ning on grammatical knowledge, such as the relationship between active and passive\nsentence constructions.\nInference and Variables\nWhat about more complex requests such as:\n(F.10) Can vegetarians eat at Maharani?\nThis request results in the same answer as the others not because they mean the same\nthing, but because there is a common-sense connection between what vegetarians eat\nand what vegetarian restaurants serve. This is a fact about the world. We\u2019ll need to\nconnect the meaning representation of this request with this fact about the world in a",
    "metadata": {
      "source": "F",
      "chunk_id": 2,
      "token_count": 640,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 4\n\n4APPENDIX F \u2022 L OGICAL REPRESENTATIONS OF SENTENCE MEANING\nknowledge base. A system must be able to use inference \u2014to draw valid conclusions inference\nbased on the meaning representation of inputs and its background knowledge. It\nmust be possible for the system to draw conclusions about the truth of propositions\nthat are not explicitly represented in the knowledge base but that are nevertheless\nlogically derivable from the propositions that are present.\nNow consider the following somewhat more complex request:\n(F.11) I\u2019d like to \ufb01nd a restaurant where I can get vegetarian food.\nThis request does not make reference to any particular restaurant; the user wants in-\nformation about an unknown restaurant that serves vegetarian food. Since no restau-\nrants are named, simple matching is not going to work. Answering this request\nrequires the use of variables , using some representation like the following: variables\nServes (x;VegetarianFood ) (F.12)\nMatching succeeds only if the variable xcan be replaced by some object in the\nknowledge base in such a way that the entire proposition will then match. The con-\ncept that is substituted for the variable can then be used to ful\ufb01ll the user\u2019s request.\nIt is critical for any meaning representation language to be able to handle these kinds\nof inde\ufb01nite references.\nExpressiveness\nFinally, a meaning representation scheme must be expressive enough to handle a\nwide range of subject matter, ideally any sensible natural language utterance. Al-\nthough this is probably too much to expect from any single representational system,\nFirst-Order Logic, as described in Section F.3, is expressive enough to handle quite\na lot of what needs to be represented.\nF.2 Model-Theoretic Semantics\nWhat is it about meaning representation languages that allows them to ful\ufb01ll these\ndesiderata, bridging the gap from formal representations to representations that tell\nus something about some state of affairs in the world?\nThe answer is a model . A model is a formal construct that stands for the partic- model\nular state of affairs in the world. Expressions in a meaning representation language\ncan be mapped to elements of the model, like objects, properties of objects, and\nrelations among objects. If the model accurately captures the facts we\u2019re interested\nin, then a consistent mapping between the meaning representation and the model\nprovides the bridge between meaning representation and world. Models provide a\nsurprisingly simple and powerful way to ground the expressions in meaning repre-\nsentation languages.\nFirst, some terminology. The vocabulary of a meaning representation consists of\ntwo parts: the non-logical vocabulary and the logical vocabulary. The non-logical\nvocabulary consists of the open-ended set of names for the objects, properties, andnon-logical\nvocabulary\nrelations that make up the world we\u2019re trying to represent. These appear in various\nschemes as predicates, nodes, labels on links, or labels in slots in frames. The log-\nical vocabulary consists of the closed set of symbols, operators, quanti\ufb01ers, links,logical\nvocabulary\netc., that provide the formal means for composing expressions in a given meaning\nrepresentation language.",
    "metadata": {
      "source": "F",
      "chunk_id": 3,
      "token_count": 664,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 5",
    "metadata": {
      "source": "F",
      "chunk_id": 4,
      "token_count": 4,
      "chapter_title": ""
    }
  },
  {
    "content": "F.2 \u2022 M ODEL -THEORETIC SEMANTICS 5\nEach element of the non-logical vocabulary must have a denotation in the model, denotation\nmeaning that every element corresponds to a \ufb01xed, well-de\ufb01ned part of the model.\nLet\u2019s start with objects. The domain of a model is the set of objects that are being domain\nrepresented. Each distinct concept, category, or individual denotes a unique element\nin the domain.\nWe represent properties of objects in a model by denoting the domain elements\nthat have the property; that is, properties denote sets. The denotation of the property\nredis the set of things we think are red. Similarly, a relation among object denotes\na set of ordered lists, or tuples, of domain elements that take part in the relation: the\ndenotation of the relation Married is set of pairs of domain objects that are married.\nThis approach to properties and relations is called extensional , because we de\ufb01ne extensional\nconcepts by their extension, their denotations. To summarize:\n\u2022 Objects denote elements of the domain\n\u2022 Properties denote sets of elements of the domain\n\u2022 Relations denote sets of tuples of elements of the domain\nWe now need a mapping that gets us from our meaning representation to the\ncorresponding denotations: a function that maps from the non-logical vocabulary of\nour meaning representation to the proper denotations in the model. We\u2019ll call such\na mapping an interpretation . interpretation\nLet\u2019s return to our restaurant advice application, and let its domain consist of\nsets of restaurants, patrons, facts about the likes and dislikes of the patrons, and\nfacts about the restaurants such as their cuisine, typical cost, and noise level. To\nbegin populating our domain, D, let\u2019s assume that we\u2019re dealing with four patrons\ndesignated by the non-logical symbols Matthew, Franco, Katie , and Caroline . de-\nnoting four unique domain elements. We\u2019ll use the constants a;b;cand, dto stand\nfor these domain elements. We\u2019re deliberately using meaningless, non-mnemonic\nnames for our domain elements to emphasize the fact that whatever it is that we\nknow about these entities has to come from the formal properties of the model and\nnot from the names of the symbols. Continuing, let\u2019s assume that our application\nincludes three restaurants, designated as Frasca ,Med, and Rioin our meaning rep-\nresentation, that denote the domain elements e;f, and g. Finally, let\u2019s assume that\nwe\u2019re dealing with the three cuisines Italian ,Mexican , and Eclectic , denoted by h;i,\nandjin our model.\nProperties like Noisy denote the subset of restaurants from our domain that are\nknown to be noisy. Two-place relational notions, such as which restaurants individ-\nual patrons Like, denote ordered pairs, or tuples, of the objects from the domain.\nAnd, since we decided to represent cuisines as objects in our model, we can cap-\nture which restaurants Serve which cuisines as a set of tuples. One possible state of\naffairs using this scheme is given in Fig. F.2.\nGiven this simple scheme, we can ground our meaning representations by con-\nsulting the appropriate denotations in the corresponding model. For example, we can\nevaluate a representation claiming that Matthew likes the Rio , or that The Med serves\nItalian by mapping the objects in the meaning representations to their corresponding\ndomain elements and mapping any links, predicates, or slots in the meaning repre-\nsentation to the appropriate relations in the model. More concretely, we can verify\na representation asserting that Matthew likes Frasca by \ufb01rst using our interpretation",
    "metadata": {
      "source": "F",
      "chunk_id": 5,
      "token_count": 766,
      "chapter_title": ""
    }
  },
  {
    "content": "includes three restaurants, designated as Frasca ,Med, and Rioin our meaning rep-\nresentation, that denote the domain elements e;f, and g. Finally, let\u2019s assume that\nwe\u2019re dealing with the three cuisines Italian ,Mexican , and Eclectic , denoted by h;i,\nandjin our model.\nProperties like Noisy denote the subset of restaurants from our domain that are\nknown to be noisy. Two-place relational notions, such as which restaurants individ-\nual patrons Like, denote ordered pairs, or tuples, of the objects from the domain.\nAnd, since we decided to represent cuisines as objects in our model, we can cap-\nture which restaurants Serve which cuisines as a set of tuples. One possible state of\naffairs using this scheme is given in Fig. F.2.\nGiven this simple scheme, we can ground our meaning representations by con-\nsulting the appropriate denotations in the corresponding model. For example, we can\nevaluate a representation claiming that Matthew likes the Rio , or that The Med serves\nItalian by mapping the objects in the meaning representations to their corresponding\ndomain elements and mapping any links, predicates, or slots in the meaning repre-\nsentation to the appropriate relations in the model. More concretely, we can verify\na representation asserting that Matthew likes Frasca by \ufb01rst using our interpretation\nfunction to map the symbol Matthew to its denotation a,Frasca toe, and the Likes\nrelation to the appropriate set of tuples. We then check that set of tuples for the\npresence of the tuple ha;ei. If, as it is in this case, the tuple is present in the model,\nthen we can conclude that Matthew likes Frasca is true; if it isn\u2019t then we can\u2019t.",
    "metadata": {
      "source": "F",
      "chunk_id": 6,
      "token_count": 365,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 6\n\n6APPENDIX F \u2022 L OGICAL REPRESENTATIONS OF SENTENCE MEANING\nDomain D=fa;b;c;d;e;f;g;h;i;jg\nMatthew, Franco, Katie and Caroline a;b;c;d\nFrasca, Med, Rio e;f;g\nItalian, Mexican, Eclectic h;i;j\nProperties\nNoisy Noisy =fe;f;gg\nFrasca, Med, and Rio are noisy\nRelations\nLikes Likes =fha;fi;hc;fi;hc;gi;hb;ei;hd;fi;hd;gig\nMatthew likes the Med\nKatie likes the Med and Rio\nFranco likes Frasca\nCaroline likes the Med and Rio\nServes Serves =fhf;ji;hg;ii;he;hig\nMed serves eclectic\nRio serves Mexican\nFrasca serves Italian\nFigure F.2 A model of the restaurant world.\nThis is all pretty straightforward\u2014we\u2019re using sets and operations on sets to\nground the expressions in our meaning representations. Of course, the more inter-\nesting part comes when we consider more complex examples such as the following:\n(F.13) Katie likes the Rio and Matthew likes the Med.\n(F.14) Katie and Caroline like the same restaurants.\n(F.15) Franco likes noisy, expensive restaurants.\n(F.16) Not everybody likes Frasca.\nOur simple scheme for grounding the meaning of representations is not adequate\nfor examples such as these. Plausible meaning representations for these examples\nwill not map directly to individual entities, properties, or relations. Instead, they\ninvolve complications such as conjunctions, equality, quanti\ufb01ed variables, and nega-\ntions. To assess whether these statements are consistent with our model, we\u2019ll have\nto tear them apart, assess the parts, and then determine the meaning of the whole\nfrom the meaning of the parts.\nConsider the \ufb01rst example above. A meaning representation for this example\nwill include two distinct propositions expressing the individual patron\u2019s preferences,\nconjoined with some kind of implicit or explicit conjunction operator. Our model\ndoesn\u2019t have a relation that encodes pairwise preferences for all of the patrons and\nrestaurants in our model, nor does it need to. We know from our model that Matthew\nlikes the Med and separately that Katie likes the Rio (that is, the tuples ha;fiand\nhc;giare members of the set denoted by the Likes relation). All we really need to\nknow is how to deal with the semantics of the conjunction operator. If we assume\nthe simplest possible semantics for the English word and, the whole statement is\ntrue if it is the case that each of the components is true in our model. In this case,\nboth components are true since the appropriate tuples are present and therefore the\nsentence as a whole is true.\nWhat we\u2019ve done with this example is provide a truth-conditional semanticstruth-\nconditional\nsemanticsfor the assumed conjunction operator in some meaning representation. That is,\nwe\u2019ve provided a method for determining the truth of a complex expression from",
    "metadata": {
      "source": "F",
      "chunk_id": 7,
      "token_count": 644,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 7\n\nF.3 \u2022 F IRST-ORDER LOGIC 7\nFormula!AtomicFormula\njFormula Connective Formula\njQuanti\ufb01er Variable ; : : :Formula\nj : Formula\nj(Formula )\nAtomicFormula!Predicate (Term ; : : :)\nTerm!Function (Term ; : : :)\njConstant\njVariable\nConnective! ^j_j =)\nQuanti\ufb01er! 8j9\nConstant!AjVegetarianFoodjMaharani\u0001\u0001\u0001\nVariable!xjyj\u0001\u0001\u0001\nPredicate!ServesjNearj\u0001\u0001\u0001\nFunction!LocationOfjCuisineOfj\u0001\u0001\u0001\nFigure F.3 A context-free grammar speci\ufb01cation of the syntax of First-Order Logic repre-\nsentations. Adapted from Russell and Norvig 2002.\nthe meanings of the parts (by consulting a model) and the meaning of an operator by\nconsulting a truth table. Meaning representation languages are truth-conditional to\nthe extent that they give a formal speci\ufb01cation as to how we can determine the mean-\ning of complex sentences from the meaning of their parts. In particular, we need to\nknow the semantics of the entire logical vocabulary of the meaning representation\nscheme being used.\nNote that although the details of how this happens depend on details of the par-\nticular meaning representation being used, it should be clear that assessing the truth\nconditions of examples like these involves nothing beyond the simple set operations\nwe\u2019ve been discussing. We return to these issues in the next section in the context of\nthe semantics of First-Order Logic.\nF.3 First-Order Logic\nFirst-Order Logic ( FOL) is a \ufb02exible, well-understood, and computationally tractable\nmeaning representation language that satis\ufb01es many of the desiderata given in Sec-\ntion F.1. It provides a sound computational basis for the veri\ufb01ability, inference, and\nexpressiveness requirements, as well as a sound model-theoretic semantics.\nAn additional attractive feature of FOLis that it makes few speci\ufb01c commitments\nas to how things ought to be represented, and those it does are shared by many of\nthe schemes mentioned earlier: the represented world consists of objects, properties\nof objects, and relations among objects.\nThe remainder of this section introduces the basic syntax and semantics of FOL\nand then describes the application of FOL to the representation of events.\nF.3.1 Basic Elements of First-Order Logic\nLet\u2019s explore FOL by \ufb01rst examining its various atomic elements and then showing\nhow they can be composed to create larger meaning representations. Figure F.3,\nwhich provides a complete context-free grammar for the particular syntax of FOL\nthat we will use, is our roadmap for this section.",
    "metadata": {
      "source": "F",
      "chunk_id": 8,
      "token_count": 598,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 8\n\n8APPENDIX F \u2022 L OGICAL REPRESENTATIONS OF SENTENCE MEANING\nLet\u2019s begin by examining the notion of a term , the FOL device for representing term\nobjects. As can be seen from Fig. F.3, FOL provides three ways to represent these\nbasic building blocks: constants, functions, and variables. Each of these devices can\nbe thought of as designating an object in the world under consideration.\nConstants inFOL refer to speci\ufb01c objects in the world being described. Such constant\nconstants are conventionally depicted as either single capitalized letters such as A\nandBor single capitalized words that are often reminiscent of proper nouns such as\nMaharani andHarry . Like programming language constants, FOL constants refer\nto exactly one object. Objects can, however, have multiple constants that refer to\nthem.\nFunctions inFOL correspond to concepts that are often expressed in English as function\ngenitives such as Frasca\u2019s location . A FOL translation of such an expression might\nlook like the following.\nLocationOf (Frasca ) (F.17)\nFOL functions are syntactically the same as single argument predicates. It is im-\nportant to remember, however, that while they have the appearance of predicates,\nthey are in fact terms in that they refer to unique objects. Functions provide a con-\nvenient way to refer to speci\ufb01c objects without having to associate a named constant\nwith them. This is particularly convenient in cases in which many named objects,\nlike restaurants, have a unique concept such as a location associated with them.\nVariables are our \ufb01nal FOL mechanism for referring to objects. Variables, de- variable\npicted as single lower-case letters, let us make assertions and draw inferences about\nobjects without having to make reference to any particular named object. This ability\nto make statements about anonymous objects comes in two \ufb02avors: making state-\nments about a particular unknown object and making statements about all the objects\nin some arbitrary world of objects. We return to the topic of variables after we have\npresented quanti\ufb01ers, the elements of FOL that make variables useful.\nNow that we have the means to refer to objects, we can move on to the FOL\nmechanisms that are used to state relations that hold among objects. Predicates are\nsymbols that refer to, or name, the relations that hold among some \ufb01xed number\nof objects in a given domain. Returning to the example introduced informally in\nSection F.1, a reasonable FOL representation for Maharani serves vegetarian food\nmight look like the following formula:\nServes (Maharani ;VegetarianFood ) (F.18)\nThis FOL sentence asserts that Serves , a two-place predicate, holds between the\nobjects denoted by the constants Maharani andVegetarianFood .\nA somewhat different use of predicates is illustrated by the following fairly typ-\nical representation for a sentence like Maharani is a restaurant :\nRestaurant (Maharani ) (F.19)\nThis is an example of a one-place predicate that is used, not to relate multiple objects,\nbut rather to assert a property of a single object. In this case, it encodes the category\nmembership of Maharani .\nWith the ability to refer to objects, to assert facts about objects, and to relate\nobjects to one another, we can create rudimentary composite representations. These\nrepresentations correspond to the atomic formula level in Fig. F.3. This ability to\ncompose complex representations is, however, not limited to the use of single pred-\nicates. Larger composite representations can also be put together through the use of",
    "metadata": {
      "source": "F",
      "chunk_id": 9,
      "token_count": 764,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 9\n\nF.3 \u2022 F IRST-ORDER LOGIC 9\nlogical connectives . As can be seen from Fig. F.3, logical connectives let us createlogical\nconnectives\nlarger representations by conjoining logical formulas using one of three operators.\nConsider, for example, the following BERP sentence and one possible representation\nfor it:\n(F.20) I only have \ufb01ve dollars and I don\u2019t have a lot of time.\nHave (Speaker ;FiveDollars )^:Have (Speaker ;LotOfTime ) (F.21)\nThe semantic representation for this example is built up in a straightforward way\nfrom the semantics of the individual clauses through the use of the ^and:operators.\nNote that the recursive nature of the grammar in Fig. F.3 allows an in\ufb01nite number\nof logical formulas to be created through the use of these connectives. Thus, as with\nsyntax, we can use a \ufb01nite device to create an in\ufb01nite number of representations.\nF.3.2 Variables and Quanti\ufb01ers\nWe now have all the machinery necessary to return to our earlier discussion of vari-\nables. As noted above, variables are used in two ways in FOL: to refer to particular\nanonymous objects and to refer generically to all objects in a collection. These two\nuses are made possible through the use of operators known as quanti\ufb01ers . The two quanti\ufb01ers\noperators that are basic to FOL are the existential quanti\ufb01er, which is denoted 9and\nis pronounced as \u201cthere exists\u201d, and the universal quanti\ufb01er, which is denoted 8and\nis pronounced as \u201cfor all\u201d.\nThe need for an existentially quanti\ufb01ed variable is often signaled by the presence\nof an inde\ufb01nite noun phrase in English. Consider the following example:\n(F.22) a restaurant that serves Mexican food near ICSI.\nHere, reference is being made to an anonymous object of a speci\ufb01ed category with\nparticular properties. The following would be a reasonable representation of the\nmeaning of such a phrase:\n9xRestaurant (x)^Serves (x;MexicanFood ) (F.23)\n^Near (LocationOf (x);LocationOf (ICSI ))\nThe existential quanti\ufb01er at the head of this sentence instructs us on how to\ninterpret the variable xin the context of this sentence. Informally, it says that for\nthis sentence to be true there must be at least one object such that if we were to\nsubstitute it for the variable x, the resulting sentence would be true. For example,\nifAyCaramba is a Mexican restaurant near ICSI, then substituting AyCaramba forx\nresults in the following logical formula:\nRestaurant (AyCaramba )^Serves (AyCaramba ;MexicanFood ) (F.24)\n^Near ((LocationOf (AyCaramba );LocationOf (ICSI ))\nBased on the semantics of the ^operator, this sentence will be true if all of its\nthree component atomic formulas are true. These in turn will be true if they are\neither present in the system\u2019s knowledge base or can be inferred from other facts in\nthe knowledge base.\nThe use of the universal quanti\ufb01er also has an interpretation based on substi-\ntution of known objects for variables. The substitution semantics for the universal\nquanti\ufb01er takes the expression for all quite literally; the8operator states that for the\nlogical formula in question to be true, the substitution of anyobject in the knowledge",
    "metadata": {
      "source": "F",
      "chunk_id": 10,
      "token_count": 763,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 10\n\n10 APPENDIX F \u2022 L OGICAL REPRESENTATIONS OF SENTENCE MEANING\nbase for the universally quanti\ufb01ed variable should result in a true formula. This is in\nmarked contrast to the 9operator, which only insists on a single valid substitution\nfor the sentence to be true.\nConsider the following example:\n(F.25) All vegetarian restaurants serve vegetarian food.\nA reasonable representation for this sentence would be something like the following:\n8xVegetarianRestaurant (x) =)Serves (x;VegetarianFood ) (F.26)\nFor this sentence to be true, every substitution of a known object for xmust result in a\nsentence that is true. We can divide the set of all possible substitutions into the set of\nobjects consisting of vegetarian restaurants and the set consisting of everything else.\nLet us \ufb01rst consider the case in which the substituted object actually is a vegetarian\nrestaurant; one such substitution would result in the following sentence:\nVegetarianRestaurant (Maharani ) =)Serves (Maharani ;VegetarianFood )\n(F.27)\nIf we assume that we know that the consequent clause\nServes (Maharani ;VegetarianFood ) (F.28)\nis true, then this sentence as a whole must be true. Both the antecedent and the\nconsequent have the value True and, therefore, according to the \ufb01rst two rows of\nFig. F.4 on page 12 the sentence itself can have the value True . This result will be\nthe same for all possible substitutions of Terms representing vegetarian restaurants\nforx.\nRemember, however, that for this sentence to be true, it must be true for all\npossible substitutions. What happens when we consider a substitution from the set\nof objects that are not vegetarian restaurants? Consider the substitution of a non-\nvegetarian restaurant such as AyCaramba for the variable x:\nVegetarianRestaurant (AyCaramba ) =)Serves (AyCaramba ;VegetarianFood )\nSince the antecedent of the implication is False , we can determine from Fig. F.4\nthat the sentence is always True , again satisfying the 8constraint.\nNote that it may still be the case that AyCaramba serves vegetarian food with-\nout actually being a vegetarian restaurant. Note also that, despite our choice of\nexamples, there are no implied categorical restrictions on the objects that can be\nsubstituted for xby this kind of reasoning. In other words, there is no restriction of\nxto restaurants or concepts related to them. Consider the following substitution:\nVegetarianRestaurant (Carburetor ) =)Serves (Carburetor ;VegetarianFood )\nHere the antecedent is still false so the rule remains true under this kind of irrelevant\nsubstitution.\nTo review, variables in logical formulas must be either existentially ( 9) or uni-\nversally (8) quanti\ufb01ed. To satisfy an existentially quanti\ufb01ed variable, at least one\nsubstitution must result in a true sentence. To satisfy a universally quanti\ufb01ed vari-\nable, all substitutions must result in true sentences.",
    "metadata": {
      "source": "F",
      "chunk_id": 11,
      "token_count": 669,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 11\n\nF.3 \u2022 F IRST-ORDER LOGIC 11\nF.3.3 Lambda Notation\nThe \ufb01nal element we need to complete our discussion of FOL is called the lambda\nnotation (Church, 1940). This notation provides a way to abstract from fully speci-lambda\nnotation\n\ufb01ed FOLformulas in a way that will be particularly useful for semantic analysis. The\nlambda notation extends the syntax of FOL to include expressions of the following\nform:\nlx:P(x) (F.29)\nSuch expressions consist of the Greek symbol l, followed by one or more variables,\nfollowed by a FOL formula that makes use of those variables.\nThe usefulness of these l-expressions is based on the ability to apply them to\nlogical terms to yield new FOLexpressions where the formal parameter variables are\nbound to the speci\ufb01ed terms. This process is known as l-reduction , and consists l-reduction\nof a simple textual replacement of the lvariables and the removal of the l. The\nfollowing expressions illustrate the application of a l-expression to the constant A,\nfollowed by the result of performing a l-reduction on this expression:\nlx:P(x)(A) (F.30)\nP(A)\nAn important and useful variation of this technique is the use of one l-expression\nas the body of another as in the following expression:\nlx:ly:Near (x;y) (F.31)\nThis fairly abstract expression can be glossed as the state of something being near\nsomething else. The following expressions illustrate a single l-application and sub-\nsequent reduction with this kind of embedded l-expression:\nlx:ly:Near (x;y)(Bacaro ) (F.32)\nly:Near (Bacaro ;y)\nThe important point here is that the resulting expression is still a l-expression; the\n\ufb01rst reduction bound the variable xand removed the outer l, thus revealing the\ninner expression. As might be expected, this resulting l-expression can, in turn,\nbe applied to another term to arrive at a fully speci\ufb01ed logical formula, as in the\nfollowing:\nly:Near (Bacaro ;y)(Centro ) (F.33)\nNear (Bacaro ;Centro )\nThis general technique, called currying1(Sch \u00a8on\ufb01nkel, 1924) is a way of converting currying\na predicate with multiple arguments into a sequence of single-argument predicates.\nThel-notation also provides a way to incrementally gather arguments to a pred-\nicate when they do not all appear together as daughters of the predicate in a parse\ntree.\nF.3.4 The Semantics of First-Order Logic\nThe various objects, properties, and relations represented in a FOL knowledge base\nacquire their meanings by virtue of their correspondence to objects, properties, and\n1Currying is the standard term, although Heim and Kratzer (1998) present an interesting argument for\nthe term Sch\u00a8on\ufb01nkelization over currying, since Curry later built on Sch \u00a8on\ufb01nkel\u2019s work.",
    "metadata": {
      "source": "F",
      "chunk_id": 12,
      "token_count": 660,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 12\n\n12 APPENDIX F \u2022 L OGICAL REPRESENTATIONS OF SENTENCE MEANING\nrelations out in the external world being modeled. We can accomplish this by em-\nploying the model-theoretic approach introduced in Section F.2. Recall that this\napproach employs simple set-theoretic notions to provide a truth-conditional map-\nping from the expressions in a meaning representation to the state of affairs being\nmodeled. We can apply this approach to FOL by going through all the elements in\nFig. F.3 on page 7 and specifying how each should be accounted for.\nWe can start by asserting that the objects in our world, FOL terms, denote ele-\nments in a domain, and asserting that atomic formulas are captured either as sets of\ndomain elements for properties, or as sets of tuples of elements for relations. As an\nexample, consider the following:\n(F.34) Centro is near Bacaro.\nCapturing the meaning of this example in FOL involves identifying the Terms\nandPredicates that correspond to the various grammatical elements in the sentence\nand creating logical formulas that capture the relations implied by the words and\nsyntax of the sentence. For this example, such an effort might yield something like\nthe following:\nNear (Centro ;Bacaro ) (F.35)\nThe meaning of this logical formula is based on whether the domain elements de-\nnoted by the terms Centro andBacaro are contained among the tuples denoted by\nthe relation denoted by the predicate Near in the current model.\nThe interpretation of formulas involving logical connectives is based on the\nmeanings of the components in the formulas combined with the meanings of the\nconnectives they contain. Figure F.4 gives interpretations for each of the logical\noperators shown in Fig. F.3.\nP Q :P P^Q P_Q P =)Q\nFalse False True False False True\nFalse True True False True True\nTrue False False False True False\nTrue True False True True True\nFigure F.4 Truth table giving the semantics of the various logical connectives.\nThe semantics of the ^(and) and:(not) operators are fairly straightforward,\nand are correlated with at least some of the senses of the corresponding English\nterms. However, it is worth pointing out that the _(or) operator is not disjunctive\nin the same way that the corresponding English word is, and that the =)(im-\nplies) operator is only loosely based on any common-sense notions of implication\nor causation.\nThe \ufb01nal bit we need to address involves variables and quanti\ufb01ers. Recall that\nthere are no variables in our set-based models, only elements of the domain and\nrelations that hold among them. We can provide a model-based account for formulas\nwith variables by employing the notion of a substitution introduced earlier on page\n9. Formulas involving 9are true if a substitution of terms for variables results in\na formula that is true in the model. Formulas involving 8must be true under all\npossible substitutions.\nF.3.5 Inference\nA meaning representation language must support inference to add valid new propo-\nsitions to a knowledge base or to determine the truth of propositions not explicitly",
    "metadata": {
      "source": "F",
      "chunk_id": 13,
      "token_count": 672,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 13",
    "metadata": {
      "source": "F",
      "chunk_id": 14,
      "token_count": 4,
      "chapter_title": ""
    }
  },
  {
    "content": "F.3 \u2022 F IRST-ORDER LOGIC 13\ncontained within a knowledge base (Section F.1). This section brie\ufb02y discusses\nmodus ponens , the most widely implemented inference method provided by FOL.\nModus ponens is a form of inference that corresponds to what is informally Modus ponens\nknown as if-then reasoning. We can abstractly de\ufb01ne modus ponens as follows,\nwhere aandbshould be taken as FOL formulas:\na\na=)b\nb(F.36)\nA schema like this indicates that the formula below the line can be inferred from the\nformulas above the line by some form of inference. Modus ponens states that if the\nleft-hand side of an implication rule is true, then the right-hand side of the rule can\nbe inferred. In the following discussions, we will refer to the left-hand side of an\nimplication as the antecedent and the right-hand side as the consequent .\nFor a typical use of modus ponens, consider the following example, which uses\na rule from the last section:\nVegetarianRestaurant (Leaf )\n8xVegetarianRestaurant (x) =)Serves (x;VegetarianFood )\nServes (Leaf ;VegetarianFood )(F.37)\nHere, the formula VegetarianRestaurant (Leaf )matches the antecedent of the rule,\nthus allowing us to use modus ponens to conclude Serves (Leaf ;VegetarianFood ).\nModus ponens can be put to practical use in one of two ways: forward chaining\nand backward chaining. In forward chaining systems, modus ponens is used inforward\nchaining\nprecisely the manner just described. As individual facts are added to the knowledge\nbase, modus ponens is used to \ufb01re all applicable implication rules. In this kind of\narrangement, as soon as a new fact is added to the knowledge base, all applicable\nimplication rules are found and applied, each resulting in the addition of new facts to\nthe knowledge base. These new propositions in turn can be used to \ufb01re implication\nrules applicable to them. The process continues until no further facts can be deduced.\nThe forward chaining approach has the advantage that facts will be present in\nthe knowledge base when needed, because, in a sense all inference is performed in\nadvance. This can substantially reduce the time needed to answer subsequent queries\nsince they should all amount to simple lookups. The disadvantage of this approach\nis that facts that will never be needed may be inferred and stored.\nInbackward chaining , modus ponens is run in reverse to prove speci\ufb01c propo-backward\nchaining\nsitions called queries. The \ufb01rst step is to see if the query formula is true by determin-\ning if it is present in the knowledge base. If it is not, then the next step is to search\nfor applicable implication rules present in the knowledge base. An applicable rule\nis one whereby the consequent of the rule matches the query formula. If there are\nany such rules, then the query can be proved if the antecedent of any one them can\nbe shown to be true. This can be performed recursively by backward chaining on\nthe antecedent as a new query. The Prolog programming language is a backward\nchaining system that implements this strategy.\nTo see how this works, let\u2019s assume that we have been asked to verify the truth of\nthe proposition Serves (Leaf ;VegetarianFood ), assuming the facts given above the\nline in (F.37). Since this proposition is not present in the knowledge base, a search",
    "metadata": {
      "source": "F",
      "chunk_id": 15,
      "token_count": 770,
      "chapter_title": ""
    }
  },
  {
    "content": "the knowledge base when needed, because, in a sense all inference is performed in\nadvance. This can substantially reduce the time needed to answer subsequent queries\nsince they should all amount to simple lookups. The disadvantage of this approach\nis that facts that will never be needed may be inferred and stored.\nInbackward chaining , modus ponens is run in reverse to prove speci\ufb01c propo-backward\nchaining\nsitions called queries. The \ufb01rst step is to see if the query formula is true by determin-\ning if it is present in the knowledge base. If it is not, then the next step is to search\nfor applicable implication rules present in the knowledge base. An applicable rule\nis one whereby the consequent of the rule matches the query formula. If there are\nany such rules, then the query can be proved if the antecedent of any one them can\nbe shown to be true. This can be performed recursively by backward chaining on\nthe antecedent as a new query. The Prolog programming language is a backward\nchaining system that implements this strategy.\nTo see how this works, let\u2019s assume that we have been asked to verify the truth of\nthe proposition Serves (Leaf ;VegetarianFood ), assuming the facts given above the\nline in (F.37). Since this proposition is not present in the knowledge base, a search\nfor an applicable rule is initiated resulting in the rule given above. After substituting\nthe constant Leaf for the variable x, our next task is to prove the antecedent of the\nrule, VegetarianRestaurant (Leaf ), which, of course, is one of the facts we are given.",
    "metadata": {
      "source": "F",
      "chunk_id": 16,
      "token_count": 348,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 14\n\n14 APPENDIX F \u2022 L OGICAL REPRESENTATIONS OF SENTENCE MEANING\nNote that it is critical to distinguish between reasoning by backward chaining\nfrom queries to known facts and reasoning backwards from known consequents to\nunknown antecedents. To be speci\ufb01c, by reasoning backwards we mean that if the\nconsequent of a rule is known to be true, we assume that the antecedent will be as\nwell. For example, let\u2019s assume that we know that Serves (Leaf ;VegetarianFood )is\ntrue. Since this fact matches the consequent of our rule, we might reason backwards\nto the conclusion that VegetarianRestaurant (Leaf ).\nWhile backward chaining is a sound method of reasoning, reasoning backwards\nis an invalid, though frequently useful, form of plausible reasoning . Plausible rea-\nsoning from consequents to antecedents is known as abduction , and as we show in abduction\nChapter 24, is often useful in accounting for many of the inferences people make\nwhile analyzing extended discourses.\nWhile forward and backward reasoning are sound, neither is complete . This complete\nmeans that there are valid inferences that cannot be found by systems using these\nmethods alone. Fortunately, there is an alternative inference technique called reso-\nlution that is sound and complete. Unfortunately, inference systems based on res- resolution\nolution are far more computationally expensive than forward or backward chaining\nsystems. In practice, therefore, most systems use some form of chaining and place\na burden on knowledge base developers to encode the knowledge in a fashion that\npermits the necessary inferences to be drawn.\nF.4 Event and State Representations\nMuch of the semantics that we wish to capture consists of representations of states\nand events. States are conditions, or properties, that remain unchanged over an\nextended period of time, and events denote changes in some state of affairs. The\nrepresentation of both states and events may involve a host of participants, props,\ntimes and locations.\nThe representations for events and states that we have used thus far have con-\nsisted of single predicates with as many arguments as are needed to incorporate all\nthe roles associated with a given example. For example, the representation for Leaf\nserves vegetarian fare consists of a single predicate with arguments for the entity\ndoing the serving and the thing served.\nServes (Leaf ;VegetarianFare ) (F.38)\nThis approach assumes that the predicate used to represent an event verb has the\nsame number of arguments as are present in the verb\u2019s syntactic subcategorization\nframe. Unfortunately, this is clearly not always the case. Consider the following\nexamples of the verb eat:\n(F.39) I ate.\n(F.40) I ate a turkey sandwich.\n(F.41) I ate a turkey sandwich at my desk.\n(F.42) I ate at my desk.\n(F.43) I ate lunch.\n(F.44) I ate a turkey sandwich for lunch.\n(F.45) I ate a turkey sandwich for lunch at my desk.",
    "metadata": {
      "source": "F",
      "chunk_id": 17,
      "token_count": 633,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 15\n\nF.5 \u2022 D ESCRIPTION LOGICS 15\nClearly, choosing the correct number of arguments for the predicate represent-\ning the meaning of eatis a tricky problem. These examples introduce \ufb01ve distinct\narguments, or roles, in an array of different syntactic forms, locations, and combina-\ntions. Unfortunately, predicates in FOL have \ufb01xed arity \u2013 they take a \ufb01xed number arity\nof arguments.\nTo address this problem, we introduce the notion of an event variable to allow event variable\nus to make assertions about particular events. To do this, we can refactor our event\npredicates to have an existentially quanti\ufb01ed variable as their \ufb01rst, and only , argu-\nment. Using this event variable, we can introduce additional predicates to represent\nthe other information we have about the event. These predicates take an event vari-\nable as their \ufb01rst argument and related FOL terms as their second argument. The\nfollowing formula illustrates this scheme with the meaning representation of F.40\nfrom our earlier discussion.\n9e Eating (e)^Eater (e;Speaker )^Eaten (e;TurkeySandwich )\nHere, the quanti\ufb01ed variable estands for the eating event and is used to bind the\nevent predicate with the core information provided via the named roles Eater and\nEaten . To handle the more complex examples, we simply add additional relations\nto capture the provided information, as in the following for F.45.\n9e Eating (e)^Eater (e;Speaker )^Eaten (e;TurkeySandwich ) (F.46)\n^Meal (e;Lunch )^Location (e;Desk )\nEvent representations of this sort are referred to as neo-Davidsonian event rep-neo-\nDavidsonian\nresentations (Davidson 1967, Parsons 1990) after the philosopher Donald Davidson\nwho introduced the notion of an event variable (Davidson, 1967). To summarize, in\nthe neo-Davidsonian approach to event representations:\n\u2022 Events are captured with predicates that take a single event variable as an\nargument.\n\u2022 There is no need to specify a \ufb01xed number of arguments for a given FOL\npredicate; rather, as many roles and \ufb01llers can be glued on as are provided in\nthe input.\n\u2022 No more roles are postulated than are mentioned in the input.\n\u2022 The logical connections among closely related inputs that share the same pred-\nicate are satis\ufb01ed without the need for additional inference.\nThis approach still leaves us with the problem of determining the set of predi-\ncates needed to represent roles associated with speci\ufb01c events like Eater andEaten ,\nas well as more general concepts like Location andTime . We\u2019ll return to this prob-\nlem in more detail in Chapter 20 and Chapter 21.\nF.5 Description Logics\nAs noted at the beginning of this chapter, a fair number of representational schemes\nhave been invented to capture the meaning of linguistic utterances. It is now widely\naccepted that meanings represented in these various approaches can, in principle, be\ntranslated into equivalent statements in FOL with relative ease. The dif\ufb01culty is that\nin many of these approaches the semantics of a statement are de\ufb01ned procedurally.\nThat is, the meaning arises from whatever the system that interprets it does with it.",
    "metadata": {
      "source": "F",
      "chunk_id": 18,
      "token_count": 714,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 16\n\n16 APPENDIX F \u2022 L OGICAL REPRESENTATIONS OF SENTENCE MEANING\nDescription logics are an effort to better specify the semantics of these earlier\nstructured network representations and to provide a conceptual framework that is\nespecially well suited to certain kinds of domain modeling. Formally, the term De-\nscription Logics refers to a family of logical approaches that correspond to varying\nsubsets of FOL. The restrictions placed on the expressiveness of Description Logics\nserve to guarantee the tractability of various critical kinds of inference. Our focus\nhere, however, will be on the modeling aspects of DLs rather than on computational\ncomplexity issues.\nWhen using Description Logics to model an application domain, the emphasis\nis on the representation of knowledge about categories, individuals that belong to\nthose categories, and the relationships that can hold among these individuals. The\nset of categories, or concepts, that make up a particular application domain is called\nitsterminology . The portion of a knowledge base that contains the terminology is terminology\ntraditionally called the TBox ; this is in contrast to the ABox that contains facts about TBox\nABox individuals. The terminology is typically arranged into a hierarchical organization\ncalled an ontology that captures the subset/superset relations among the categories. ontology\nReturning to our earlier culinary domain, we represented domain concepts us-\ning unary predicates such as Restaurant (x); the DL equivalent omits the variable,\nso the restaurant category is simply written as Restaurant .2To capture the fact\nthat a particular domain element, such as Frasca , is a restaurant, we assert Restau-\nrant(Frasca) in much the same way we would in FOL. The semantics of these\ncategories are speci\ufb01ed in precisely the same way that was introduced earlier in\nSection F.2: a category like Restaurant simply denotes the set of domain elements\nthat are restaurants.\nOnce we\u2019ve speci\ufb01ed the categories of interest in a particular domain, the next\nstep is to arrange them into a hierarchical structure. There are two ways to cap-\nture the hierarchical relationships present in a terminology: we can directly assert\nrelations between categories that are related hierarchically, or we can provide com-\nplete de\ufb01nitions for our concepts and then rely on inference to provide hierarchical\nrelationships. The choice between these methods hinges on the use to which the re-\nsulting categories will be put and the feasibility of formulating precise de\ufb01nitions for\nmany naturally occurring categories. We\u2019ll discuss the \ufb01rst option here and return to\nthe notion of de\ufb01nitions later in this section.\nTo directly specify a hierarchical structure, we can assert subsumption relations subsumption\nbetween the appropriate concepts in a terminology. The subsumption relation is\nconventionally written as CvDand is read as Cis subsumed by D; that is, all\nmembers of the category Care also members of the category D. Not surprisingly, the\nformal semantics of this relation are provided by a simple set relation; any domain\nelement that is in the set denoted by Cis also in the set denoted by D.\nAdding the following statements to the TBox asserts that all restaurants are com-\nmercial establishments and, moreover, that there are various subtypes of restaurants.\nRestaurantvCommercialEstablishment (F.47)\nItalianRestaurant vRestaurant (F.48)\nChineseRestaurant vRestaurant (F.49)\nMexicanRestaurant vRestaurant (F.50)\nOntologies such as this are conventionally illustrated with diagrams such as the one\n2DL statements are conventionally typeset with a sans serif font. We\u2019ll follow that convention here,\nreverting to our standard mathematical notation when giving FOL equivalents of DL statements.",
    "metadata": {
      "source": "F",
      "chunk_id": 19,
      "token_count": 780,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 17\n\nF.5 \u2022 D ESCRIPTION LOGICS 17\nshown in Fig. F.5, where subsumption relations are denoted by links between the\nnodes representing the categories.\nRestaurantChineseRestaurant MexicanRestaurantItalianRestaurantCommercialEstablishment\nFigure F.5 A graphical network representation of a set of subsumption relations in the\nrestaurant domain.\nNote, that it was precisely the vague nature of semantic network diagrams like\nthis that motivated the development of Description Logics. For example, from this\ndiagram we can\u2019t tell whether the given set of categories is exhaustive or disjoint.\nThat is, we can\u2019t tell if these are all the kinds of restaurants that we\u2019ll be dealing with\nin our domain or whether there might be others. We also can\u2019t tell if an individual\nrestaurant must fall into only oneof these categories, or if it is possible, for example,\nfor a restaurant to be both Italian and Chinese. The DL statements given above are\nmore transparent in their meaning; they simply assert a set of subsumption relations\nbetween categories and make no claims about coverage or mutual exclusion.\nIf an application requires coverage and disjointness information, then such in-\nformation must be made explicitly. The simplest ways to capture this kind of in-\nformation is through the use of negation and disjunction operators. For example,\nthe following assertion would tell us that Chinese restaurants can\u2019t also be Italian\nrestaurants.\nChineseRestaurant vnotItalianRestaurant (F.51)\nSpecifying that a set of subconcepts covers a category can be achieved with disjunc-\ntion, as in the following:\nRestaurantv (F.52)\n(orItalianRestaurant ChineseRestaurant MexicanRestaurant )\nHaving a hierarchy such as the one given in Fig. F.5 tells us next to nothing\nabout the concepts in it. We certainly don\u2019t know anything about what makes a\nrestaurant a restaurant, much less Italian, Chinese, or expensive. What is needed are\nadditional assertions about what it means to be a member of any of these categories.\nIn Description Logics such statements come in the form of relations between the\nconcepts being described and other concepts in the domain. In keeping with its\norigins in structured network representations, relations in Description Logics are\ntypically binary and are often referred to as roles, or role-relations.\nTo see how such relations work, let\u2019s consider some of the facts about restaurants\ndiscussed earlier in the chapter. We\u2019ll use the hasCuisine relation to capture infor-\nmation as to what kinds of food restaurants serve and the hasPriceRange relation\nto capture how pricey particular restaurants tend to be. We can use these relations\nto say something more concrete about our various classes of restaurants. Let\u2019s start",
    "metadata": {
      "source": "F",
      "chunk_id": 20,
      "token_count": 562,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 18\n\n18 APPENDIX F \u2022 L OGICAL REPRESENTATIONS OF SENTENCE MEANING\nwith our ItalianRestaurant concept. As a \ufb01rst approximation, we might say some-\nthing uncontroversial like Italian restaurants serve Italian cuisine. To capture these\nnotions, let\u2019s \ufb01rst add some new concepts to our terminology to represent various\nkinds of cuisine.\nMexicanCuisinevCuisine\nItalianCuisinevCuisine\nChineseCuisinevCuisine\nVegetarianCuisine vCuisineExpensiveRestaurant vRestaurant\nModerateRestaurant vRestaurant\nCheapRestaurant vRestaurant\nNext, let\u2019s revise our earlier version of ItalianRestaurant to capture cuisine infor-\nmation.\nItalianRestaurant vRestaurantu9hasCuisine :ItalianCuisine (F.53)\nThe correct way to read this expression is that individuals in the category Italian-\nRestaurant are subsumed both by the category Restaurant and by an unnamed\nclass de\ufb01ned by the existential clause\u2014the set of entities that serve Italian cuisine.\nAn equivalent statement in FOL would be\n8xItalianRestaurant (x)!Restaurant (x) (F.54)\n^(9yServes (x;y)^ItalianCuisine (y))\nThis FOL translation should make it clear what the DL assertions given above do\nand do not entail. In particular, they don\u2019t say that domain entities classi\ufb01ed as Ital-\nian restaurants can\u2019t engage in other relations like being expensive or even serving\nChinese cuisine. And critically, they don\u2019t say much about domain entities that we\nknow do serve Italian cuisine. In fact, inspection of the FOL translation makes it\nclear that we cannot infer that any new entities belong to this category based on their\ncharacteristics. The best we can do is infer new facts about restaurants that we\u2019re\nexplicitly told are members of this category.\nOf course, inferring the category membership of individuals given certain char-\nacteristics is a common and critical reasoning task that we need to support. This\nbrings us back to the alternative approach to creating hierarchical structures in a\nterminology: actually providing a de\ufb01nition of the categories we\u2019re creating in the\nform of necessary and suf\ufb01cient conditions for category membership. In this case,\nwe might explicitly provide a de\ufb01nition for ItalianRestaurant as being those restau-\nrants that serve Italian cuisine, and ModerateRestaurant as being those whose\nprice range is moderate.\nItalianRestaurant \u0011Restaurantu9hasCuisine :ItalianCuisine (F.55)\nModerateRestaurant \u0011RestaurantuhasPriceRange :ModeratePrices (F.56)\nWhile our earlier statements provided necessary conditions for membership in these\ncategories, these statements provide both necessary and suf\ufb01cient conditions.\nFinally, let\u2019s now consider the super\ufb01cially similar case of vegetarian restaurants.\nClearly, vegetarian restaurants are those that serve vegetarian cuisine. But they don\u2019t\nmerely serve vegetarian fare, that\u2019s all they serve. We can accommodate this kind of\nconstraint by adding an additional restriction in the form of a universal quanti\ufb01er to",
    "metadata": {
      "source": "F",
      "chunk_id": 21,
      "token_count": 643,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 19\n\nF.5 \u2022 D ESCRIPTION LOGICS 19\nour earlier description of VegetarianRestaurants , as follows:\nVegetarianRestaurant \u0011Restaurant (F.57)\nu9hasCuisine :VegetarianCuisine\nu8hasCuisine :VegetarianCuisine\nInference\nParalleling the focus of Description Logics on categories, relations, and individuals\nis a processing focus on a restricted subset of logical inference. Rather than employ-\ning the full range of reasoning permitted by FOL, DL reasoning systems emphasize\nthe closely coupled problems of subsumption and instance checking.\nSubsumption , as a form of inference, is the task of determining, based on the subsumption\nfacts asserted in a terminology, whether a superset/subset relationship exists between\ntwo concepts. Correspondingly, instance checking asks if an individual can be ainstance\nchecking\nmember of a particular category given the facts we know about both the individual\nand the terminology. The inference mechanisms underlying subsumption and in-\nstance checking go beyond simply checking for explicitly stated subsumption rela-\ntions in a terminology. They must explicitly reason using the relational information\nasserted about the terminology to infer appropriate subsumption and membership\nrelations.\nReturning to our restaurant domain, let\u2019s add a new kind of restaurant using the\nfollowing statement:\nIlFornaiovModerateRestaurant u9hasCuisine :ItalianCuisine (F.58)\nGiven this assertion, we might ask whether the IlFornaio chain of restaurants might\nbe classi\ufb01ed as an Italian restaurant or a vegetarian restaurant. More precisely, we\ncan pose the following questions to our reasoning system:\nIlFornaiovItalianRestaurant (F.59)\nIlFornaiovVegetarianRestaurant (F.60)\nThe answer to the \ufb01rst question is positive since IlFornaio meets the criteria we\nspeci\ufb01ed for the category ItalianRestaurant : it\u2019s a Restaurant since we explicitly\nclassi\ufb01ed it as a ModerateRestaurant , which is a subtype of Restaurant , and it\nmeets the has.Cuisine class restriction since we\u2019ve asserted that directly.\nThe answer to the second question is negative. Recall, that our criteria for veg-\netarian restaurants contains two requirements: it has to serve vegetarian fare, and\nthat\u2019s all it can serve. Our current de\ufb01nition for IlFornaio fails on both counts since\nwe have not asserted any relations that state that IlFornaio serves vegetarian fare,\nand the relation we have asserted, hasCuisine.ItalianCuisine , contradicts the sec-\nond criteria.\nA related reasoning task, based on the basic subsumption inference, is to derive\ntheimplied hierarchy for a terminology given facts about the categories in the ter-implied\nhierarchy\nminology. This task roughly corresponds to a repeated application of the subsump-\ntion operator to pairs of concepts in the terminology. Given our current collection\nof statements, the expanded hierarchy shown in Fig. F.6 can be inferred. You should\nconvince yourself that this diagram contains all and only the subsumption links that\nshould be present given our current knowledge.\nInstance checking is the task of determining whether a particular individual can\nbe classi\ufb01ed as a member of a particular category. This process takes what is known",
    "metadata": {
      "source": "F",
      "chunk_id": 22,
      "token_count": 697,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 20\n\n20 APPENDIX F \u2022 L OGICAL REPRESENTATIONS OF SENTENCE MEANING\nRestaurant\nChineseRestaurant MexicanRestaurantItalianRestaurantExpensiveRestaurantCheapRestaurantModerateRestaurantIl FornaioVegetarianRestaurant\nFigure F.6 A graphical network representation of the complete set of subsumption relations\nin the restaurant domain given the current set of assertions in the TBox.\nabout a given individual, in the form of relations and explicit categorical statements,\nand then compares that information with what is known about the current terminol-\nogy. It then returns a list of the most speci\ufb01c categories to which the individual can\nbelong.\nAs an example of a categorization problem, consider an establishment that we\u2019re\ntold is a restaurant and serves Italian cuisine.\nRestaurant (Gondolier )\nhasCuisine (Gondolier ;ItalianCuisine )\nHere, we\u2019re being told that the entity denoted by the term Gondolier is a restau-\nrant and serves Italian food. Given this new information and the contents of our\ncurrent TBox, we might reasonably like to ask if this is an Italian restaurant, if it is\na vegetarian restaurant, or if it has moderate prices.\nAssuming the de\ufb01nitional statements given earlier, we can indeed categorize\nthe Gondolier as an Italian restaurant. That is, the information we\u2019ve been given\nabout it meets the necessary and suf\ufb01cient conditions required for membership in\nthis category. And as with the IlFornaio category, this individual fails to match the\nstated criteria for the VegetarianRestaurant . Finally, the Gondolier might also\nturn out to be a moderately priced restaurant, but we can\u2019t tell at this point since\nwe don\u2019t know anything about its prices. What this means is that given our current\nknowledge the answer to the query ModerateRestaurant (Gondolier )would be false\nsince it lacks the required hasPriceRange relation.\nThe implementation of subsumption, instance checking, as well as other kinds of\ninferences needed for practical applications, varies according to the expressivity of\nthe Description Logic being used. However, for a Description Logic of even modest\npower, the primary implementation techniques are based on satis\ufb01ability methods\nthat in turn rely on the underlying model-based semantics introduced earlier in this\nchapter.\nOWL and the Semantic Web\nThe highest-pro\ufb01le role for Description Logics, to date, has been as a part of the\ndevelopment of the Semantic Web. The Semantic Web is an ongoing effort to pro-\nvide a way to formally specify the semantics of the contents of the Web (Fensel\net al., 2003). A key component of this effort involves the creation and deployment\nof ontologies for various application areas of interest. The meaning representation",
    "metadata": {
      "source": "F",
      "chunk_id": 23,
      "token_count": 588,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 21\n\nF.6 \u2022 S UMMARY 21\nlanguage used to represent this knowledge is the Web Ontology Language (OWL)Web Ontology\nLanguage\n(McGuiness and van Harmelen, 2004). OWL embodies a Description Logic that\ncorresponds roughly to the one we\u2019ve been describing here.\nF.6 Summary\nThis chapter has introduced the representational approach to meaning. The follow-\ning are some of the highlights of this chapter:\n\u2022 A major approach to meaning in computational linguistics involves the cre-\nation of formal meaning representations that capture the meaning-related\ncontent of linguistic inputs. These representations are intended to bridge the\ngap from language to common-sense knowledge of the world.\n\u2022 The frameworks that specify the syntax and semantics of these representa-\ntions are called meaning representation languages . A wide variety of such\nlanguages are used in natural language processing and arti\ufb01cial intelligence.\n\u2022 Such representations need to be able to support the practical computational\nrequirements of semantic processing. Among these are the need to determine\nthe truth of propositions , to support unambiguous representations , to rep-\nresent variables , to support inference , and to be suf\ufb01ciently expressive .\n\u2022 Human languages have a wide variety of features that are used to convey\nmeaning. Among the most important of these is the ability to convey a predicate-\nargument structure .\n\u2022First-Order Logic is a well-understood, computationally tractable meaning\nrepresentation language that offers much of what is needed in a meaning rep-\nresentation language.\n\u2022 Important elements of semantic representation including states andevents\ncan be captured in FOL.\n\u2022Semantic networks andframes can be captured within the FOL framework.\n\u2022 Modern Description Logics consist of useful and computationally tractable\nsubsets of full First-Order Logic. The most prominent use of a description\nlogic is the Web Ontology Language (OWL), used in the speci\ufb01cation of the\nSemantic Web.\nBibliographical and Historical Notes\nThe earliest computational use of declarative meaning representations in natural lan-\nguage processing was in the context of question-answering systems (Green et al.\n1961, Raphael 1968, Lindsey 1963). These systems employed ad hoc representa-\ntions for the facts needed to answer questions. Questions were then translated into\na form that could be matched against facts in the knowledge base. Simmons (1965)\nprovides an overview of these early efforts.\nWoods (1967) investigated the use of FOL-like representations in question an-\nswering as a replacement for the ad hoc representations in use at the time. Woods\n(1973) further developed and extended these ideas in the landmark Lunar system.",
    "metadata": {
      "source": "F",
      "chunk_id": 24,
      "token_count": 558,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 22",
    "metadata": {
      "source": "F",
      "chunk_id": 25,
      "token_count": 4,
      "chapter_title": ""
    }
  },
  {
    "content": "22 APPENDIX F \u2022 L OGICAL REPRESENTATIONS OF SENTENCE MEANING\nInterestingly, the representations used in Lunar had both truth-conditional and pro-\ncedural semantics. Winograd (1972) employed a similar representation based on the\nMicro-Planner language in his SHRDLU system.\nDuring this same period, researchers interested in the cognitive modeling of lan-\nguage and memory had been working with various forms of associative network\nrepresentations. Masterman (1957) was the \ufb01rst to make computational use of a\nsemantic network-like knowledge representation, although semantic networks are\ngenerally credited to Quillian (1968). A considerable amount of work in the se-\nmantic network framework was carried out during this era (Norman and Rumelhart\n1975, Schank 1972, Wilks 1975b, Wilks 1975a, Kintsch 1974). It was during this\nperiod that a number of researchers began to incorporate Fillmore\u2019s notion of case\nroles (Fillmore, 1968) into their representations. Simmons (1973) was the earliest\nadopter of case roles as part of representations for natural language processing.\nDetailed analyses by Woods (1975) and Brachman (1979) aimed at \ufb01guring out\nwhat semantic networks actually mean led to the development of a number of more\nsophisticated network-like languages including KRL (Bobrow and Winograd, 1977)\nand KL-ONE (Brachman and Schmolze, 1985). As these frameworks became more\nsophisticated and well de\ufb01ned, it became clear that they were restricted variants of\nFOL coupled with specialized indexing inference procedures. A useful collection of\npapers covering much of this work can be found in Brachman and Levesque (1985).\nRussell and Norvig (2002) describe a modern perspective on these representational\nefforts.\nLinguistic efforts to assign semantic structures to natural language sentences in\nthe generative era began with the work of Katz and Fodor (1963). The limitations of\ntheir simple feature-based representations and the natural \ufb01t of logic to many of the\nlinguistic problems of the day quickly led to the adoption of a variety of predicate-\nargument structures as preferred semantic representations (Lakoff 1972, McCawley\n1968). The subsequent introduction by Montague (1973) of the truth-conditional\nmodel-theoretic framework into linguistic theory led to a much tighter integration\nbetween theories of formal syntax and a wide range of formal semantic frameworks.\nGood introductions to Montague semantics and its role in linguistic theory can be\nfound in Dowty et al. (1981) and Partee (1976).\nThe representation of events as rei\ufb01ed objects is due to Davidson (1967). The\napproach presented here, which explicitly rei\ufb01es event participants, is due to Parsons\n(1990).\nA recent comprehensive treatment of logic and language can be found in van\nBenthem and ter Meulen (1997). A classic semantics text is Lyons (1977). McCaw-\nley (1993) is an indispensable textbook covering a wide range of topics concerning\nlogic and language. Chierchia and McConnell-Ginet (1991) also broadly covers\nsemantic issues from a linguistic perspective. Heim and Kratzer (1998) is a more\nrecent text written from the perspective of current generative theory.\nExercises\nF.1 Peruse your daily newspaper for three examples of ambiguous sentences or\nheadlines. Describe the various sources of the ambiguities.\nF.2 Consider a domain in which the word coffee can refer to the following con-",
    "metadata": {
      "source": "F",
      "chunk_id": 26,
      "token_count": 779,
      "chapter_title": ""
    }
  },
  {
    "content": "1968). The subsequent introduction by Montague (1973) of the truth-conditional\nmodel-theoretic framework into linguistic theory led to a much tighter integration\nbetween theories of formal syntax and a wide range of formal semantic frameworks.\nGood introductions to Montague semantics and its role in linguistic theory can be\nfound in Dowty et al. (1981) and Partee (1976).\nThe representation of events as rei\ufb01ed objects is due to Davidson (1967). The\napproach presented here, which explicitly rei\ufb01es event participants, is due to Parsons\n(1990).\nA recent comprehensive treatment of logic and language can be found in van\nBenthem and ter Meulen (1997). A classic semantics text is Lyons (1977). McCaw-\nley (1993) is an indispensable textbook covering a wide range of topics concerning\nlogic and language. Chierchia and McConnell-Ginet (1991) also broadly covers\nsemantic issues from a linguistic perspective. Heim and Kratzer (1998) is a more\nrecent text written from the perspective of current generative theory.\nExercises\nF.1 Peruse your daily newspaper for three examples of ambiguous sentences or\nheadlines. Describe the various sources of the ambiguities.\nF.2 Consider a domain in which the word coffee can refer to the following con-\ncepts in a knowledge-based system: a caffeinated or decaffeinated beverage,\nground coffee used to make either kind of beverage, and the beans themselves.",
    "metadata": {
      "source": "F",
      "chunk_id": 27,
      "token_count": 314,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 23\n\nEXERCISES 23\nGive arguments as to which of the following uses of coffee are ambiguous and\nwhich are vague.\n1. I\u2019ve had my coffee for today.\n2. Buy some coffee on your way home.\n3. Please grind some more coffee.\nF.3 The following rule, which we gave as a translation for Example F.25, is not a\nreasonable de\ufb01nition of what it means to be a vegetarian restaurant.\n8xVegetarianRestaurant (x) =)Serves (x;VegetarianFood )\nGive a FOLrule that better de\ufb01nes vegetarian restaurants in terms of what they\nserve.\nF.4 Give FOL translations for the following sentences:\n1. Vegetarians do not eat meat.\n2. Not all vegetarians eat eggs.\nF.5 Give a set of facts and inferences necessary to prove the following assertions:\n1. McDonald\u2019s is not a vegetarian restaurant.\n2. Some vegetarians can eat at McDonald\u2019s.\nDon\u2019t just place these facts in your knowledge base. Show that they can be\ninferred from some more general facts about vegetarians and McDonald\u2019s.\nF.6 On page 12, we gave the representation Near (Centro ;Bacaro )as a transla-\ntion for the sentence Centro is near Bacaro . In a truth-conditional semantics,\nthis formula is either true or false given some model. Critique this truth-\nconditional approach with respect to the meaning of words like near.",
    "metadata": {
      "source": "F",
      "chunk_id": 28,
      "token_count": 311,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 24",
    "metadata": {
      "source": "F",
      "chunk_id": 29,
      "token_count": 4,
      "chapter_title": ""
    }
  },
  {
    "content": "24 Appendix F \u2022 Logical Representations of Sentence Meaning\nBanarescu, L., C. Bonial, S. Cai, M. Georgescu, K. Grif-\n\ufb01tt, U. Hermjakob, K. Knight, P. Koehn, M. Palmer, and\nN. Schneider. 2013. Abstract meaning representation for\nsembanking. 7th Linguistic Annotation Workshop and In-\nteroperability with Discourse .\nvan Benthem, J. and A. ter Meulen, eds. 1997. Handbook of\nLogic and Language . MIT Press.\nBobrow, D. G. and T. Winograd. 1977. An overview of KRL,\na knowledge representation language. Cognitive Science ,\n1(1):3\u201346.\nBrachman, R. J. 1979. On the epistemogical status of seman-\ntic networks. In N. V . Findler, ed., Associative Networks:\nRepresentation and Use of Knowledge by Computers , 3\u2013\n50. Academic Press.\nBrachman, R. J. and H. J. Levesque, eds. 1985. Readings in\nKnowledge Representation . Morgan Kaufmann.\nBrachman, R. J. and J. G. Schmolze. 1985. An overview of\nthe KL-ONE knowledge representation system. Cogni-\ntive Science , 9(2):171\u2013216.\nChierchia, G. and S. McConnell-Ginet. 1991. Meaning and\nGrammar . MIT Press.\nChurch, A. 1940. A formulation of a simple theory of types.\nJournal of Symbolic Logic , 5:56\u201368.\nDavidson, D. 1967. The logical form of action sentences. In\nN. Rescher, ed., The Logic of Decision and Action . Uni-\nversity of Pittsburgh Press.\nDowty, D. R., R. E. Wall, and S. Peters. 1981. Introduction\nto Montague Semantics . D. Reidel.\nFensel, D., J. A. Hendler, H. Lieberman, and W. Wahlster,\neds. 2003. Spinning the Semantic Web: Bring the World\nWide Web to its Full Potential . MIT Press, Cambridge,\nMA.\nFillmore, C. J. 1968. The case for case. In E. W. Bach and\nR. T. Harms, eds, Universals in Linguistic Theory , 1\u201388.\nHolt, Rinehart & Winston.\nGreen, B. F., A. K. Wolf, C. Chomsky, and K. Laughery.\n1961. Baseball: An automatic question answerer. Pro-\nceedings of the Western Joint Computer Conference 19 .\nHeim, I. and A. Kratzer. 1998. Semantics in a Generative\nGrammar . Blackwell Publishers, Malden, MA.\nKatz, J. J. and J. A. Fodor. 1963. The structure of a semantic\ntheory. Language , 39:170\u2013210.\nKintsch, W. 1974. The Representation of Meaning in Mem-\nory. Wiley, New York.\nLakoff, G. 1972. Linguistics and natural logic. In D. David-\nson and G. Harman, eds, Semantics for Natural Lan-\nguage , 545\u2013665. D. Reidel.\nLindsey, R. 1963. Inferential memory as the basis of ma-",
    "metadata": {
      "source": "F",
      "chunk_id": 30,
      "token_count": 758,
      "chapter_title": ""
    }
  },
  {
    "content": "Wide Web to its Full Potential . MIT Press, Cambridge,\nMA.\nFillmore, C. J. 1968. The case for case. In E. W. Bach and\nR. T. Harms, eds, Universals in Linguistic Theory , 1\u201388.\nHolt, Rinehart & Winston.\nGreen, B. F., A. K. Wolf, C. Chomsky, and K. Laughery.\n1961. Baseball: An automatic question answerer. Pro-\nceedings of the Western Joint Computer Conference 19 .\nHeim, I. and A. Kratzer. 1998. Semantics in a Generative\nGrammar . Blackwell Publishers, Malden, MA.\nKatz, J. J. and J. A. Fodor. 1963. The structure of a semantic\ntheory. Language , 39:170\u2013210.\nKintsch, W. 1974. The Representation of Meaning in Mem-\nory. Wiley, New York.\nLakoff, G. 1972. Linguistics and natural logic. In D. David-\nson and G. Harman, eds, Semantics for Natural Lan-\nguage , 545\u2013665. D. Reidel.\nLindsey, R. 1963. Inferential memory as the basis of ma-\nchines which understand natural language. In E. Feigen-\nbaum and J. Feldman, eds, Computers and Thought , 217\u2013\n233. McGraw Hill.\nLyons, J. 1977. Semantics . Cambridge University Press.\nMasterman, M. 1957. The thesaurus in syntax and semantics.\nMechanical Translation , 4(1):1\u20132.\nMcCawley, J. D. 1968. The role of semantics in a gram-\nmar. In E. W. Bach and R. T. Harms, eds, Universals in\nLinguistic Theory , 124\u2013169. Holt, Rinehart & Winston.McCawley, J. D. 1993. Everything that Linguists Have Al-\nways Wanted to Know about Logic , 2nd edition. Univer-\nsity of Chicago Press, Chicago, IL.\nMcGuiness, D. L. and F. van Harmelen. 2004. OWL web\nontology overview. Technical Report 20040210, World\nWide Web Consortium.\nMontague, R. 1973. The proper treatment of quanti\ufb01cation\nin ordinary English. In R. Thomason, ed., Formal Philos-\nophy: Selected Papers of Richard Montague , 247\u2013270.\nYale University Press, New Haven, CT.\nNorman, D. A. and D. E. Rumelhart. 1975. Explorations in\nCognition . Freeman.\nParsons, T. 1990. Events in the Semantics of English . MIT\nPress.\nPartee, B. H., ed. 1976. Montague Grammar . Academic\nPress.\nQuillian, M. R. 1968. Semantic memory. In M. Minsky, ed.,\nSemantic Information Processing , 227\u2013270. MIT Press.\nRaphael, B. 1968. SIR: A computer program for semantic\ninformation retrieval. In M. Minsky, ed., Semantic Infor-\nmation Processing , 33\u2013145. MIT Press.\nRussell, S. and P. Norvig. 2002. Arti\ufb01cial Intelligence: A\nModern Approach , 2nd edition. Prentice Hall.",
    "metadata": {
      "source": "F",
      "chunk_id": 31,
      "token_count": 754,
      "chapter_title": ""
    }
  },
  {
    "content": "McGuiness, D. L. and F. van Harmelen. 2004. OWL web\nontology overview. Technical Report 20040210, World\nWide Web Consortium.\nMontague, R. 1973. The proper treatment of quanti\ufb01cation\nin ordinary English. In R. Thomason, ed., Formal Philos-\nophy: Selected Papers of Richard Montague , 247\u2013270.\nYale University Press, New Haven, CT.\nNorman, D. A. and D. E. Rumelhart. 1975. Explorations in\nCognition . Freeman.\nParsons, T. 1990. Events in the Semantics of English . MIT\nPress.\nPartee, B. H., ed. 1976. Montague Grammar . Academic\nPress.\nQuillian, M. R. 1968. Semantic memory. In M. Minsky, ed.,\nSemantic Information Processing , 227\u2013270. MIT Press.\nRaphael, B. 1968. SIR: A computer program for semantic\ninformation retrieval. In M. Minsky, ed., Semantic Infor-\nmation Processing , 33\u2013145. MIT Press.\nRussell, S. and P. Norvig. 2002. Arti\ufb01cial Intelligence: A\nModern Approach , 2nd edition. Prentice Hall.\nSchank, R. C. 1972. Conceptual dependency: A theory\nof natural language processing. Cognitive Psychology ,\n3:552\u2013631.\nSch\u00a8on\ufb01nkel, M. 1924. \u00a8Uber die Bausteine der mathema-\ntischen Logik. Mathematische Annalen , 92:305\u2013316.\nEnglish translation appears in From Frege to G \u00a8odel: A\nSource Book in Mathematical Logic , Harvard University\nPress, 1967.\nSimmons, R. F. 1965. Answering English questions by com-\nputer: A survey. CACM , 8(1):53\u201370.\nSimmons, R. F. 1973. Semantic networks: Their compu-\ntation and use for understanding English sentences. In\nR. C. Schank and K. M. Colby, eds, Computer Models of\nThought and Language , 61\u2013113. W.H. Freeman & Co.\nWilks, Y . 1975a. Preference semantics. In E. L. Keenan,\ned.,The Formal Semantics of Natural Language , 329\u2013\n350. Cambridge Univ. Press.\nWilks, Y . 1975b. A preferential, pattern-seeking, seman-\ntics for natural language inference. Arti\ufb01cial Intelligence ,\n6(1):53\u201374.\nWinograd, T. 1972. Understanding Natural Language . Aca-\ndemic Press.\nWoods, W. A. 1967. Semantics for a Question-Answering\nSystem . Ph.D. thesis, Harvard University.\nWoods, W. A. 1973. Progress in natural language under-\nstanding. Proceedings of AFIPS National Conference .\nWoods, W. A. 1975. What\u2019s in a link: Foundations for se-\nmantic networks. In D. G. Bobrow and A. M. Collins, eds,\nRepresentation and Understanding: Studies in Cognitive\nScience , 35\u201382. Academic Press.",
    "metadata": {
      "source": "F",
      "chunk_id": 32,
      "token_count": 711,
      "chapter_title": ""
    }
  }
]