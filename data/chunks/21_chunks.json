[
  {
    "content": "# 21\n\n## Page 1\n\nSpeech and Language Processing. Daniel Jurafsky & James H. Martin. Copyright \u00a92024. All\nrights reserved. Draft of January 12, 2025.\nCHAPTER\n21Semantic Role Labeling\n\u201cWho, What, Where, When, With what, Why, How\u201d\nThe seven circumstances, associated with Hermagoras and Aristotle (Sloan, 2010)\nSometime between the 7th and 4th centuries BCE, the Indian grammarian P \u00afan.ini1\nwrote a famous treatise on Sanskrit grammar, the As .t.\u00afadhy \u00afay\u00af\u0131 (\u20188 books\u2019), a treatise\nthat has been called \u201cone of the greatest monuments of hu-\nman intelligence\u201d (Bloom\ufb01eld, 1933, 11). The work de-\nscribes the linguistics of the Sanskrit language in the form\nof 3959 sutras, each very ef\ufb01ciently (since it had to be\nmemorized!) expressing part of a formal rule system that\nbrilliantly pre\ufb01gured modern mechanisms of formal lan-\nguage theory (Penn and Kiparsky, 2012). One set of rules\ndescribes the k\u00afarakas , semantic relationships between a\nverb and noun arguments, roles like agent ,instrument , or\ndestination . P\u00afan.ini\u2019s work was the earliest we know of\nthat modeled the linguistic realization of events and their\nparticipants. This task of understanding how participants relate to events\u2014being\nable to answer the question \u201cWho did what to whom\u201d (and perhaps also \u201cwhen and\nwhere\u201d)\u2014is a central question of natural language processing.\nLet\u2019s move forward 2.5 millennia to the present and consider the very mundane\ngoal of understanding text about a purchase of stock by XYZ Corporation. This\npurchasing event and its participants can be described by a wide variety of surface\nforms. The event can be described by a verb ( sold, bought ) or a noun ( purchase ),\nand XYZ Corp can be the syntactic subject (of bought ), the indirect object (of sold),\nor in a genitive or noun compound relation (with the noun purchase ) despite having\nnotionally the same role in all of them:\n\u2022 XYZ corporation bought the stock.\n\u2022 They sold the stock to XYZ corporation.\n\u2022 The stock was bought by XYZ corporation.\n\u2022 The purchase of the stock by XYZ corporation...\n\u2022 The stock purchase by XYZ corporation...\nIn this chapter we introduce a level of representation that captures the common-\nality between these sentences: there was a purchase event, the participants were\nXYZ Corp and some stock, and XYZ Corp was the buyer. These shallow semantic\nrepresentations , semantic roles , express the role that arguments of a predicate take\nin the event, codi\ufb01ed in databases like PropBank and FrameNet. We\u2019ll introduce\nsemantic role labeling , the task of assigning roles to spans in sentences, and selec-\ntional restrictions , the preferences that predicates express about their arguments,\nsuch as the fact that the theme of eatis generally something edible.\n1Figure shows a birch bark manuscript from Kashmir of the Rupavatra, a grammatical textbook based\non the Sanskrit grammar of Panini. Image from the Wellcome Collection.",
    "metadata": {
      "source": "21",
      "chunk_id": 0,
      "token_count": 691,
      "chapter_title": "21"
    }
  },
  {
    "content": "## Page 2\n\n2CHAPTER 21 \u2022 S EMANTIC ROLE LABELING\n21.1 Semantic Roles\nConsider the meanings of the arguments Sasha ,Pat,the window , and the door in\nthese two sentences.\n(21.1) Sasha broke the window.\n(21.2) Pat opened the door.\nThe subjects Sasha andPat, what we might call the breaker of the window-\nbreaking event and the opener of the door-opening event, have something in com-\nmon. They are both volitional actors, often animate, and they have direct causal\nresponsibility for their events.\nThematic roles are a way to capture this semantic commonality between break- thematic roles\nersandopeners . We say that the subjects of both these verbs are agents . Thus, agents\nAGENT is the thematic role that represents an abstract idea such as volitional causa-\ntion. Similarly, the direct objects of both these verbs, the BrokenThing andOpenedThing ,\nare both prototypically inanimate objects that are affected in some way by the action.\nThe semantic role for these participants is theme . theme\nThematic Role De\ufb01nition\nAGENT The volitional causer of an event\nEXPERIENCER The experiencer of an event\nFORCE The non-volitional causer of the event\nTHEME The participant most directly affected by an event\nRESULT The end product of an event\nCONTENT The proposition or content of a propositional event\nINSTRUMENT An instrument used in an event\nBENEFICIARY The bene\ufb01ciary of an event\nSOURCE The origin of the object of a transfer event\nGOAL The destination of an object of a transfer event\nFigure 21.1 Some commonly used thematic roles with their de\ufb01nitions.\nAlthough thematic roles are one of the oldest linguistic models, as we saw above,\ntheir modern formulation is due to Fillmore (1968) and Gruber (1965). Although\nthere is no universally agreed-upon set of roles, Figs. 21.1 and 21.2 list some the-\nmatic roles that have been used in various computational papers, together with rough\nde\ufb01nitions and examples. Most thematic role sets have about a dozen roles, but we\u2019ll\nsee sets with smaller numbers of roles with even more abstract meanings, and sets\nwith very large numbers of roles that are speci\ufb01c to situations. We\u2019ll use the general\nterm semantic roles for all sets of roles, whether small or large. semantic roles\n21.2 Diathesis Alternations\nThe main reason computational systems use semantic roles is to act as a shallow\nmeaning representation that can let us make simple inferences that aren\u2019t possible\nfrom the pure surface string of words, or even from the parse tree. To extend the\nearlier examples, if a document says that Company A acquired Company B , we\u2019d\nlike to know that this answers the query Was Company B acquired? despite the fact\nthat the two sentences have very different surface syntax. Similarly, this shallow\nsemantics might act as a useful intermediate language in machine translation.",
    "metadata": {
      "source": "21",
      "chunk_id": 1,
      "token_count": 640,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 3\n\n21.2 \u2022 D IATHESIS ALTERNATIONS 3\nThematic Role Example\nAGENT The waiter spilled the soup.\nEXPERIENCER John has a headache.\nFORCE The wind blows debris from the mall into our yards.\nTHEME Only after Benjamin Franklin broke the ice ...\nRESULT The city built a regulation-size baseball diamond ...\nCONTENT Mona asked \u201cYou met Mary Ann at a supermarket?\u201d\nINSTRUMENT He poached cat\ufb01sh, stunning them with a shocking device ...\nBENEFICIARY Whenever Ann Callahan makes hotel reservations for her boss ...\nSOURCE I \ufb02ew in from Boston .\nGOAL I drove to Portland .\nFigure 21.2 Some prototypical examples of various thematic roles.\nSemantic roles thus help generalize over different surface realizations of pred-\nicate arguments. For example, while the AGENT is often realized as the subject of\nthe sentence, in other cases the THEME can be the subject. Consider these possible\nrealizations of the thematic arguments of the verb break :\n(21.3) John\nAGENTbroke the window.\nTHEME\n(21.4) John\nAGENTbroke the window\nTHEMEwith a rock.\nINSTRUMENT\n(21.5) The rock\nINSTRUMENTbroke the window.\nTHEME\n(21.6) The window\nTHEMEbroke.\n(21.7) The window\nTHEMEwas broken by John.\nAGENT\nThese examples suggest that break has (at least) the possible arguments AGENT ,\nTHEME , and INSTRUMENT . The set of thematic role arguments taken by a verb is\noften called the thematic grid ,q-grid, or case frame . We can see that there are thematic grid\ncase frame (among others) the following possibilities for the realization of these arguments of\nbreak :\nAGENT /Subject, THEME /Object\nAGENT /Subject, THEME /Object, INSTRUMENT /PPwith\nINSTRUMENT /Subject, THEME /Object\nTHEME /Subject\nIt turns out that many verbs allow their thematic roles to be realized in various\nsyntactic positions. For example, verbs like give can realize the THEME and GOAL\narguments in two different ways:\n(21.8) a. Doris\nAGENTgave the book\nTHEMEto Cary.\nGOAL\nb.Doris\nAGENTgave Cary\nGOALthe book.\nTHEME\nThese multiple argument structure realizations (the fact that break can take AGENT ,\nINSTRUMENT , or THEME as subject, and give can realize its THEME and GOAL in\neither order) are called verb alternations ordiathesis alternations . The alternationverb\nalternation\nwe showed above for give, the dative alternation , seems to occur with particular se-dative\nalternation\nmantic classes of verbs, including \u201cverbs of future having\u201d ( advance ,allocate ,offer,",
    "metadata": {
      "source": "21",
      "chunk_id": 2,
      "token_count": 598,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 4",
    "metadata": {
      "source": "21",
      "chunk_id": 3,
      "token_count": 4,
      "chapter_title": ""
    }
  },
  {
    "content": "4CHAPTER 21 \u2022 S EMANTIC ROLE LABELING\nowe), \u201csend verbs\u201d ( forward ,hand ,mail), \u201cverbs of throwing\u201d ( kick,pass,throw ),\nand so on. Levin (1993) lists for 3100 English verbs the semantic classes to which\nthey belong (47 high-level classes, divided into 193 more speci\ufb01c classes) and the\nvarious alternations in which they participate. These lists of verb classes have been\nincorporated into the online resource VerbNet (Kipper et al., 2000), which links each\nverb to both WordNet and FrameNet entries.\n21.3 Semantic Roles: Problems with Thematic Roles\nRepresenting meaning at the thematic role level seems like it should be useful in\ndealing with complications like diathesis alternations. Yet it has proved quite dif\ufb01-\ncult to come up with a standard set of roles, and equally dif\ufb01cult to produce a formal\nde\ufb01nition of roles like AGENT ,THEME , or INSTRUMENT .\nFor example, researchers attempting to de\ufb01ne role sets often \ufb01nd they need to\nfragment a role like AGENT orTHEME into many speci\ufb01c roles. Levin and Rappa-\nport Hovav (2005) summarize a number of such cases, such as the fact there seem\nto be at least two kinds of INSTRUMENTS ,intermediary instruments that can appear\nas subjects and enabling instruments that cannot:\n(21.9) a. Shelly cut the banana with a knife.\nb. The knife cut the banana.\n(21.10) a. Shelly ate the sliced banana with a fork.\nb. *The fork ate the sliced banana.\nIn addition to the fragmentation problem, there are cases in which we\u2019d like to\nreason about and generalize across semantic roles, but the \ufb01nite discrete lists of roles\ndon\u2019t let us do this.\nFinally, it has proved dif\ufb01cult to formally de\ufb01ne the thematic roles. Consider the\nAGENT role; most cases of AGENTS are animate, volitional, sentient, causal, but any\nindividual noun phrase might not exhibit all of these properties.\nThese problems have led to alternative semantic role models that use either semantic role\nmany fewer or many more roles.\nThe \ufb01rst of these options is to de\ufb01ne generalized semantic roles that abstract\nover the speci\ufb01c thematic roles. For example, PROTO -AGENT and PROTO -PATIENT proto-agent\nproto-patient are generalized roles that express roughly agent-like and roughly patient-like mean-\nings. These roles are de\ufb01ned, not by necessary and suf\ufb01cient conditions, but rather\nby a set of heuristic features that accompany more agent-like or more patient-like\nmeanings. Thus, the more an argument displays agent-like properties (being voli-\ntionally involved in the event, causing an event or a change of state in another par-\nticipant, being sentient or intentionally involved, moving) the greater the likelihood\nthat the argument can be labeled a PROTO -AGENT . The more patient-like the proper-\nties (undergoing change of state, causally affected by another participant, stationary\nrelative to other participants, etc.), the greater the likelihood that the argument can\nbe labeled a PROTO -PATIENT .\nThe second direction is instead to de\ufb01ne semantic roles that are speci\ufb01c to a\nparticular verb or a particular group of semantically related verbs or nouns.\nIn the next two sections we describe two commonly used lexical resources that\nmake use of these alternative versions of semantic roles. PropBank uses both proto-",
    "metadata": {
      "source": "21",
      "chunk_id": 4,
      "token_count": 767,
      "chapter_title": ""
    }
  },
  {
    "content": "many fewer or many more roles.\nThe \ufb01rst of these options is to de\ufb01ne generalized semantic roles that abstract\nover the speci\ufb01c thematic roles. For example, PROTO -AGENT and PROTO -PATIENT proto-agent\nproto-patient are generalized roles that express roughly agent-like and roughly patient-like mean-\nings. These roles are de\ufb01ned, not by necessary and suf\ufb01cient conditions, but rather\nby a set of heuristic features that accompany more agent-like or more patient-like\nmeanings. Thus, the more an argument displays agent-like properties (being voli-\ntionally involved in the event, causing an event or a change of state in another par-\nticipant, being sentient or intentionally involved, moving) the greater the likelihood\nthat the argument can be labeled a PROTO -AGENT . The more patient-like the proper-\nties (undergoing change of state, causally affected by another participant, stationary\nrelative to other participants, etc.), the greater the likelihood that the argument can\nbe labeled a PROTO -PATIENT .\nThe second direction is instead to de\ufb01ne semantic roles that are speci\ufb01c to a\nparticular verb or a particular group of semantically related verbs or nouns.\nIn the next two sections we describe two commonly used lexical resources that\nmake use of these alternative versions of semantic roles. PropBank uses both proto-\nroles and verb-speci\ufb01c semantic roles. FrameNet uses semantic roles that are spe-\nci\ufb01c to a general semantic idea called a frame .",
    "metadata": {
      "source": "21",
      "chunk_id": 5,
      "token_count": 322,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 5\n\n21.4 \u2022 T HEPROPOSITION BANK 5\n21.4 The Proposition Bank\nThe Proposition Bank , generally referred to as PropBank , is a resource of sen- PropBank\ntences annotated with semantic roles. The English PropBank labels all the sentences\nin the Penn TreeBank; the Chinese PropBank labels sentences in the Penn Chinese\nTreeBank. Because of the dif\ufb01culty of de\ufb01ning a universal set of thematic roles,\nthe semantic roles in PropBank are de\ufb01ned with respect to an individual verb sense.\nEach sense of each verb thus has a speci\ufb01c set of roles, which are given only numbers\nrather than names: Arg0 ,Arg1 ,Arg2 , and so on. In general, Arg0 represents the\nPROTO -AGENT , and Arg1 , the PROTO -PATIENT . The semantics of the other roles\nare less consistent, often being de\ufb01ned speci\ufb01cally for each verb. Nonetheless there\nare some generalization; the Arg2 is often the benefactive, instrument, attribute, or\nend state, the Arg3 the start point, benefactive, instrument, or attribute, and the Arg4\nthe end point.\nHere are some slightly simpli\ufb01ed PropBank entries for one sense each of the\nverbs agree andfall. Such PropBank entries are called frame \ufb01les ; note that the\nde\ufb01nitions in the frame \ufb01le for each role (\u201cOther entity agreeing\u201d, \u201cExtent, amount\nfallen\u201d) are informal glosses intended to be read by humans, rather than being formal\nde\ufb01nitions.\n(21.11) agree.01\nArg0: Agreer\nArg1: Proposition\nArg2: Other entity agreeing\nEx1: [ Arg0 The group] agreed [Arg1 it wouldn\u2019t make an offer].\nEx2: [ ArgM-TMP Usually] [ Arg0 John] agrees [Arg2 with Mary]\n[Arg1 on everything].\n(21.12) fall.01\nArg1: Logical subject, patient, thing falling\nArg2: Extent, amount fallen\nArg3: start point\nArg4: end point, end state of arg1\nEx1: [ Arg1 Sales] fell[Arg4 to $25 million] [ Arg3 from $27 million].\nEx2: [ Arg1 The average junk bond] fell[Arg2 by 4.2%].\nNote that there is no Arg0 role for fall, because the normal subject of fallis a\nPROTO -PATIENT .\nThe PropBank semantic roles can be useful in recovering shallow semantic in-\nformation about verbal arguments. Consider the verb increase :\n(21.13) increase.01 \u201cgo up incrementally\u201d\nArg0: causer of increase\nArg1: thing increasing\nArg2: amount increased by, EXT, or MNR\nArg3: start point\nArg4: end point\nA PropBank semantic role labeling would allow us to infer the commonality in\nthe event structures of the following three examples, that is, that in each case Big\nFruit Co. is the AGENT andthe price of bananas is the THEME , despite the differing\nsurface forms.",
    "metadata": {
      "source": "21",
      "chunk_id": 6,
      "token_count": 677,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 6\n\n6CHAPTER 21 \u2022 S EMANTIC ROLE LABELING\n(21.14) [ Arg0 Big Fruit Co. ] increased [ Arg1 the price of bananas].\n(21.15) [ Arg1 The price of bananas] was increased again [ Arg0 by Big Fruit Co. ]\n(21.16) [ Arg1 The price of bananas] increased [ Arg2 5%].\nPropBank also has a number of non-numbered arguments called ArgMs , (ArgM-\nTMP, ArgM-LOC, etc.) which represent modi\ufb01cation or adjunct meanings. These\nare relatively stable across predicates, so aren\u2019t listed with each frame \ufb01le. Data\nlabeled with these modi\ufb01ers can be helpful in training systems to detect temporal,\nlocation, or directional modi\ufb01cation across predicates. Some of the ArgM\u2019s include:\nTMP when? yesterday evening, now\nLOC where? at the museum, in San Francisco\nDIR where to/from? down, to Bangkok\nMNR how? clearly, with much enthusiasm\nPRP/CAU why? because ... , in response to the ruling\nREC themselves, each other\nADV miscellaneous\nPRD secondary predication ...ate the meat raw\nWhile PropBank focuses on verbs, a related project, NomBank (Meyers et al., NomBank\n2004) adds annotations to noun predicates. For example the noun agreement in\nApple\u2019s agreement with IBM would be labeled with Apple as the Arg0 and IBM as\nthe Arg2. This allows semantic role labelers to assign labels to arguments of both\nverbal and nominal predicates.\n21.5 FrameNet\nWhile making inferences about the semantic commonalities across different sen-\ntences with increase is useful, it would be even more useful if we could make such\ninferences in many more situations, across different verbs, and also between verbs\nand nouns. For example, we\u2019d like to extract the similarity among these three sen-\ntences:\n(21.17) [ Arg1 The price of bananas] increased [ Arg2 5%].\n(21.18) [ Arg1 The price of bananas] rose [ Arg2 5%].\n(21.19) There has been a [ Arg2 5%] rise [ Arg1 in the price of bananas].\nNote that the second example uses the different verb rise, and the third example\nuses the noun rather than the verb rise. We\u2019d like a system to recognize that the\nprice of bananas is what went up, and that 5%is the amount it went up, no matter\nwhether the 5%appears as the object of the verb increased or as a nominal modi\ufb01er\nof the noun rise.\nThe FrameNet project is another semantic-role-labeling project that attempts FrameNet\nto address just these kinds of problems (Baker et al. 1998, Fillmore et al. 2003,\nFillmore and Baker 2009, Ruppenhofer et al. 2016). Whereas roles in the PropBank\nproject are speci\ufb01c to an individual verb, roles in the FrameNet project are speci\ufb01c\nto aframe .\nWhat is a frame? Consider the following set of words:\nreservation, \ufb02ight, travel, buy, price, cost, fare, rates, meal, plane\nThere are many individual lexical relations of hyponymy, synonymy, and so on\nbetween many of the words in this list. The resulting set of relations does not,",
    "metadata": {
      "source": "21",
      "chunk_id": 7,
      "token_count": 740,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 7\n\n21.5 \u2022 F RAME NET 7\nhowever, add up to a complete account of how these words are related. They are\nclearly all de\ufb01ned with respect to a coherent chunk of common-sense background\ninformation concerning air travel.\nWe call the holistic background knowledge that unites these words a frame (Fill- frame\nmore, 1985). The idea that groups of words are de\ufb01ned with respect to some back-\nground information is widespread in arti\ufb01cial intelligence and cognitive science,\nwhere besides frame we see related works like a model (Johnson-Laird, 1983), or model\neven script (Schank and Abelson, 1977). script\nA frame in FrameNet is a background knowledge structure that de\ufb01nes a set of\nframe-speci\ufb01c semantic roles, called frame elements , and includes a set of predi- frame elements\ncates that use these roles. Each word evokes a frame and pro\ufb01les some aspect of the\nframe and its elements. The FrameNet dataset includes a set of frames and frame\nelements, the lexical units associated with each frame, and a set of labeled exam-\nple sentences. For example, the change position onascale frame is de\ufb01ned as\nfollows:\nThis frame consists of words that indicate the change of an Item\u2019s posi-\ntion on a scale (the Attribute) from a starting point (Initial value) to an\nend point (Final value).\nSome of the semantic roles (frame elements) in the frame are de\ufb01ned as in\nFig. 21.3. Note that these are separated into core roles , which are frame speci\ufb01c, and core roles\nnon-core roles , which are more like the Arg-M arguments in PropBank, expressing non-core roles\nmore general properties of time, location, and so on.\nCore Roles\nATTRIBUTE The A TTRIBUTE is a scalar property that the I TEM possesses.\nDIFFERENCE The distance by which an I TEM changes its position on the scale.\nFINAL STATE A description that presents the I TEM\u2019s state after the change in the A TTRIBUTE \u2019s\nvalue as an independent predication.\nFINAL VALUE The position on the scale where the I TEM ends up.\nINITIAL STATE A description that presents the I TEM\u2019s state before the change in the A T-\nTRIBUTE \u2019s value as an independent predication.\nINITIAL VALUE The initial position on the scale from which the I TEM moves away.\nITEM The entity that has a position on the scale.\nVALUE RANGE A portion of the scale, typically identi\ufb01ed by its end points, along which the\nvalues of the A TTRIBUTE \ufb02uctuate.\nSome Non-Core Roles\nDURATION The length of time over which the change takes place.\nSPEED The rate of change of the V ALUE .\nGROUP The G ROUP in which an I TEM changes the value of an\nATTRIBUTE in a speci\ufb01ed way.\nFigure 21.3 The frame elements in the change position onascale frame from the FrameNet Labelers\nGuide (Ruppenhofer et al., 2016).\nHere are some example sentences:\n(21.20) [ ITEM Oil]rose [ATTRIBUTE in price] [ DIFFERENCE by 2%].\n(21.21) [ ITEM It] has increased [FINAL STATE to having them 1 day a month].\n(21.22) [ ITEM Microsoft shares] fell[FINAL VALUE to 7 5/8].\n(21.23) [ ITEM Colon cancer incidence] fell[DIFFERENCE by 50%] [ GROUP among\nmen].",
    "metadata": {
      "source": "21",
      "chunk_id": 8,
      "token_count": 763,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 8\n\n8CHAPTER 21 \u2022 S EMANTIC ROLE LABELING\n(21.24) a steady increase [INITIAL VALUE from 9.5] [ FINAL VALUE to 14.3] [ ITEM\nin dividends]\n(21.25) a [ DIFFERENCE 5%] [ ITEM dividend] increase ...\nNote from these example sentences that the frame includes target words like rise,\nfall, and increase . In fact, the complete frame consists of the following words:\nVERBS: dwindle move soar escalation shift\nadvance edge mushroom swell explosion tumble\nclimb explode plummet swing fall\ndecline fall reach triple \ufb02uctuation ADVERBS:\ndecrease \ufb02uctuate rise tumble gain increasingly\ndiminish gain rocket growth\ndip grow shift NOUNS: hike\ndouble increase skyrocket decline increase\ndrop jump slide decrease rise\nFrameNet also codes relationships between frames, allowing frames to inherit\nfrom each other, or representing relations between frames like causation (and gen-\neralizations among frame elements in different frames can be represented by inheri-\ntance as well). Thus, there is a Cause change ofposition onascale frame that is\nlinked to the Change ofposition onascale frame by the cause relation, but that\nadds an A GENT role and is used for causative examples such as the following:\n(21.26) [ AGENT They] raised [ITEM the price of their soda] [ DIFFERENCE by 2%].\nTogether, these two frames would allow an understanding system to extract the\ncommon event semantics of all the verbal and nominal causative and non-causative\nusages.\nFrameNets have also been developed for many other languages including Span-\nish, German, Japanese, Portuguese, Italian, and Chinese.\n21.6 Semantic Role Labeling\nSemantic role labeling (sometimes shortened as SRL ) is the task of automaticallysemantic role\nlabeling\n\ufb01nding the semantic roles of each argument of each predicate in a sentence. Cur-\nrent approaches to semantic role labeling are based on supervised machine learning,\noften using the FrameNet and PropBank resources to specify what counts as a pred-\nicate, de\ufb01ne the set of roles used in the task, and provide training and test sets.\nRecall that the difference between these two models of semantic roles is that\nFrameNet (21.27) employs many frame-speci\ufb01c frame elements as roles, while Prop-\nBank (21.28) uses a smaller number of numbered argument labels that can be inter-\npreted as verb-speci\ufb01c labels, along with the more general ARGM labels. Some\nexamples:\n(21.27)[You] can\u2019t [blame] [the program] [for being unable to identify it]\nCOGNIZER TARGET EVALUEE REASON\n(21.28)[The San Francisco Examiner] issued [a special edition] [yesterday]\nARG0 TARGET ARG 1 ARGM -TMP\n21.6.1 A Feature-based Algorithm for Semantic Role Labeling\nA simpli\ufb01ed feature-based semantic role labeling algorithm is sketched in Fig. 21.4.\nFeature-based algorithms\u2014from the very earliest systems like (Simmons, 1973)\u2014\nbegin by parsing, using broad-coverage parsers to assign a parse to the input string.",
    "metadata": {
      "source": "21",
      "chunk_id": 9,
      "token_count": 689,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 9\n\n21.6 \u2022 S EMANTIC ROLE LABELING 9\nFigure 21.5 shows a parse of (21.28) above. The parse is then traversed to \ufb01nd all\nwords that are predicates.\nFor each of these predicates, the algorithm examines each node in the parse\ntree and uses supervised classi\ufb01cation to decide the semantic role (if any) it plays\nfor this predicate. Given a labeled training set such as PropBank or FrameNet, a\nfeature vector is extracted for each node, using feature templates described in the\nnext subsection. A 1-of-N classi\ufb01er is then trained to predict a semantic role for\neach constituent given these features, where N is the number of potential semantic\nroles plus an extra NONE role for non-role constituents. Any standard classi\ufb01cation\nalgorithms can be used. Finally, for each test sentence to be labeled, the classi\ufb01er is\nrun on each relevant constituent.\nfunction SEMANTIC ROLELABEL (words )returns labeled tree\nparse PARSE (words )\nfor each predicate inparse do\nfor each node inparse do\nfeaturevector EXTRACT FEATURES (node ,predicate ,parse )\nCLASSIFY NODE(node ,featurevector ,parse )\nFigure 21.4 A generic semantic-role-labeling algorithm. C LASSIFY NODE is a 1-of- Nclas-\nsi\ufb01er that assigns a semantic role (or NONE for non-role constituents), trained on labeled data\nsuch as FrameNet or PropBank.\nS\nNP-SBJ =A R G 0 VP\nDT NNP NNP NNP\nThe San Francisco Examiner\nVBD = TARGET NP=A R G 1 PP-TMP =A R G M - T M P\nissued DT JJ NN IN NP\nas p e c i a l e d i t i o n a r o u n d N N N P - T M P\nnoon yesterday\nFigure 21.5 Parse tree for a PropBank sentence, showing the PropBank argument labels. The dotted line\nshows the path feature NP\"S#VP#VBD for ARG0, the NP-SBJ constituent The San Francisco Examiner.\nInstead of training a single-stage classi\ufb01er as in Fig. 21.5, the node-level classi-\n\ufb01cation task can be broken down into multiple steps:\n1.Pruning: Since only a small number of the constituents in a sentence are\narguments of any given predicate, many systems use simple heuristics to prune\nunlikely constituents.\n2.Identi\ufb01cation: a binary classi\ufb01cation of each node as an argument to be la-\nbeled or a NONE .\n3.Classi\ufb01cation: a 1-of- Nclassi\ufb01cation of all the constituents that were labeled\nas arguments by the previous stage",
    "metadata": {
      "source": "21",
      "chunk_id": 10,
      "token_count": 595,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 10\n\n10 CHAPTER 21 \u2022 S EMANTIC ROLE LABELING\nThe separation of identi\ufb01cation and classi\ufb01cation may lead to better use of fea-\ntures (different features may be useful for the two tasks) or to computational ef\ufb01-\nciency.\nGlobal Optimization\nThe classi\ufb01cation algorithm of Fig. 21.5 classi\ufb01es each argument separately (\u2018lo-\ncally\u2019), making the simplifying assumption that each argument of a predicate can be\nlabeled independently. This assumption is false; there are interactions between argu-\nments that require a more \u2018global\u2019 assignment of labels to constituents. For example,\nconstituents in FrameNet and PropBank are required to be non-overlapping. More\nsigni\ufb01cantly, the semantic roles of constituents are not independent. For example\nPropBank does not allow multiple identical arguments; two constituents of the same\nverb cannot both be labeled ARG0 .\nRole labeling systems thus often add a fourth step to deal with global consistency\nacross the labels in a sentence. For example, the local classi\ufb01ers can return a list of\npossible labels associated with probabilities for each constituent, and a second-pass\nViterbi decoding or re-ranking approach can be used to choose the best consensus\nlabel. Integer linear programming (ILP) is another common way to choose a solution\nthat conforms best to multiple constraints.\nFeatures for Semantic Role Labeling\nMost systems use some generalization of the core set of features introduced by\nGildea and Jurafsky (2000). Common basic features templates (demonstrated on\ntheNP-SBJ constituent The San Francisco Examiner in Fig. 21.5) include:\n\u2022 The governing predicate , in this case the verb issued . The predicate is a cru-\ncial feature since labels are de\ufb01ned only with respect to a particular predicate.\n\u2022 The phrase type of the constituent, in this case, NP(orNP-SBJ ). Some se-\nmantic roles tend to appear as NPs, others as SorPP, and so on.\n\u2022 The headword of the constituent, Examiner . The headword of a constituent\ncan be computed with standard head rules, such as those given in Appendix D\nin Fig. ??. Certain headwords (e.g., pronouns) place strong constraints on the\npossible semantic roles they are likely to \ufb01ll.\n\u2022 The headword part of speech of the constituent, NNP .\n\u2022 The path in the parse tree from the constituent to the predicate. This path is\nmarked by the dotted line in Fig. 21.5. Following Gildea and Jurafsky (2000),\nwe can use a simple linear representation of the path, NP \"S#VP#VBD.\"and\n#represent upward and downward movement in the tree, respectively. The\npath is very useful as a compact representation of many kinds of grammatical\nfunction relationships between the constituent and the predicate.\n\u2022 The voice of the clause in which the constituent appears, in this case, active\n(as contrasted with passive ). Passive sentences tend to have strongly different\nlinkings of semantic roles to surface form than do active ones.\n\u2022 The binary linear position of the constituent with respect to the predicate,\neither before orafter .\n\u2022 The subcategorization of the predicate, the set of expected arguments that\nappear in the verb phrase. We can extract this information by using the phrase-\nstructure rule that expands the immediate parent of the predicate; VP !VBD\nNP PP for the predicate in Fig. 21.5.\n\u2022 The named entity type of the constituent.",
    "metadata": {
      "source": "21",
      "chunk_id": 11,
      "token_count": 753,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 11\n\n21.6 \u2022 S EMANTIC ROLE LABELING 11\n\u2022 The \ufb01rst words and the last word of the constituent.\nThe following feature vector thus represents the \ufb01rst NP in our example (recall\nthat most observations will have the value NONE rather than, for example, ARG0,\nsince most constituents in the parse tree will not bear a semantic role):\nARG0: [issued, NP, Examiner, NNP, NP \"S#VP#VBD, active, before, VP !NP PP,\nORG, The, Examiner]\nOther features are often used in addition, such as sets of n-grams inside the\nconstituent, or more complex versions of the path features (the upward or downward\nhalves, or whether particular nodes occur in the path).\nIt\u2019s also possible to use dependency parses instead of constituency parses as the\nbasis of features, for example using dependency parse paths instead of constituency\npaths.\n21.6.2 A Neural Algorithm for Semantic Role Labeling\nA simple neural approach to SRL is to treat it as a sequence labeling task like named-\nentity recognition, using the BIO approach. Let\u2019s assume that we are given the\npredicate and the task is just detecting and labeling spans. Recall that with BIO\ntagging, we have a begin and end tag for each possible role ( B-ARG0,I-ARG0;B-\nARG1,I-ARG1, and so on), plus an outside tag O.\nENCODER[CLS]thecatslovehats[SEP]love[SEP]FFNB-ARG0I-ARG0B-PREDconcatenate with predicateB-ARG1FFNSoftmaxFFNFFNFFN\nFigure 21.6 A simple neural approach to semantic role labeling. The input sentence is\nfollowed by [SEP] and an extra input for the predicate, in this case love. The encoder outputs\nare concatenated to an indicator variable which is 1 for the predicate and 0 for all other words\nAfter He et al. (2017) and Shi and Lin (2019).\nAs with all the taggers, the goal is to compute the highest probability tag se-\nquence \u02c6 y, given the input sequence of words w:\n\u02c6y=argmax\ny2TP(yjw)\nFig. 21.6 shows a sketch of a standard algorithm from He et al. (2017). Here each\ninput word is mapped to pretrained embeddings, and then each token is concatenated\nwith the predicate embedding and then passed through a feedforward network with\na softmax which outputs a distribution over each SRL label. For decoding, a CRF\nlayer can be used instead of the MLP layer on top of the biLSTM output to do global\ninference, but in practice this doesn\u2019t seem to provide much bene\ufb01t.",
    "metadata": {
      "source": "21",
      "chunk_id": 12,
      "token_count": 594,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 12\n\n12 CHAPTER 21 \u2022 S EMANTIC ROLE LABELING\n21.6.3 Evaluation of Semantic Role Labeling\nThe standard evaluation for semantic role labeling is to require that each argument\nlabel must be assigned to the exactly correct word sequence or parse constituent, and\nthen compute precision, recall, and F-measure. Identi\ufb01cation and classi\ufb01cation can\nalso be evaluated separately. Two common datasets used for evaluation are CoNLL-\n2005 (Carreras and M `arquez, 2005) and CoNLL-2012 (Pradhan et al., 2013).\n21.7 Selectional Restrictions\nWe turn in this section to another way to represent facts about the relationship be-\ntween predicates and arguments. A selectional restriction is a semantic type con-selectional\nrestriction\nstraint that a verb imposes on the kind of concepts that are allowed to \ufb01ll its argument\nroles. Consider the two meanings associated with the following example:\n(21.29) I want to eat someplace nearby.\nThere are two possible parses and semantic interpretations for this sentence. In\nthe sensible interpretation, eatis intransitive and the phrase someplace nearby is\nan adjunct that gives the location of the eating event. In the nonsensical speaker-as-\nGodzilla interpretation, eatis transitive and the phrase someplace nearby is the direct\nobject and the THEME of the eating, like the NP Malaysian food in the following\nsentences:\n(21.30) I want to eat Malaysian food.\nHow do we know that someplace nearby isn\u2019t the direct object in this sentence?\nOne useful cue is the semantic fact that the THEME of E ATING events tends to be\nsomething that is edible . This restriction placed by the verb eaton the \ufb01ller of its\nTHEME argument is a selectional restriction.\nSelectional restrictions are associated with senses, not entire lexemes. We can\nsee this in the following examples of the lexeme serve :\n(21.31) The restaurant serves green-lipped mussels.\n(21.32) Which airlines serve Denver?\nExample (21.31) illustrates the offering-food sense of serve , which ordinarily re-\nstricts its THEME to be some kind of food Example (21.32) illustrates the provides a\ncommercial service to sense of serve , which constrains its THEME to be some type\nof appropriate location.\nSelectional restrictions vary widely in their speci\ufb01city. The verb imagine , for\nexample, imposes strict requirements on its AGENT role (restricting it to humans\nand other animate entities) but places very few semantic requirements on its THEME\nrole. A verb like diagonalize , on the other hand, places a very speci\ufb01c constraint\non the \ufb01ller of its THEME role: it has to be a matrix, while the arguments of the\nadjective odorless are restricted to concepts that could possess an odor:\n(21.33) In rehearsal, I often ask the musicians to imagine a tennis game.\n(21.34) Radon is an odorless gas that can\u2019t be detected by human senses.\n(21.35) To diagonalize a matrix is to \ufb01nd its eigenvalues.\nThese examples illustrate that the set of concepts we need to represent selectional\nrestrictions (being a matrix, being able to possess an odor, etc) is quite open ended.\nThis distinguishes selectional restrictions from other features for representing lexical\nknowledge, like parts-of-speech, which are quite limited in number.",
    "metadata": {
      "source": "21",
      "chunk_id": 13,
      "token_count": 733,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 13\n\n21.7 \u2022 S ELECTIONAL RESTRICTIONS 13\n21.7.1 Representing Selectional Restrictions\nOne way to capture the semantics of selectional restrictions is to use and extend the\nevent representation of Appendix F. Recall that the neo-Davidsonian representation\nof an event consists of a single variable that stands for the event, a predicate denoting\nthe kind of event, and variables and relations for the event roles. Ignoring the issue of\nthel-structures and using thematic roles rather than deep event roles, the semantic\ncontribution of a verb like eatmight look like the following:\n9e;x;y Eating (e)^Agent (e;x)^T heme (e;y)\nWith this representation, all we know about y, the \ufb01ller of the THEME role, is that\nit is associated with an Eating event through the Theme relation. To stipulate the\nselectional restriction that ymust be something edible, we simply add a new term to\nthat effect:\n9e;x;y Eating (e)^Agent (e;x)^T heme (e;y)^EdibleT hing (y)\nWhen a phrase like ate a hamburger is encountered, a semantic analyzer can form\nthe following kind of representation:\n9e;x;y Eating (e)^Eater (e;x)^T heme (e;y)^EdibleT hing (y)^Hamburger (y)\nThis representation is perfectly reasonable since the membership of yin the category\nHamburger is consistent with its membership in the category EdibleThing , assuming\na reasonable set of facts in the knowledge base. Correspondingly, the representation\nfor a phrase such as ate a takeoff would be ill-formed because membership in an\nevent-like category such as Takeoff would be inconsistent with membership in the\ncategory EdibleThing .\nWhile this approach adequately captures the semantics of selectional restrictions,\nthere are two problems with its direct use. First, using FOL to perform the simple\ntask of enforcing selectional restrictions is overkill. Other, far simpler, formalisms\ncan do the job with far less computational cost. The second problem is that this\napproach presupposes a large, logical knowledge base of facts about the concepts\nthat make up selectional restrictions. Unfortunately, although such common-sense\nknowledge bases are being developed, none currently have the kind of coverage\nnecessary to the task.\nA more practical approach is to state selectional restrictions in terms of WordNet\nsynsets rather than as logical concepts. Each predicate simply speci\ufb01es a WordNet\nsynset as the selectional restriction on each of its arguments. A meaning representa-\ntion is well-formed if the role \ufb01ller word is a hyponym (subordinate) of this synset.\nFor our ate a hamburger example, for instance, we could set the selectional\nrestriction on the THEME role of the verb eatto the synset ffood, nutrient g, glossed\nasany substance that can be metabolized by an animal to give energy and build\ntissue . Luckily, the chain of hypernyms for hamburger shown in Fig. 21.7 reveals\nthat hamburgers are indeed food. Again, the \ufb01ller of a role need not match the\nrestriction synset exactly; it just needs to have the synset as one of its superordinates.\nWe can apply this approach to the THEME roles of the verbs imagine ,lift, and di-\nagonalize , discussed earlier. Let us restrict imagine \u2019sTHEME to the synsetfentityg,\nlift\u2019sTHEME tofphysical entityg, and diagonalize tofmatrixg. This arrangement\ncorrectly permits imagine a hamburger andlift a hamburger , while also correctly\nruling out diagonalize a hamburger .",
    "metadata": {
      "source": "21",
      "chunk_id": 14,
      "token_count": 778,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 14\n\n14 CHAPTER 21 \u2022 S EMANTIC ROLE LABELING\nSense 1\nhamburger, beefburger --\n(a fried cake of minced beef served on a bun)\n=> sandwich\n=> snack food\n=> dish\n=> nutriment, nourishment, nutrition...\n=> food, nutrient\n=> substance\n=> matter\n=> physical entity\n=> entity\nFigure 21.7 Evidence from WordNet that hamburgers are edible.\n21.7.2 Selectional Preferences\nIn the earliest implementations, selectional restrictions were considered strict con-\nstraints on the kind of arguments a predicate could take (Katz and Fodor 1963,\nHirst 1987). For example, the verb eatmight require that its THEME argument\nbe[+FOOD] . Early word sense disambiguation systems used this idea to rule out\nsenses that violated the selectional restrictions of their governing predicates.\nVery quickly, however, it became clear that these selectional restrictions were\nbetter represented as preferences rather than strict constraints (Wilks 1975b, Wilks\n1975a). For example, selectional restriction violations (like inedible arguments of\neat) often occur in well-formed sentences, for example because they are negated\n(21.36), or because selectional restrictions are overstated (21.37):\n(21.36) But it fell apart in 1931, perhaps because people realized you can\u2019t eat\ngold for lunch if you\u2019re hungry.\n(21.37) In his two championship trials, Mr. Kulkarni ateglass on an empty\nstomach, accompanied only by water and tea.\nModern systems for selectional preferences therefore specify the relation be-\ntween a predicate and its possible arguments with soft constraints of some kind.\nSelectional Association\nOne of the most in\ufb02uential has been the selectional association model of Resnik\n(1993). Resnik de\ufb01nes the idea of selectional preference strength as the generalselectional\npreference\nstrengthamount of information that a predicate tells us about the semantic class of its argu-\nments. For example, the verb eattells us a lot about the semantic class of its direct\nobjects, since they tend to be edible. The verb be, by contrast, tells us less about\nits direct objects. The selectional preference strength can be de\ufb01ned by the differ-\nence in information between two distributions: the distribution of expected semantic\nclasses P(c)(how likely is it that a direct object will fall into class c) and the dis-\ntribution of expected semantic classes for the particular verb P(cjv)(how likely is\nit that the direct object of the speci\ufb01c verb vwill fall into semantic class c). The\ngreater the difference between these distributions, the more information the verb\nis giving us about possible objects. The difference between these two distributions\ncan be quanti\ufb01ed by relative entropy , or the Kullback-Leibler divergence (Kullback relative entropy\nand Leibler, 1951). The Kullback-Leibler or KL divergence D(PjjQ)expresses the KL divergence",
    "metadata": {
      "source": "21",
      "chunk_id": 15,
      "token_count": 659,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 15\n\n21.7 \u2022 S ELECTIONAL RESTRICTIONS 15\ndifference between two probability distributions PandQ\nD(PjjQ) =X\nxP(x)logP(x)\nQ(x)(21.38)\nThe selectional preference SR(v)uses the KL divergence to express how much in-\nformation, in bits, the verb vexpresses about the possible semantic class of its argu-\nment.\nSR(v) = D(P(cjv)jjP(c))\n=X\ncP(cjv)logP(cjv)\nP(c)(21.39)\nResnik then de\ufb01nes the selectional association of a particular class and verb as theselectional\nassociation\nrelative contribution of that class to the general selectional preference of the verb:\nAR(v;c) =1\nSR(v)P(cjv)logP(cjv)\nP(c)(21.40)\nThe selectional association is thus a probabilistic measure of the strength of asso-\nciation between a predicate and a class dominating the argument to the predicate.\nResnik estimates the probabilities for these associations by parsing a corpus, count-\ning all the times each predicate occurs with each argument word, and assuming\nthat each word is a partial observation of all the WordNet concepts containing the\nword. The following table from Resnik (1996) shows some sample high and low\nselectional associations for verbs and some WordNet semantic classes of their direct\nobjects.\nDirect Object Direct Object\nVerb Semantic Class Assoc Semantic Class Assoc\nread WRITING 6.80 ACTIVITY -.20\nwrite WRITING 7.26 COMMERCE 0\nsee ENTITY 5.79 METHOD -0.01\nSelectional Preference via Conditional Probability\nAn alternative to using selectional association between a verb and the WordNet class\nof its arguments is to use the conditional probability of an argument word given a\npredicate verb, directly modeling the strength of association of one verb (predicate)\nwith one noun (argument).\nThe conditional probability model can be computed by parsing a very large cor-\npus (billions of words), and computing co-occurrence counts: how often a given\nverb occurs with a given noun in a given relation. The conditional probability of an\nargument noun given a verb for a particular relation P(njv;r)can then be used as a\nselectional preference metric for that pair of words (Brockmann and Lapata 2003,\nKeller and Lapata 2003):\nP(njv;r) =(\nC(n;v;r)\nC(v;r)ifC(n;v;r)>0\n0 otherwise\nThe inverse probability P(vjn;r)was found to have better performance in some cases\n(Brockmann and Lapata, 2003):\nP(vjn;r) =(\nC(n;v;r)\nC(n;r)ifC(n;v;r)>0\n0 otherwise",
    "metadata": {
      "source": "21",
      "chunk_id": 16,
      "token_count": 606,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 16\n\n16 CHAPTER 21 \u2022 S EMANTIC ROLE LABELING\nAn even simpler approach is to use the simple log co-occurrence frequency of\nthe predicate with the argument log count (v;n;r)instead of conditional probability;\nthis seems to do better for extracting preferences for syntactic subjects rather than\nobjects (Brockmann and Lapata, 2003).\nEvaluating Selectional Preferences\nOne way to evaluate models of selectional preferences is to use pseudowords (Gale pseudowords\net al. 1992, Sch \u00a8utze 1992). A pseudoword is an arti\ufb01cial word created by concate-\nnating a test word in some context (say banana ) with a confounder word (say door )\nto create banana-door ). The task of the system is to identify which of the two words\nis the original word. To evaluate a selectional preference model (for example on the\nrelationship between a verb and a direct object) we take a test corpus and select all\nverb tokens. For each verb token (say drive ) we select the direct object (e.g., car),\nconcatenated with a confounder word that is its nearest neighbor , the noun with the\nfrequency closest to the original (say house ), to make car/house ). We then use the\nselectional preference model to choose which of carandhouse are more preferred\nobjects of drive , and compute how often the model chooses the correct original ob-\nject (e.g., car) (Chambers and Jurafsky, 2010).\nAnother evaluation metric is to get human preferences for a test set of verb-\nargument pairs, and have them rate their degree of plausibility. This is usually done\nby using magnitude estimation, a technique from psychophysics, in which subjects\nrate the plausibility of an argument proportional to a modulus item. A selectional\npreference model can then be evaluated by its correlation with the human prefer-\nences (Keller and Lapata, 2003).\n21.8 Primitive Decomposition of Predicates\nOne way of thinking about the semantic roles we have discussed through the chapter\nis that they help us de\ufb01ne the roles that arguments play in a decompositional way,\nbased on \ufb01nite lists of thematic roles (agent, patient, instrument, proto-agent, proto-\npatient, etc.). This idea of decomposing meaning into sets of primitive semantic\nelements or features, called primitive decomposition orcomponential analysis ,componential\nanalysis\nhas been taken even further, and focused particularly on predicates.\nConsider these examples of the verb kill:\n(21.41) Jim killed his philodendron.\n(21.42) Jim did something to cause his philodendron to become not alive.\nThere is a truth-conditional (\u2018propositional semantics\u2019) perspective from which these\ntwo sentences have the same meaning. Assuming this equivalence, we could repre-\nsent the meaning of killas:\n(21.43) KILL (x,y),CAUSE (x,BECOME (NOT(ALIVE (y))))\nthus using semantic primitives like do,cause ,become not , and alive .\nIndeed, one such set of potential semantic primitives has been used to account\nfor some of the verbal alternations discussed in Section 21.2 (Lakoff 1965, Dowty\n1979). Consider the following examples.\n(21.44) John opened the door. )CAUSE (John, BECOME (OPEN (door)))\n(21.45) The door opened. )BECOME (OPEN (door))",
    "metadata": {
      "source": "21",
      "chunk_id": 17,
      "token_count": 749,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 17\n\n21.9 \u2022 S UMMARY 17\n(21.46) The door is open. )OPEN (door)\nThe decompositional approach asserts that a single state-like predicate associ-\nated with open underlies all of these examples. The differences among the meanings\nof these examples arises from the combination of this single predicate with the prim-\nitives CAUSE and BECOME .\nWhile this approach to primitive decomposition can explain the similarity be-\ntween states and actions or causative and non-causative predicates, it still relies on\nhaving a large number of predicates like open . More radical approaches choose to\nbreak down these predicates as well. One such approach to verbal predicate decom-\nposition that played a role in early natural language systems is conceptual depen-\ndency (CD), a set of ten primitive predicates, shown in Fig. 21.8.conceptual\ndependency\nPrimitive De\ufb01nition\nATRANS The abstract transfer of possession or control from one entity to\nanother\nPTRANS The physical transfer of an object from one location to another\nMTRANS The transfer of mental concepts between entities or within an\nentity\nMBUILD The creation of new information within an entity\nPROPEL The application of physical force to move an object\nMOVE The integral movement of a body part by an animal\nINGEST The taking in of a substance by an animal\nEXPEL The expulsion of something from an animal\nSPEAK The action of producing a sound\nATTEND The action of focusing a sense organ\nFigure 21.8 A set of conceptual dependency primitives.\nBelow is an example sentence along with its CDrepresentation. The verb brought\nis translated into the two primitives ATRANS and PTRANS to indicate that the waiter\nboth physically conveyed the check to Mary and passed control of it to her. Note\nthat CDalso associates a \ufb01xed set of thematic roles with each primitive to represent\nthe various participants in the action.\n(21.47) The waiter brought Mary the check.\n9x;y Atrans (x)^Actor (x;Waiter )^Ob ject (x;Check )^To(x;Mary )\n^Ptrans (y)^Actor (y;Waiter )^Ob ject (y;Check )^To(y;Mary )\n21.9 Summary\n\u2022Semantic roles are abstract models of the role an argument plays in the event\ndescribed by the predicate.\n\u2022Thematic roles are a model of semantic roles based on a single \ufb01nite list of\nroles. Other semantic role models include per-verb semantic role lists and\nproto-agent /proto-patient , both of which are implemented in PropBank ,\nand per-frame role lists, implemented in FrameNet .",
    "metadata": {
      "source": "21",
      "chunk_id": 18,
      "token_count": 563,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 18\n\n18 CHAPTER 21 \u2022 S EMANTIC ROLE LABELING\n\u2022Semantic role labeling is the task of assigning semantic role labels to the\nconstituents of a sentence. The task is generally treated as a supervised ma-\nchine learning task, with models trained on PropBank or FrameNet. Algo-\nrithms generally start by parsing a sentence and then automatically tag each\nparse tree node with a semantic role. Neural models map straight from words\nend-to-end.\n\u2022 Semantic selectional restrictions allow words (particularly predicates) to post\nconstraints on the semantic properties of their argument words. Selectional\npreference models (like selectional association or simple conditional proba-\nbility) allow a weight or probability to be assigned to the association between\na predicate and an argument word or class.\nBibliographical and Historical Notes\nAlthough the idea of semantic roles dates back to P \u00afan.ini, they were re-introduced\ninto modern linguistics by Gruber (1965), Fillmore (1966) and Fillmore (1968). Fill-\nmore had become interested in argument structure by studying Lucien Tesni `ere\u2019s\ngroundbreaking \u00b4El\u00b4ements de Syntaxe Structurale (Tesni `ere, 1959) in which the term\n\u2018dependency\u2019 was introduced and the foundations were laid for dependency gram-\nmar. Following Tesni `ere\u2019s terminology, Fillmore \ufb01rst referred to argument roles as\nactants (Fillmore, 1966) but quickly switched to the term case, (see Fillmore (2003))\nand proposed a universal list of semantic roles or cases (Agent, Patient, Instrument,\netc.), that could be taken on by the arguments of predicates. Verbs would be listed in\nthe lexicon with their case frame , the list of obligatory (or optional) case arguments.\nThe idea that semantic roles could provide an intermediate level of semantic\nrepresentation that could help map from syntactic parse structures to deeper, more\nfully-speci\ufb01ed representations of meaning was quickly adopted in natural language\nprocessing, and systems for extracting case frames were created for machine transla-\ntion (Wilks, 1973), question-answering (Hendrix et al., 1973), spoken-language pro-\ncessing (Nash-Webber, 1975), and dialogue systems (Bobrow et al., 1977). General-\npurpose semantic role labelers were developed. The earliest ones (Simmons, 1973)\n\ufb01rst parsed a sentence by means of an ATN (Augmented Transition Network) parser.\nEach verb then had a set of rules specifying how the parse should be mapped to se-\nmantic roles. These rules mainly made reference to grammatical functions (subject,\nobject, complement of speci\ufb01c prepositions) but also checked constituent internal\nfeatures such as the animacy of head nouns. Later systems assigned roles from pre-\nbuilt parse trees, again by using dictionaries with verb-speci\ufb01c case frames (Levin\n1977, Marcus 1980).\nBy 1977 case representation was widely used and taught in AI and NLP courses,\nand was described as a standard of natural language processing in the \ufb01rst edition of\nWinston\u2019s 1977 textbook Arti\ufb01cial Intelligence .\nIn the 1980s Fillmore proposed his model of frame semantics , later describing\nthe intuition as follows:\n\u201cThe idea behind frame semantics is that speakers are aware of possi-\nbly quite complex situation types, packages of connected expectations,\nthat go by various names\u2014frames, schemas, scenarios, scripts, cultural\nnarratives, memes\u2014and the words in our language are understood with\nsuch frames as their presupposed background.\u201d (Fillmore, 2012, p. 712)",
    "metadata": {
      "source": "21",
      "chunk_id": 19,
      "token_count": 787,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 19",
    "metadata": {
      "source": "21",
      "chunk_id": 20,
      "token_count": 4,
      "chapter_title": ""
    }
  },
  {
    "content": "BIBLIOGRAPHICAL AND HISTORICAL NOTES 19\nThe word frame seemed to be in the air for a suite of related notions proposed at\nabout the same time by Minsky (1974), Hymes (1974), and Goffman (1974), as\nwell as related notions with other names like scripts (Schank and Abelson, 1975)\nandschemata (Bobrow and Norman, 1975) (see Tannen (1979) for a comparison).\nFillmore was also in\ufb02uenced by the semantic \ufb01eld theorists and by a visit to the Yale\nAI lab where he took notice of the lists of slots and \ufb01llers used by early information\nextraction systems like DeJong (1982) and Schank and Abelson (1977). In the 1990s\nFillmore drew on these insights to begin the FrameNet corpus annotation project.\nAt the same time, Beth Levin drew on her early case frame dictionaries (Levin,\n1977) to develop her book which summarized sets of verb classes de\ufb01ned by shared\nargument realizations (Levin, 1993). The VerbNet project built on this work (Kipper\net al., 2000), leading soon afterwards to the PropBank semantic-role-labeled corpus\ncreated by Martha Palmer and colleagues (Palmer et al., 2005).\nThe combination of rich linguistic annotation and corpus-based approach in-\nstantiated in FrameNet and PropBank led to a revival of automatic approaches to\nsemantic role labeling, \ufb01rst on FrameNet (Gildea and Jurafsky, 2000) and then on\nPropBank data (Gildea and Palmer, 2002, inter alia). The problem \ufb01rst addressed in\nthe 1970s by handwritten rules was thus now generally recast as one of supervised\nmachine learning enabled by large and consistent databases. Many popular features\nused for role labeling are de\ufb01ned in Gildea and Jurafsky (2002), Surdeanu et al.\n(2003), Xue and Palmer (2004), Pradhan et al. (2005), Che et al. (2009), and Zhao\net al. (2009). The use of dependency rather than constituency parses was introduced\nin the CoNLL-2008 shared task (Surdeanu et al., 2008). For surveys see Palmer\net al. (2010) and M `arquez et al. (2008).\nThe use of neural approaches to semantic role labeling was pioneered by Col-\nlobert et al. (2011), who applied a CRF on top of a convolutional net. Early work\nlike Foland, Jr. and Martin (2015) focused on using dependency features. Later work\neschewed syntactic features altogether; Zhou and Xu (2015) introduced the use of\na stacked (6-8 layer) biLSTM architecture, and (He et al., 2017) showed how to\naugment the biLSTM architecture with highway networks and also replace the CRF\nwith A* decoding that make it possible to apply a wide variety of global constraints\nin SRL decoding.\nMost semantic role labeling schemes only work within a single sentence, fo-\ncusing on the object of the verbal (or nominal, in the case of NomBank) predicate.\nHowever, in many cases, a verbal or nominal predicate may have an implicit argu-\nment : one that appears only in a contextual sentence, or perhaps not at all and mustimplicit\nargument\nbe inferred. In the two sentences This house has a new owner. The sale was \ufb01nalized",
    "metadata": {
      "source": "21",
      "chunk_id": 21,
      "token_count": 772,
      "chapter_title": ""
    }
  },
  {
    "content": "in the CoNLL-2008 shared task (Surdeanu et al., 2008). For surveys see Palmer\net al. (2010) and M `arquez et al. (2008).\nThe use of neural approaches to semantic role labeling was pioneered by Col-\nlobert et al. (2011), who applied a CRF on top of a convolutional net. Early work\nlike Foland, Jr. and Martin (2015) focused on using dependency features. Later work\neschewed syntactic features altogether; Zhou and Xu (2015) introduced the use of\na stacked (6-8 layer) biLSTM architecture, and (He et al., 2017) showed how to\naugment the biLSTM architecture with highway networks and also replace the CRF\nwith A* decoding that make it possible to apply a wide variety of global constraints\nin SRL decoding.\nMost semantic role labeling schemes only work within a single sentence, fo-\ncusing on the object of the verbal (or nominal, in the case of NomBank) predicate.\nHowever, in many cases, a verbal or nominal predicate may have an implicit argu-\nment : one that appears only in a contextual sentence, or perhaps not at all and mustimplicit\nargument\nbe inferred. In the two sentences This house has a new owner. The sale was \ufb01nalized\n10 days ago. thesale in the second sentence has no A RG1, but a reasonable reader\nwould infer that the Arg1 should be the house mentioned in the prior sentence. Find-\ning these arguments, implicit argument detection (sometimes shortened as iSRL ) iSRL\nwas introduced by Gerber and Chai (2010) and Ruppenhofer et al. (2010). See Do\net al. (2017) for more recent neural models.\nTo avoid the need for huge labeled training sets, unsupervised approaches for\nsemantic role labeling attempt to induce the set of semantic roles by clustering over\narguments. The task was pioneered by Riloff and Schmelzenbach (1998) and Swier\nand Stevenson (2004); see Grenager and Manning (2006), Titov and Klementiev\n(2012), Lang and Lapata (2014), Woodsend and Lapata (2015), and Titov and Khod-\ndam (2014).\nRecent innovations in frame labeling include connotation frames , which mark\nricher information about the argument of predicates. Connotation frames mark the",
    "metadata": {
      "source": "21",
      "chunk_id": 22,
      "token_count": 522,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 20\n\n20 CHAPTER 21 \u2022 S EMANTIC ROLE LABELING\nsentiment of the writer or reader toward the arguments (for example using the verb\nsurvive inhe survived a bombing expresses the writer\u2019s sympathy toward the subject\nheand negative sentiment toward the bombing. See Chapter 22 for more details.\nSelectional preference has been widely studied beyond the selectional associa-\ntion models of Resnik (1993) and Resnik (1996). Methods have included clustering\n(Rooth et al., 1999), discriminative learning (Bergsma et al., 2008), and topic mod-\nels (S \u00b4eaghdha 2010, Ritter et al. 2010), and constraints can be expressed at the level\nof words or classes (Agirre and Martinez, 2001). Selectional preferences have also\nbeen successfully integrated into semantic role labeling (Erk 2007, Zapirain et al.\n2013, Do et al. 2017).\nExercises",
    "metadata": {
      "source": "21",
      "chunk_id": 23,
      "token_count": 216,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 21",
    "metadata": {
      "source": "21",
      "chunk_id": 24,
      "token_count": 4,
      "chapter_title": ""
    }
  },
  {
    "content": "Exercises 21\nAgirre, E. and D. Martinez. 2001. Learning class-to-class\nselectional preferences. CoNLL .\nBaker, C. F., C. J. Fillmore, and J. B. Lowe. 1998. The Berke-\nley FrameNet project. COLING/ACL .\nBergsma, S., D. Lin, and R. Goebel. 2008. Discriminative\nlearning of selectional preference from unlabeled text.\nEMNLP .\nBloom\ufb01eld, L. 1933. Language . University of Chicago\nPress.\nBobrow, D. G., R. M. Kaplan, M. Kay, D. A. Norman,\nH. Thompson, and T. Winograd. 1977. GUS, A frame\ndriven dialog system. Arti\ufb01cial Intelligence , 8:155\u2013173.\nBobrow, D. G. and D. A. Norman. 1975. Some principles of\nmemory schemata. In D. G. Bobrow and A. Collins, eds,\nRepresentation and Understanding . Academic Press.\nBrockmann, C. and M. Lapata. 2003. Evaluating and com-\nbining approaches to selectional preference acquisition.\nEACL .\nCarreras, X. and L. M `arquez. 2005. Introduction to\nthe CoNLL-2005 shared task: Semantic role labeling.\nCoNLL .\nChambers, N. and D. Jurafsky. 2010. Improving the use\nof pseudo-words for evaluating selectional preferences.\nACL.\nChe, W., Z. Li, Y . Li, Y . Guo, B. Qin, and T. Liu. 2009. Mul-\ntilingual dependency-based syntactic and semantic pars-\ning. CoNLL .\nCollobert, R., J. Weston, L. Bottou, M. Karlen,\nK. Kavukcuoglu, and P. Kuksa. 2011. Natural language\nprocessing (almost) from scratch. JMLR , 12:2493\u20132537.\nDeJong, G. F. 1982. An overview of the FRUMP system.\nIn W. G. Lehnert and M. H. Ringle, eds, Strategies for\nNatural Language Processing , 149\u2013176. LEA.\nDo, Q. N. T., S. Bethard, and M.-F. Moens. 2017. Improv-\ning implicit semantic role labeling by predicting semantic\nframe arguments. IJCNLP .\nDowty, D. R. 1979. Word Meaning and Montague Grammar .\nD. Reidel.\nErk, K. 2007. A simple, similarity-based model for selec-\ntional preferences. ACL.\nFillmore, C. J. 1966. A proposal concerning English prepo-\nsitions. In F. P. Dinneen, ed., 17th annual Round Table ,\nvolume 17 of Monograph Series on Language and Lin-\nguistics , 19\u201334. Georgetown University Press.\nFillmore, C. J. 1968. The case for case. In E. W. Bach and\nR. T. Harms, eds, Universals in Linguistic Theory , 1\u201388.\nHolt, Rinehart & Winston.\nFillmore, C. J. 1985. Frames and the semantics of under-\nstanding. Quaderni di Semantica , VI(2):222\u2013254.",
    "metadata": {
      "source": "21",
      "chunk_id": 25,
      "token_count": 759,
      "chapter_title": ""
    }
  },
  {
    "content": "In W. G. Lehnert and M. H. Ringle, eds, Strategies for\nNatural Language Processing , 149\u2013176. LEA.\nDo, Q. N. T., S. Bethard, and M.-F. Moens. 2017. Improv-\ning implicit semantic role labeling by predicting semantic\nframe arguments. IJCNLP .\nDowty, D. R. 1979. Word Meaning and Montague Grammar .\nD. Reidel.\nErk, K. 2007. A simple, similarity-based model for selec-\ntional preferences. ACL.\nFillmore, C. J. 1966. A proposal concerning English prepo-\nsitions. In F. P. Dinneen, ed., 17th annual Round Table ,\nvolume 17 of Monograph Series on Language and Lin-\nguistics , 19\u201334. Georgetown University Press.\nFillmore, C. J. 1968. The case for case. In E. W. Bach and\nR. T. Harms, eds, Universals in Linguistic Theory , 1\u201388.\nHolt, Rinehart & Winston.\nFillmore, C. J. 1985. Frames and the semantics of under-\nstanding. Quaderni di Semantica , VI(2):222\u2013254.\nFillmore, C. J. 2003. Valency and semantic roles: the con-\ncept of deep structure case. In V . Agel, L. M. Eichinger,\nH. W. Eroms, P. Hellwig, H. J. Heringer, and H. Lobin,\neds, Dependenz und Valenz: Ein internationales Hand-\nbuch der zeitgen \u00a8ossischen Forschung , chapter 36, 457\u2013\n475. Walter de Gruyter.\nFillmore, C. J. 2012. ACL lifetime achievement award:\nEncounters with language. Computational Linguistics ,\n38(4):701\u2013718.Fillmore, C. J. and C. F. Baker. 2009. A frames approach\nto semantic analysis. In B. Heine and H. Narrog, eds,\nThe Oxford Handbook of Linguistic Analysis , 313\u2013340.\nOxford University Press.\nFillmore, C. J., C. R. Johnson, and M. R. L. Petruck. 2003.\nBackground to FrameNet. International journal of lexi-\ncography , 16(3):235\u2013250.\nFoland, Jr., W. R. and J. H. Martin. 2015. Dependency-\nbased semantic role labeling using convolutional neural\nnetworks. *SEM 2015 .\nGale, W. A., K. W. Church, and D. Yarowsky. 1992. Work on\nstatistical methods for word sense disambiguation. AAAI\nFall Symposium on Probabilistic Approaches to Natural\nLanguage .\nGerber, M. and J. Y . Chai. 2010. Beyond nombank: A study\nof implicit arguments for nominal predicates. ACL.\nGildea, D. and D. Jurafsky. 2000. Automatic labeling of se-\nmantic roles. ACL.\nGildea, D. and D. Jurafsky. 2002. Automatic labeling of se-\nmantic roles. Computational Linguistics , 28(3):245\u2013288.\nGildea, D. and M. Palmer. 2002. The necessity of syntactic\nparsing for predicate argument recognition. ACL.",
    "metadata": {
      "source": "21",
      "chunk_id": 26,
      "token_count": 755,
      "chapter_title": ""
    }
  },
  {
    "content": "Oxford University Press.\nFillmore, C. J., C. R. Johnson, and M. R. L. Petruck. 2003.\nBackground to FrameNet. International journal of lexi-\ncography , 16(3):235\u2013250.\nFoland, Jr., W. R. and J. H. Martin. 2015. Dependency-\nbased semantic role labeling using convolutional neural\nnetworks. *SEM 2015 .\nGale, W. A., K. W. Church, and D. Yarowsky. 1992. Work on\nstatistical methods for word sense disambiguation. AAAI\nFall Symposium on Probabilistic Approaches to Natural\nLanguage .\nGerber, M. and J. Y . Chai. 2010. Beyond nombank: A study\nof implicit arguments for nominal predicates. ACL.\nGildea, D. and D. Jurafsky. 2000. Automatic labeling of se-\nmantic roles. ACL.\nGildea, D. and D. Jurafsky. 2002. Automatic labeling of se-\nmantic roles. Computational Linguistics , 28(3):245\u2013288.\nGildea, D. and M. Palmer. 2002. The necessity of syntactic\nparsing for predicate argument recognition. ACL.\nGoffman, E. 1974. Frame analysis: An essay on the organi-\nzation of experience . Harvard University Press.\nGrenager, T. and C. D. Manning. 2006. Unsupervised dis-\ncovery of a statistical verb lexicon. EMNLP .\nGruber, J. S. 1965. Studies in Lexical Relations . Ph.D. thesis,\nMIT.\nHe, L., K. Lee, M. Lewis, and L. Zettlemoyer. 2017. Deep\nsemantic role labeling: What works and what\u2019s next.\nACL.\nHendrix, G. G., C. W. Thompson, and J. Slocum. 1973. Lan-\nguage processing via canonical verbs and semantic mod-\nels.Proceedings of IJCAI-73 .\nHirst, G. 1987. Semantic Interpretation and the Resolution\nof Ambiguity . Cambridge University Press.\nHymes, D. 1974. Ways of speaking. In R. Bauman and\nJ. Sherzer, eds, Explorations in the ethnography of speak-\ning, 433\u2013451. Cambridge University Press.\nJohnson-Laird, P. N. 1983. Mental Models . Harvard Univer-\nsity Press, Cambridge, MA.\nKatz, J. J. and J. A. Fodor. 1963. The structure of a semantic\ntheory. Language , 39:170\u2013210.\nKeller, F. and M. Lapata. 2003. Using the web to obtain fre-\nquencies for unseen bigrams. Computational Linguistics ,\n29:459\u2013484.\nKipper, K., H. T. Dang, and M. Palmer. 2000. Class-based\nconstruction of a verb lexicon. AAAI .\nKullback, S. and R. A. Leibler. 1951. On information and\nsuf\ufb01ciency. Annals of Mathematical Statistics , 22:79\u201386.\nLakoff, G. 1965. On the Nature of Syntactic Irregularity .\nPh.D. thesis, Indiana University. Published as Irregularity",
    "metadata": {
      "source": "21",
      "chunk_id": 27,
      "token_count": 744,
      "chapter_title": ""
    }
  },
  {
    "content": "of Ambiguity . Cambridge University Press.\nHymes, D. 1974. Ways of speaking. In R. Bauman and\nJ. Sherzer, eds, Explorations in the ethnography of speak-\ning, 433\u2013451. Cambridge University Press.\nJohnson-Laird, P. N. 1983. Mental Models . Harvard Univer-\nsity Press, Cambridge, MA.\nKatz, J. J. and J. A. Fodor. 1963. The structure of a semantic\ntheory. Language , 39:170\u2013210.\nKeller, F. and M. Lapata. 2003. Using the web to obtain fre-\nquencies for unseen bigrams. Computational Linguistics ,\n29:459\u2013484.\nKipper, K., H. T. Dang, and M. Palmer. 2000. Class-based\nconstruction of a verb lexicon. AAAI .\nKullback, S. and R. A. Leibler. 1951. On information and\nsuf\ufb01ciency. Annals of Mathematical Statistics , 22:79\u201386.\nLakoff, G. 1965. On the Nature of Syntactic Irregularity .\nPh.D. thesis, Indiana University. Published as Irregularity\nin Syntax . Holt, Rinehart, and Winston, New York, 1970.\nLang, J. and M. Lapata. 2014. Similarity-driven semantic\nrole induction via graph partitioning. Computational Lin-\nguistics , 40(3):633\u2013669.\nLevin, B. 1977. Mapping sentences to case frames. Techni-\ncal Report 167, MIT AI Laboratory. AI Working Paper\n143.",
    "metadata": {
      "source": "21",
      "chunk_id": 28,
      "token_count": 366,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 22",
    "metadata": {
      "source": "21",
      "chunk_id": 29,
      "token_count": 4,
      "chapter_title": ""
    }
  },
  {
    "content": "22 Chapter 21 \u2022 Semantic Role Labeling\nLevin, B. 1993. English Verb Classes and Alternations: A\nPreliminary Investigation . University of Chicago Press.\nLevin, B. and M. Rappaport Hovav. 2005. Argument Real-\nization . Cambridge University Press.\nMarcus, M. P. 1980. A Theory of Syntactic Recognition for\nNatural Language . MIT Press.\nM`arquez, L., X. Carreras, K. C. Litkowski, and S. Steven-\nson. 2008. Semantic role labeling: An introduction to the\nspecial issue. Computational linguistics , 34(2):145\u2013159.\nMeyers, A., R. Reeves, C. Macleod, R. Szekely, V . Zielinska,\nB. Young, and R. Grishman. 2004. The nombank project:\nAn interim report. NAACL/HLT Workshop: Frontiers in\nCorpus Annotation .\nMinsky, M. 1974. A framework for representing knowledge.\nTechnical Report 306, MIT AI Laboratory. Memo 306.\nNash-Webber, B. L. 1975. The role of semantics in automatic\nspeech understanding. In D. G. Bobrow and A. Collins,\neds, Representation and Understanding , 351\u2013382. Aca-\ndemic Press.\nPalmer, M., D. Gildea, and N. Xue. 2010. Semantic role\nlabeling. Synthesis Lectures on Human Language Tech-\nnologies , 3(1):1\u2013103.\nPalmer, M., P. Kingsbury, and D. Gildea. 2005. The proposi-\ntion bank: An annotated corpus of semantic roles. Com-\nputational Linguistics , 31(1):71\u2013106.\nPenn, G. and P. Kiparsky. 2012. On P \u00afan.ini and the gen-\nerative capacity of contextualized replacement systems.\nCOLING .\nPradhan, S., A. Moschitti, N. Xue, H. T. Ng, A. Bj \u00a8orkelund,\nO. Uryupina, Y . Zhang, and Z. Zhong. 2013. Towards\nrobust linguistic analysis using OntoNotes. CoNLL .\nPradhan, S., W. Ward, K. Hacioglu, J. H. Martin, and D. Ju-\nrafsky. 2005. Semantic role labeling using different syn-\ntactic views. ACL.\nResnik, P. 1993. Semantic classes and syntactic ambiguity.\nHLT.\nResnik, P. 1996. Selectional constraints: An information-\ntheoretic model and its computational realization. Cogni-\ntion, 61:127\u2013159.\nRiloff, E. and M. Schmelzenbach. 1998. An empirical ap-\nproach to conceptual case frame acquisition. Proceedings\nof the Sixth Workshop on Very Large Corpora .\nRitter, A., O. Etzioni, and Mausam. 2010. A latent dirichlet\nallocation method for selectional preferences. ACL.\nRooth, M., S. Riezler, D. Prescher, G. Carroll, and F. Beil.\n1999. Inducing a semantically annotated lexicon via EM-\nbased clustering. ACL.\nRuppenhofer, J., M. Ellsworth, M. R. L. Petruck, C. R. John-",
    "metadata": {
      "source": "21",
      "chunk_id": 30,
      "token_count": 752,
      "chapter_title": ""
    }
  },
  {
    "content": "robust linguistic analysis using OntoNotes. CoNLL .\nPradhan, S., W. Ward, K. Hacioglu, J. H. Martin, and D. Ju-\nrafsky. 2005. Semantic role labeling using different syn-\ntactic views. ACL.\nResnik, P. 1993. Semantic classes and syntactic ambiguity.\nHLT.\nResnik, P. 1996. Selectional constraints: An information-\ntheoretic model and its computational realization. Cogni-\ntion, 61:127\u2013159.\nRiloff, E. and M. Schmelzenbach. 1998. An empirical ap-\nproach to conceptual case frame acquisition. Proceedings\nof the Sixth Workshop on Very Large Corpora .\nRitter, A., O. Etzioni, and Mausam. 2010. A latent dirichlet\nallocation method for selectional preferences. ACL.\nRooth, M., S. Riezler, D. Prescher, G. Carroll, and F. Beil.\n1999. Inducing a semantically annotated lexicon via EM-\nbased clustering. ACL.\nRuppenhofer, J., M. Ellsworth, M. R. L. Petruck, C. R. John-\nson, C. F. Baker, and J. Scheffczyk. 2016. FrameNet II:\nExtended theory and practice.\nRuppenhofer, J., C. Sporleder, R. Morante, C. F. Baker,\nand M. Palmer. 2010. Semeval-2010 task 10: Linking\nevents and their participants in discourse. 5th Interna-\ntional Workshop on Semantic Evaluation .\nSchank, R. C. and R. P. Abelson. 1975. Scripts, plans, and\nknowledge. Proceedings of IJCAI-75 .\nSchank, R. C. and R. P. Abelson. 1977. Scripts, Plans, Goals\nand Understanding . Lawrence Erlbaum.Sch\u00a8utze, H. 1992. Context space. AAAI Fall Symposium on\nProbabilistic Approaches to Natural Language .\nS\u00b4eaghdha, D. O. 2010. Latent variable models of selectional\npreference. ACL.\nShi, P. and J. Lin. 2019. Simple BERT models for relation\nextraction and semantic role labeling. ArXiv.\nSimmons, R. F. 1973. Semantic networks: Their compu-\ntation and use for understanding English sentences. In\nR. C. Schank and K. M. Colby, eds, Computer Models of\nThought and Language , 61\u2013113. W.H. Freeman & Co.\nSloan, M. C. 2010. Aristotle\u2019s Nicomachean Ethics as the\noriginal locus for the Septem Circumstantiae. Classical\nPhilology , 105(3):236\u2013251.\nSurdeanu, M., S. Harabagiu, J. Williams, and P. Aarseth.\n2003. Using predicate-argument structures for informa-\ntion extraction. ACL.\nSurdeanu, M., R. Johansson, A. Meyers, L. M `arquez, and\nJ. Nivre. 2008. The CoNLL 2008 shared task on joint\nparsing of syntactic and semantic dependencies. CoNLL .\nSwier, R. and S. Stevenson. 2004. Unsupervised semantic\nrole labelling. EMNLP .",
    "metadata": {
      "source": "21",
      "chunk_id": 31,
      "token_count": 760,
      "chapter_title": ""
    }
  },
  {
    "content": "preference. ACL.\nShi, P. and J. Lin. 2019. Simple BERT models for relation\nextraction and semantic role labeling. ArXiv.\nSimmons, R. F. 1973. Semantic networks: Their compu-\ntation and use for understanding English sentences. In\nR. C. Schank and K. M. Colby, eds, Computer Models of\nThought and Language , 61\u2013113. W.H. Freeman & Co.\nSloan, M. C. 2010. Aristotle\u2019s Nicomachean Ethics as the\noriginal locus for the Septem Circumstantiae. Classical\nPhilology , 105(3):236\u2013251.\nSurdeanu, M., S. Harabagiu, J. Williams, and P. Aarseth.\n2003. Using predicate-argument structures for informa-\ntion extraction. ACL.\nSurdeanu, M., R. Johansson, A. Meyers, L. M `arquez, and\nJ. Nivre. 2008. The CoNLL 2008 shared task on joint\nparsing of syntactic and semantic dependencies. CoNLL .\nSwier, R. and S. Stevenson. 2004. Unsupervised semantic\nrole labelling. EMNLP .\nTannen, D. 1979. What\u2019s in a frame? Surface evidence for\nunderlying expectations. In R. Freedle, ed., New Direc-\ntions in Discourse Processing , 137\u2013181. Ablex.\nTesni `ere, L. 1959. \u00b4El\u00b4ements de Syntaxe Structurale . Librairie\nC. Klincksieck, Paris.\nTitov, I. and E. Khoddam. 2014. Unsupervised induction of\nsemantic roles within a reconstruction-error minimization\nframework. NAACL HLT .\nTitov, I. and A. Klementiev. 2012. A Bayesian approach to\nunsupervised semantic role induction. EACL .\nWilks, Y . 1973. An arti\ufb01cial intelligence approach to ma-\nchine translation. In R. C. Schank and K. M. Colby, eds,\nComputer Models of Thought and Language , 114\u2013151.\nW.H. Freeman.\nWilks, Y . 1975a. Preference semantics. In E. L. Keenan,\ned.,The Formal Semantics of Natural Language , 329\u2013\n350. Cambridge Univ. Press.\nWilks, Y . 1975b. A preferential, pattern-seeking, seman-\ntics for natural language inference. Arti\ufb01cial Intelligence ,\n6(1):53\u201374.\nWinston, P. H. 1977. Arti\ufb01cial Intelligence . Addison Wesley.\nWoodsend, K. and M. Lapata. 2015. Distributed representa-\ntions for unsupervised semantic role labeling. EMNLP .\nXue, N. and M. Palmer. 2004. Calibrating features for se-\nmantic role labeling. EMNLP .\nZapirain, B., E. Agirre, L. M `arquez, and M. Surdeanu. 2013.\nSelectional preferences for semantic role classi\ufb01cation.\nComputational Linguistics , 39(3):631\u2013663.\nZhao, H., W. Chen, C. Kit, and G. Zhou. 2009. Multilingual\ndependency learning: A huge feature engineering method\nto semantic dependency parsing. CoNLL .",
    "metadata": {
      "source": "21",
      "chunk_id": 32,
      "token_count": 759,
      "chapter_title": ""
    }
  },
  {
    "content": "Computer Models of Thought and Language , 114\u2013151.\nW.H. Freeman.\nWilks, Y . 1975a. Preference semantics. In E. L. Keenan,\ned.,The Formal Semantics of Natural Language , 329\u2013\n350. Cambridge Univ. Press.\nWilks, Y . 1975b. A preferential, pattern-seeking, seman-\ntics for natural language inference. Arti\ufb01cial Intelligence ,\n6(1):53\u201374.\nWinston, P. H. 1977. Arti\ufb01cial Intelligence . Addison Wesley.\nWoodsend, K. and M. Lapata. 2015. Distributed representa-\ntions for unsupervised semantic role labeling. EMNLP .\nXue, N. and M. Palmer. 2004. Calibrating features for se-\nmantic role labeling. EMNLP .\nZapirain, B., E. Agirre, L. M `arquez, and M. Surdeanu. 2013.\nSelectional preferences for semantic role classi\ufb01cation.\nComputational Linguistics , 39(3):631\u2013663.\nZhao, H., W. Chen, C. Kit, and G. Zhou. 2009. Multilingual\ndependency learning: A huge feature engineering method\nto semantic dependency parsing. CoNLL .\nZhou, J. and W. Xu. 2015. End-to-end learning of semantic\nrole labeling using recurrent neural networks. ACL.",
    "metadata": {
      "source": "21",
      "chunk_id": 33,
      "token_count": 314,
      "chapter_title": ""
    }
  }
]