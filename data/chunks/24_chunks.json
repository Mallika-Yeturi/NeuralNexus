[
  {
    "content": "# 24\n\n## Page 1\n\nSpeech and Language Processing. Daniel Jurafsky & James H. Martin. Copyright \u00a92024. All\nrights reserved. Draft of January 12, 2025.\nCHAPTER\n24Discourse Coherence\nAnd even in our wildest and most wandering reveries, nay in our very dreams,\nwe shall \ufb01nd, if we re\ufb02ect, that the imagination ran not altogether at adven-\ntures, but that there was still a connection upheld among the different ideas,\nwhich succeeded each other. Were the loosest and freest conversation to be\ntranscribed, there would immediately be transcribed, there would immediately\nbe observed something which connected it in all its transitions.\nDavid Hume, An enquiry concerning human understanding , 1748\nOrson Welles\u2019 movie Citizen Kane was groundbreaking in many ways, perhaps most\nnotably in its structure. The story of the life of \ufb01ctional media magnate Charles\nFoster Kane, the movie does not proceed in chronological order through Kane\u2019s\nlife. Instead, the \ufb01lm begins with Kane\u2019s death (famously murmuring \u201cRosebud\u201d )\nand is structured around \ufb02ashbacks to his life inserted among scenes of a reporter\ninvestigating his death. The novel idea that the structure of a movie does not have\nto linearly follow the structure of the real timeline made apparent for 20th century\ncinematography the in\ufb01nite possibilities and impact of different kinds of coherent\nnarrative structures.\nBut coherent structure is not just a fact about movies or works of art. Like\nmovies, language does not normally consist of isolated, unrelated sentences, but\ninstead of collocated, structured, coherent groups of sentences. We refer to such\na coherent structured group of sentences as a discourse , and we use the word co- discourse\nherence to refer to the relationship between sentences that makes real discourses coherence\ndifferent than just random assemblages of sentences. The chapter you are now read-\ning is an example of a discourse, as is a news article, a conversation, a thread on\nsocial media, a Wikipedia page, and your favorite novel.\nWhat makes a discourse coherent? If you created a text by taking random sen-\ntences each from many different sources and pasted them together, would that be a\ncoherent discourse? Almost certainly not. Real discourses exhibit both local coher- local\nence andglobal coherence . Let\u2019s consider three ways in which real discourses are global\nlocally coherent;\nFirst, sentences or clauses in real discourses are related to nearby sentences in\nsystematic ways. Consider this example from Hobbs (1979):\n(24.1) John took a train from Paris to Istanbul. He likes spinach.\nThis sequence is incoherent because it is unclear to a reader why the second\nsentence follows the \ufb01rst; what does liking spinach have to do with train trips? In\nfact, a reader might go to some effort to try to \ufb01gure out how the discourse could be\ncoherent; perhaps there is a French spinach shortage? The very fact that hearers try\nto identify such connections suggests that human discourse comprehension involves\nthe need to establish this kind of coherence.\nBy contrast, in the following coherent example:\n(24.2) Jane took a train from Paris to Istanbul. She had to attend a conference.",
    "metadata": {
      "source": "24",
      "chunk_id": 0,
      "token_count": 706,
      "chapter_title": "24"
    }
  },
  {
    "content": "## Page 2",
    "metadata": {
      "source": "24",
      "chunk_id": 1,
      "token_count": 4,
      "chapter_title": ""
    }
  },
  {
    "content": "2CHAPTER 24 \u2022 D ISCOURSE COHERENCE\nthe second sentence gives a REASON for Jane\u2019s action in the \ufb01rst sentence. Struc-\ntured relationships like REASON that hold between text units are called coherence\nrelations , and coherent discourses are structured by many such coherence relations.coherence\nrelations\nCoherence relations are introduced in Section 24.1.\nA second way a discourse can be locally coherent is by virtue of being \u201cabout\u201d\nsomeone or something. In a coherent discourse some entities are salient , and the\ndiscourse focuses on them and doesn\u2019t go back and forth between multiple entities.\nThis is called entity-based coherence . Consider the following incoherent passage,\nin which the salient entity seems to wildly swing from John to Jenny to the piano\nstore to the living room, back to Jenny, then the piano again:\n(24.3) John wanted to buy a piano for his living room.\nJenny also wanted to buy a piano.\nHe went to the piano store.\nIt was nearby.\nThe living room was on the second \ufb02oor.\nShe didn\u2019t \ufb01nd anything she liked.\nThe piano he bought was hard to get up to that \ufb02oor.\nEntity-based coherence models measure this kind of coherence by tracking salient\nentities across a discourse. For example Centering Theory (Grosz et al., 1995), theCentering\nTheory\nmost in\ufb02uential theory of entity-based coherence, keeps track of which entities in\nthe discourse model are salient at any point (salient entities are more likely to be\npronominalized or to appear in prominent syntactic positions like subject or object).\nIn Centering Theory, transitions between sentences that maintain the same salient\nentity are considered more coherent than ones that repeatedly shift between entities.\nThe entity grid model of coherence (Barzilay and Lapata, 2008) is a commonly entity grid\nused model that realizes some of the intuitions of the Centering Theory framework.\nEntity-based coherence is introduced in Section 24.3.\nFinally, discourses can be locally coherent by being topically coherent : nearbytopically\ncoherent\nsentences are generally about the same topic and use the same or similar vocab-\nulary to discuss these topics. Because topically coherent discourses draw from a\nsingle semantic \ufb01eld or topic, they tend to exhibit the surface property known as\nlexical cohesion (Halliday and Hasan, 1976): the sharing of identical or semanti- lexical cohesion\ncally related words in nearby sentences. For example, the fact that the words house ,\nchimney ,garret ,closet , and window \u2014 all of which belong to the same semantic\n\ufb01eld\u2014 appear in the two sentences in (24.4), or that they share the identical word\nshingled , is a cue that the two are tied together as a discourse:\n(24.4) Before winter I built a chimney , and shingled the sides of my house ...\nI have thus a tight shingled and plastered house ... with a garret and a\ncloset , a large window on each side....\nIn addition to the local coherence between adjacent or nearby sentences, dis-\ncourses also exhibit global coherence . Many genres of text are associated with\nparticular conventional discourse structures. Academic articles might have sections\ndescribing the Methodology or Results. Stories might follow conventional plotlines\nor motifs. Persuasive essays have a particular claim they are trying to argue for,\nand an essay might express this claim together with a structured set of premises that\nsupport the argument and demolish potential counterarguments. We\u2019ll introduce\nversions of each of these kinds of global coherence.",
    "metadata": {
      "source": "24",
      "chunk_id": 2,
      "token_count": 768,
      "chapter_title": ""
    }
  },
  {
    "content": "single semantic \ufb01eld or topic, they tend to exhibit the surface property known as\nlexical cohesion (Halliday and Hasan, 1976): the sharing of identical or semanti- lexical cohesion\ncally related words in nearby sentences. For example, the fact that the words house ,\nchimney ,garret ,closet , and window \u2014 all of which belong to the same semantic\n\ufb01eld\u2014 appear in the two sentences in (24.4), or that they share the identical word\nshingled , is a cue that the two are tied together as a discourse:\n(24.4) Before winter I built a chimney , and shingled the sides of my house ...\nI have thus a tight shingled and plastered house ... with a garret and a\ncloset , a large window on each side....\nIn addition to the local coherence between adjacent or nearby sentences, dis-\ncourses also exhibit global coherence . Many genres of text are associated with\nparticular conventional discourse structures. Academic articles might have sections\ndescribing the Methodology or Results. Stories might follow conventional plotlines\nor motifs. Persuasive essays have a particular claim they are trying to argue for,\nand an essay might express this claim together with a structured set of premises that\nsupport the argument and demolish potential counterarguments. We\u2019ll introduce\nversions of each of these kinds of global coherence.\nWhy do we care about the local or global coherence of a discourse? Since co-\nherence is a property of a well-written text, coherence detection plays a part in any",
    "metadata": {
      "source": "24",
      "chunk_id": 3,
      "token_count": 320,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 3\n\n24.1 \u2022 C OHERENCE RELATIONS 3\ntask that requires measuring the quality of a text. For example coherence can help\nin pedagogical tasks like essay grading or essay quality measurement that are trying\nto grade how well-written a human essay is (Somasundaran et al. 2014, Feng et al.\n2014, Lai and Tetreault 2018). Coherence can also help for summarization; knowing\nthe coherence relationship between sentences can help know how to select informa-\ntion from them. Finally, detecting incoherent text may even play a role in mental\nhealth tasks like measuring symptoms of schizophrenia or other kinds of disordered\nlanguage (Ditman and Kuperberg 2010, Elvev \u02daag et al. 2007, Bedi et al. 2015, Iter\net al. 2018).\n24.1 Coherence Relations\nRecall from the introduction the difference between passages (24.5) and (24.6).\n(24.5) Jane took a train from Paris to Istanbul. She likes spinach.\n(24.6) Jane took a train from Paris to Istanbul. She had to attend a conference.\nThe reason (24.6) is more coherent is that the reader can form a connection be-\ntween the two sentences, in which the second sentence provides a potential REASON\nfor the \ufb01rst sentences. This link is harder to form for (24.5). These connections\nbetween text spans in a discourse can be speci\ufb01ed as a set of coherence relations .coherence\nrelation\nThe next two sections describe two commonly used models of coherence relations\nand associated corpora: Rhetorical Structure Theory (RST), and the Penn Discourse\nTreeBank (PDTB).\n24.1.1 Rhetorical Structure Theory\nThe most commonly used model of discourse organization is Rhetorical Structure\nTheory (RST ) (Mann and Thompson, 1987). In RST relations are de\ufb01ned between RST\ntwo spans of text, generally a nucleus and a satellite . The nucleus is the unit that nucleus\nsatellite is more central to the writer\u2019s purpose and that is interpretable independently; the\nsatellite is less central and generally is only interpretable with respect to the nucleus.\nSome symmetric relations, however, hold between two nuclei.\nBelow are a few examples of RST coherence relations, with de\ufb01nitions adapted\nfrom the RST Treebank Manual (Carlson and Marcu, 2001).\nReason: The nucleus is an action carried out by an animate agent and the satellite\nis the reason for the nucleus.\n(24.7) [ NUC Jane took a train from Paris to Istanbul.] [ SATShe had to attend a\nconference.]\nElaboration: The satellite gives additional information or detail about the situation\npresented in the nucleus.\n(24.8) [ NUC Dorothy was from Kansas.] [ SATShe lived in the midst of the great\nKansas prairies.]\nEvidence: The satellite gives additional information or detail about the situation\npresented in the nucleus. The information is presented with the goal of convince the\nreader to accept the information presented in the nucleus.\n(24.9) [ NUC Kevin must be here.] [ SATHis car is parked outside.]",
    "metadata": {
      "source": "24",
      "chunk_id": 4,
      "token_count": 703,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 4\n\n4CHAPTER 24 \u2022 D ISCOURSE COHERENCE\nAttribution: The satellite gives the source of attribution for an instance of reported\nspeech in the nucleus.\n(24.10) [ SATAnalysts estimated] [ NUC that sales at U.S. stores declined in the\nquarter, too]\nList: In this multinuclear relation, a series of nuclei is given, without contrast or\nexplicit comparison:\n(24.11) [ NUC Billy Bones was the mate; ] [ NUC Long John, he was quartermaster]\nRST relations are traditionally represented graphically; the asymmetric Nucleus-\nSatellite relation is represented with an arrow from the satellite to the nucleus:\nKevin must be here.His car is parked outsideevidence\nWe can also talk about the coherence of a larger text by considering the hierar-\nchical structure between coherence relations. Figure 24.1 shows the rhetorical struc-\nture of a paragraph from Marcu (2000a) for the text in (24.12) from the Scienti\ufb01c\nAmerican magazine.\n(24.12) With its distant orbit\u201350 percent farther from the sun than Earth\u2013and slim\natmospheric blanket, Mars experiences frigid weather conditions. Surface\ntemperatures typically average about -60 degrees Celsius (-76 degrees\nFahrenheit) at the equator and can dip to -123 degrees C near the poles. Only\nthe midday sun at tropical latitudes is warm enough to thaw ice on occasion,\nbut any liquid water formed in this way would evaporate almost instantly\nbecause of the low atmospheric pressure.\nTitle\n(1)\nMars2-9\nevidence\n2-3\nbackground\n  (2)\nWIth its \ndistant orbit  \n<p> -- 50\n percent \nfarther from \nthe sun than \nEarth -- </p> \nand slim \natmospheric \nblanket,(3)\nMars\nexperiences\nfrigid weather\nconditions.4-9\nelaboration-additional\n(4)\nSurface \ntemperatures\n typically average \nabout -60 \ndegrees Celsius\n <p> (-76 degrees\nFahrenheit)</p>\n at the equator4-5\nList\n(5)\nand can dip\nto -123\ndegrees C\nnear the\npoles.6-9\nContrast\n6-7\n(6)\nOnly the\nmidday sun at\ntropical latitudes\nis warm enough(7)\nto thaw ice\non occasion,purpose8-9\nexplanation-argumentative\n(8)\nbut any liquid water\nformed in this way \nwould evaporate \nalmost instantly(9)\nbecause of\nthe low\natmospheric\npressure.\nFigure 24.1 A discourse tree for the Scienti\ufb01c American text in (24.12), from Marcu (2000a). Note that\nasymmetric relations are represented with a curved arrow from the satellite to the nucleus.\nThe leaves in the Fig. 24.1 tree correspond to text spans of a sentence, clause or\nphrase that are called elementary discourse units orEDU s in RST; these units can EDU\nalso be referred to as discourse segments . Because these units may correspond to\narbitrary spans of text, determining the boundaries of an EDU is an important task\nfor extracting coherence relations. Roughly speaking, one can think of discourse",
    "metadata": {
      "source": "24",
      "chunk_id": 5,
      "token_count": 708,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 5",
    "metadata": {
      "source": "24",
      "chunk_id": 6,
      "token_count": 4,
      "chapter_title": ""
    }
  },
  {
    "content": "24.1 \u2022 C OHERENCE RELATIONS 5\nsegments as being analogous to constituents in sentence syntax, and indeed as we\u2019ll\nsee in Section 24.2 we generally draw on parsing algorithms to infer discourse struc-\nture.\nThere are corpora for many discourse coherence models; the RST Discourse\nTreeBank (Carlson et al., 2001) is the largest available discourse corpus. It con-\nsists of 385 English language documents selected from the Penn Treebank, with full\nRST parses for each one, using a large set of 78 distinct relations, grouped into 16\nclasses. RST treebanks exist also for Spanish, German, Basque, Dutch and Brazilian\nPortuguese (Braud et al., 2017).\nNow that we\u2019ve seen examples of coherence, we can see more clearly how a\ncoherence relation can play a role in summarization or information extraction. For\nexample, the nuclei of a text presumably express more important information than\nthe satellites, which might be dropped in a summary.\n24.1.2 Penn Discourse TreeBank (PDTB)\nThe Penn Discourse TreeBank (PDTB ) is a second commonly used dataset that PDTB\nembodies another model of coherence relations (Miltsakaki et al. 2004, Prasad et al.\n2008, Prasad et al. 2014). PDTB labeling is lexically grounded . Instead of asking\nannotators to directly tag the coherence relation between text spans, they were given\na list of discourse connectives , words that signal discourse relations, like because ,discourse\nconnectives\nalthough ,when ,since , oras a result . In a part of a text where these words marked a\ncoherence relation between two text spans, the connective and the spans were then\nannotated, as in Fig. 24.13, where the phrase as a result signals a causal relationship\nbetween what PDTB calls Arg1 (the \ufb01rst two sentences, here in italics) and Arg2\n(the third sentence, here in bold).\n(24.13) Jewelry displays in department stores were often cluttered and uninspired.\nAnd the merchandise was, well, fake. As a result , marketers of faux gems\nsteadily lost space in department stores to more fashionable\nrivals\u2014cosmetics makers.\n(24.14) In July, the Environmental Protection Agency imposed a gradual ban on\nvirtually all uses of asbestos. (implicit=as a result )By 1997, almost all\nremaining uses of cancer-causing asbestos will be outlawed.\nNot all coherence relations are marked by an explicit discourse connective, and\nso the PDTB also annotates pairs of neighboring sentences with no explicit signal,\nlike (24.14). The annotator \ufb01rst chooses the word or phrase that could have been its\nsignal (in this case as a result ), and then labels its sense. For example for the am-\nbiguous discourse connective since annotators marked whether it is using a C AUSAL\nor a T EMPORAL sense.\nThe \ufb01nal dataset contains roughly 18,000 explicit relations and 16,000 implicit\nrelations. Fig. 24.2 shows examples from each of the 4 major semantic classes, while\nFig. 24.3 shows the full tagset.\nUnlike the RST Discourse Treebank, which integrates these pairwise coherence\nrelations into a global tree structure spanning an entire discourse, the PDTB does not\nannotate anything above the span-pair level, making no commitment with respect to\nhigher-level discourse structure.\nThere are also treebanks using similar methods for other languages; (24.15)",
    "metadata": {
      "source": "24",
      "chunk_id": 7,
      "token_count": 769,
      "chapter_title": ""
    }
  },
  {
    "content": "rivals\u2014cosmetics makers.\n(24.14) In July, the Environmental Protection Agency imposed a gradual ban on\nvirtually all uses of asbestos. (implicit=as a result )By 1997, almost all\nremaining uses of cancer-causing asbestos will be outlawed.\nNot all coherence relations are marked by an explicit discourse connective, and\nso the PDTB also annotates pairs of neighboring sentences with no explicit signal,\nlike (24.14). The annotator \ufb01rst chooses the word or phrase that could have been its\nsignal (in this case as a result ), and then labels its sense. For example for the am-\nbiguous discourse connective since annotators marked whether it is using a C AUSAL\nor a T EMPORAL sense.\nThe \ufb01nal dataset contains roughly 18,000 explicit relations and 16,000 implicit\nrelations. Fig. 24.2 shows examples from each of the 4 major semantic classes, while\nFig. 24.3 shows the full tagset.\nUnlike the RST Discourse Treebank, which integrates these pairwise coherence\nrelations into a global tree structure spanning an entire discourse, the PDTB does not\nannotate anything above the span-pair level, making no commitment with respect to\nhigher-level discourse structure.\nThere are also treebanks using similar methods for other languages; (24.15)\nshows an example from the Chinese Discourse TreeBank (Zhou and Xue, 2015).\nBecause Chinese has a smaller percentage of explicit discourse connectives than\nEnglish (only 22% of all discourse relations are marked with explicit connectives,",
    "metadata": {
      "source": "24",
      "chunk_id": 8,
      "token_count": 336,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 6\n\n6CHAPTER 24 \u2022 D ISCOURSE COHERENCE\nClass Type Example\nTEMPORAL SYNCHRONOUS The parishioners of St. Michael and All Angels stop to chat at\nthe church door, as members here always have. (Implicit while )\nIn the tower, \ufb01ve men and women pull rhythmically on ropes\nattached to the same \ufb01ve bells that \ufb01rst sounded here in 1614.\nCONTINGENCY REASON Also unlike Mr. Ruder, Mr. Breeden appears to be in a position\nto get somewhere with his agenda. (implicit=because )As a for-\nmer White House aide who worked closely with Congress,\nhe is savvy in the ways of Washington.\nCOMPARISON CONTRAST The U.S. wants the removal of what it perceives as barriers to\ninvestment; Japan denies there are real barriers.\nEXPANSION CONJUNCTION Not only do the actors stand outside their characters and make\nit clear they are at odds with them, but they often literally stand\non their heads.\nFigure 24.2 The four high-level semantic distinctions in the PDTB sense hierarchy\nTemporal Comparison\n\u000fAsynchronous \u000fContrast (Juxtaposition, Opposition)\n\u000fSynchronous (Precedence, Succession) \u000fPragmatic Contrast (Juxtaposition, Opposition)\n\u000fConcession (Expectation, Contra-expectation)\n\u000fPragmatic Concession\nContingency Expansion\n\u000fCause (Reason, Result) \u000fException\n\u000fPragmatic Cause (Justi\ufb01cation) \u000fInstantiation\n\u000fCondition (Hypothetical, General, Unreal\nPresent/Past, Factual Present/Past)\u000fRestatement (Speci\ufb01cation, Equivalence, Generalization)\n\u000fPragmatic Condition (Relevance, Implicit As-\nsertion)\u000fAlternative (Conjunction, Disjunction, Chosen Alterna-\ntive)\n\u000fList\nFigure 24.3 The PDTB sense hierarchy. There are four top-level c\u00aflasses, 16 types, and 23 subtypes (not all\ntypes have subtypes). 11 of the 16 types are commonly used for implicit argument classi\ufb01cation; the 5 types in\nitalics are too rare in implicit labeling to be used.\ncompared to 47% in English), annotators labeled this corpus by directly mapping\npairs of sentences to 11 sense tags, without starting with a lexical discourse connec-\ntor.\n(24.15) [ Conn\u4e3a] [Arg2\u63a8\u52a8\u56fe\u4eec\u6c5f\u5730\u533a\u5f00\u53d1]\uff0c[Arg1\u97e9\u56fd\u6350\u6b3e\u4e00\u767e\u4e07\u7f8e\u5143\n\u8bbe\u7acb\u4e86\u56fe\u4eec\u6c5f\u53d1\u5c55\u57fa\u91d1]\n\u201c[In order to] [ Arg2 promote the development of the Tumen River region],\n[Arg1 South Korea donated one million dollars to establish the Tumen\nRiver Development Fund].\u201d\nThese discourse treebanks have been used for shared tasks on multilingual dis-\ncourse parsing (Xue et al., 2016).\n24.2 Discourse Structure Parsing\nGiven a sequence of sentences, how can we automatically determine the coherence\nrelations between them? This task is often called discourse parsing (even thoughdiscourse\nparsing\nfor PDTB we are only assigning labels to leaf spans and not building a full parse",
    "metadata": {
      "source": "24",
      "chunk_id": 9,
      "token_count": 692,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 7\n\n24.2 \u2022 D ISCOURSE STRUCTURE PARSING 7\ntree as we do for RST).\n24.2.1 EDU segmentation for RST parsing\nRST parsing is generally done in two stages. The \ufb01rst stage, EDU segmentation ,\nextracts the start and end of each EDU. The output of this stage would be a labeling\nlike the following:\n(24.16) [Mr. Rambo says] e1[that a 3.2-acre property] e2[overlooking the San\nFernando Valley] e3[is priced at $4 million] e4[because the late actor Erroll\nFlynn once lived there.] e5\nSince EDUs roughly correspond to clauses, early models of EDU segmentation\n\ufb01rst ran a syntactic parser, and then post-processed the output. Modern systems\ngenerally use neural sequence models supervised by the gold EDU segmentation in\ndatasets like the RST Discourse Treebank. Fig. 24.4 shows an example architecture\nsimpli\ufb01ed from the algorithm of Lukasik et al. (2020) that predicts for each token\nwhether or not it is a break. Here the input sentence is passed through an encoder\nand then passed through a linear layer and a softmax to produce a sequence of 0s\nand 1, where 1 indicates the start of an EDU.\nMr.RambosaysthatENCODER\u20260001linear layersoftmaxEDU break\nFigure 24.4 Predicting EDU segment beginnings from encoded text.\n24.2.2 RST parsing\nTools for building RST coherence structure for a discourse have long been based on\nsyntactic parsing algorithms like shift-reduce parsing (Marcu, 1999). Many modern\nRST parsers since Ji and Eisenstein (2014) draw on the neural syntactic parsers we\nsaw in Chapter 20, using representation learning to build representations for each\nspan, and training a parser to choose the correct shift and reduce actions based on\nthe gold parses in the training set.\nWe\u2019ll describe the shift-reduce parser of Yu et al. (2018). The parser state con-\nsists of a stack and a queue, and produces this structure by taking a series of actions\non the states. Actions include:\n\u2022shift : pushes the \ufb01rst EDU in the queue onto the stack creating a single-node\nsubtree.\n\u2022reduce (l,d): merges the top two subtrees on the stack, where lis the coherence\nrelation label, and dis the nuclearity direction, d2fNN ;NS ;SNg.\nAs well as the pop root operation, to remove the \ufb01nal tree from the stack.\nFig. 24.6 shows the actions the parser takes to build the structure in Fig. 24.5.",
    "metadata": {
      "source": "24",
      "chunk_id": 10,
      "token_count": 602,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 8",
    "metadata": {
      "source": "24",
      "chunk_id": 11,
      "token_count": 4,
      "chapter_title": ""
    }
  },
  {
    "content": "8CHAPTER 24 \u2022 D ISCOURSE COHERENCE\n560e1 e2 e3 e4attr elabelab e1: American Telephone & Telegraph Co. said it\ne2: will lay off 75 to 85 technicians here , effective Nov. 1.\ne3: The workers install , maintain and repair its private branch exchanges,\ne4: which are large intracompany telephone networks.\nFigure 1: An example of RST discourse tree, where {e1,e2,e3,e4}are EDUs, attr andelab are\ndiscourse relation labels, and arrows indicate the nuclearities of discourse relations.\nRST discourse parsing. Other studies still adopt discrete syntax features proposed by statistical models,\nfeeding them into neural network models (Braud et al., 2016; Braud et al., 2017).\nThe above approaches model syntax trees in an explicit way, requiring discrete syntax parsing outputs\nas inputs for RST parsing. These approaches may suffer from the error propagation problem. Syntax trees\nproduced by a supervised syntax parsing model could have errors, which may propagate into discourse\nparsing models. The problem could be extremely serious when inputs of discourse parsing have different\ndistributions with the training data of the supervised syntax parser. Recently, Zhang et al. (2017) suggest\nan alternative method, which extracts syntax features from a Bi-Af\ufb01ne dependency parser (Dozat and\nManning, 2016), and the method gives competitive performances on relation extraction. It actually\nrepresents syntax trees implicitly, thus it can reduce the error propagation problem.\nIn this work, we investigate the implicit syntax feature extraction approach for RST parsing. In ad-\ndition, we propose a transition-based neural model for this task, which is able to incorporate various\nfeatures \ufb02exibly. We exploit hierarchical bi-directional LSTMs (Bi-LSTMs) to encode texts, and further\nenhance the transition-based model with dynamic oracle. Based on the proposed model, we study the\neffectiveness of our proposed implicit syntax features. We conduct experiments on a standard RST dis-\ncourse TreeBank (Carlson et al., 2003). First, we evaluate the performance of our proposed transition-\nbased baseline, \ufb01nding that the model is able to achieve strong performances after applying dynamic\noracle. Then we evaluate the effectiveness of implicit syntax features extracted from a Bi-Af\ufb01ne depen-\ndency parser. Results show that the implicit syntax features are effective, giving better performances than\nexplicit Tree-LSTM (Li et al., 2015b). Our codes will be released for public under the Apache License\n2.0 at https://github.com/yunan4nlp/NNDisParser .\nIn summary, we mainly make the following two contributions in this work: (1) we propose a transition-\nbased neural RST discourse parsing model with dynamic oracle, (2) we compare three different syntactic\nintegration approaches proposed by us. The rest of the paper is organized as follows. Section 2 describes\nour proposed models including the transition-based neural model, the dynamic oracle strategy and the\nimplicit syntax feature extraction approach. Section 3 presents the experiments to evaluate our models.\nSection 4 shows the related work. Finally, section 5 draws conclusions.\n2 Transition-based Discourse Parsing\nWe follow Ji and Eisenstein (2014), exploiting a transition-based framework for RST discourse parsing.\nThe framework is conceptually simple and \ufb02exible to support arbitrary features, which has been widely\nused in a number of NLP tasks (Zhu et al., 2013; Dyer et al., 2015; Zhang et al., 2016). In addition, a",
    "metadata": {
      "source": "24",
      "chunk_id": 12,
      "token_count": 771,
      "chapter_title": ""
    }
  },
  {
    "content": "oracle. Then we evaluate the effectiveness of implicit syntax features extracted from a Bi-Af\ufb01ne depen-\ndency parser. Results show that the implicit syntax features are effective, giving better performances than\nexplicit Tree-LSTM (Li et al., 2015b). Our codes will be released for public under the Apache License\n2.0 at https://github.com/yunan4nlp/NNDisParser .\nIn summary, we mainly make the following two contributions in this work: (1) we propose a transition-\nbased neural RST discourse parsing model with dynamic oracle, (2) we compare three different syntactic\nintegration approaches proposed by us. The rest of the paper is organized as follows. Section 2 describes\nour proposed models including the transition-based neural model, the dynamic oracle strategy and the\nimplicit syntax feature extraction approach. Section 3 presents the experiments to evaluate our models.\nSection 4 shows the related work. Finally, section 5 draws conclusions.\n2 Transition-based Discourse Parsing\nWe follow Ji and Eisenstein (2014), exploiting a transition-based framework for RST discourse parsing.\nThe framework is conceptually simple and \ufb02exible to support arbitrary features, which has been widely\nused in a number of NLP tasks (Zhu et al., 2013; Dyer et al., 2015; Zhang et al., 2016). In addition, a\ntransition-based model formalizes a certain task into predicting a sequence of actions, which is essential\nsimilar to sequence-to-sequence models proposed recently (Bahdanau et al., 2014). In the following,\nwe \ufb01rst describe the transition system for RST discourse parsing, and then introduce our neural network\nmodel by its encoder and decoder parts, respectively. Thirdly, we present our proposed dynamic oracle\nstrategy aiming to enhance the transition-based model. Then we introduce the integration method of\nimplicit syntax features. Finally we describe the training method of our neural network models.\n2.1 The Transition-based System\nThe transition-based framework converts a structural learning problem into a sequence of action predic-\ntions, whose key point is a transition system. A transition system consists of two parts: states and actions.\nThe states are used to store partially-parsed results and the actions are used to control state transitions.\nFigure 24.5 Example RST discourse tree, showing four EDUs. Figure from Yu et al. (2018).\n561Step Stack Queue Action Relation\n1 ?e1,e2,e3,e4 SH ?\n2 e1 e2,e3,e4 SH ?\n3 e1,e2 e3,e4 RD(attr,SN) ?\n4 e1:2 e3,e4 SH de1e2\n5 e1:2,e3 e4 SH de1e2\n6 e1:2,e3,e4 ?RD(elab,NS) de1e2\n7 e1:2,e3:4 ?RD(elab,SN) de1e2,de3e4\n8 e1:4 ? PR de1e2,de3e4,\\e1:2e3:4\nTable 1: An example of the transition-based system for RST discourse parsing.\nThe initial state is an empty state, and the \ufb01nal state represents a full result. There are three kinds of\nactions in our transition system:\n\u2022Shift (SH), which removes the \ufb01rst EDU in the queue onto the stack, forming a single-node subtree.\n\u2022Reduce (RD) ( l,d), which merges the top two subtrees on the stack, where lis a discourse relation\nlabel, and d2{NN,NS,SN}indicates the relation nuclearity (nuclear (N) or satellite (S)).",
    "metadata": {
      "source": "24",
      "chunk_id": 13,
      "token_count": 777,
      "chapter_title": ""
    }
  },
  {
    "content": "561Step Stack Queue Action Relation\n1 ?e1,e2,e3,e4 SH ?\n2 e1 e2,e3,e4 SH ?\n3 e1,e2 e3,e4 RD(attr,SN) ?\n4 e1:2 e3,e4 SH de1e2\n5 e1:2,e3 e4 SH de1e2\n6 e1:2,e3,e4 ?RD(elab,NS) de1e2\n7 e1:2,e3:4 ?RD(elab,SN) de1e2,de3e4\n8 e1:4 ? PR de1e2,de3e4,\\e1:2e3:4\nTable 1: An example of the transition-based system for RST discourse parsing.\nThe initial state is an empty state, and the \ufb01nal state represents a full result. There are three kinds of\nactions in our transition system:\n\u2022Shift (SH), which removes the \ufb01rst EDU in the queue onto the stack, forming a single-node subtree.\n\u2022Reduce (RD) ( l,d), which merges the top two subtrees on the stack, where lis a discourse relation\nlabel, and d2{NN,NS,SN}indicates the relation nuclearity (nuclear (N) or satellite (S)).\n\u2022Pop Root (PR), which pops out the top tree on the stack, marking the decoding being completed,\nwhen the stack holds only one subtree and the queue is empty.\nGiven the RST tree as shown in Figure 1, it can be generated by the following action sequence: {SH,\nSH, RD (attr,SN) , SH, SH, RD (elab,NS) , RD (elab,SN) , PR}. Table 1 shows the decoding\nprocess in detail. By this way, we naturally convert RST discourse parsing into predicting a sequence of\ntransition actions, where each line includes a state and next step action referring to the tree.\n2.2 Encoder-Decoder\nPrevious transition-based RST discourse parsing studies exploit statistical models, using manually-\ndesigned discrete features (Sagae, 2009; Heilman and Sagae, 2015; Wang et al., 2017). In this work, we\npropose a transition-based neural model for RST discourse parsing, which follows an encoder-decoder\nframework. Given an input sequence of EDUs {e1,e2,. . . ,e n}, the encoder computes the input represen-\ntations {he\n1,he\n2,. . . ,he\nn}, and the decoder predicts next step actions conditioned on the encoder outputs.\n2.2.1 Encoder\nWe follow Li et al. (2016), using hierarchical Bi-LSTMs to encode the source EDU inputs, where the\n\ufb01rst-layer is used to represent sequencial words inside of EDUs, and the second layer is used to represent\nsequencial EDUs. Given an input sentence {w1,w2,. . . ,w m}, \ufb01rst we represent each word by its form\n(e.g., wi) and POS tag (e.g. ti), concatenating their neural embeddings. By this way, the input vectors\nof the \ufb01rst-layer Bi-LSTM are {xw\n1,xw\n2,. . . ,xw\nm}, where xw\ni=emb (wi)\u0000emb (ti), and then we apply\nBi-LSTM directly, obtaining:\n{hw\n1,hw\n2,. . . ,hw\nm}=Bi-LSTM ({xw\n1,xw\n2,. . . ,xw\nm}) (1)",
    "metadata": {
      "source": "24",
      "chunk_id": 14,
      "token_count": 769,
      "chapter_title": ""
    }
  },
  {
    "content": "propose a transition-based neural model for RST discourse parsing, which follows an encoder-decoder\nframework. Given an input sequence of EDUs {e1,e2,. . . ,e n}, the encoder computes the input represen-\ntations {he\n1,he\n2,. . . ,he\nn}, and the decoder predicts next step actions conditioned on the encoder outputs.\n2.2.1 Encoder\nWe follow Li et al. (2016), using hierarchical Bi-LSTMs to encode the source EDU inputs, where the\n\ufb01rst-layer is used to represent sequencial words inside of EDUs, and the second layer is used to represent\nsequencial EDUs. Given an input sentence {w1,w2,. . . ,w m}, \ufb01rst we represent each word by its form\n(e.g., wi) and POS tag (e.g. ti), concatenating their neural embeddings. By this way, the input vectors\nof the \ufb01rst-layer Bi-LSTM are {xw\n1,xw\n2,. . . ,xw\nm}, where xw\ni=emb (wi)\u0000emb (ti), and then we apply\nBi-LSTM directly, obtaining:\n{hw\n1,hw\n2,. . . ,hw\nm}=Bi-LSTM ({xw\n1,xw\n2,. . . ,xw\nm}) (1)\nThe second-layer Bi-LSTM is built over sequential EDUs. We should \ufb01rst obtain a suitable representa-\ntion for each EDU, which is composed by a span of words inside a certain sentence. Assuming an EDU\nwith its words by {ws,ws+1,. . . ,w t}, after applying the \ufb01rst-layer Bi-LSTM, we obtain their representa-\ntions by {hw\ns,hw\ns+1...,hw\nt}, then we calculate the EDU representation by average pooling:\nxe=1\nt\u0000s+1tX\nshw\nk (2)\nWhen the EDU representations are ready, we apply the second-layer Bi-LSTM directly, resulting:\n{he\n1,he\n2,. . . ,he\nn}=Bi-LSTM ({xe\n1,xe\n2,. . . ,xe\nn}) (3)\nFigure 24.6 Parsing the example of Fig. 24.5 using a shift-reduce parser. Figure from Yu\net al. (2018).\nThe Yu et al. (2018) uses an encoder-decoder architecture, where the encoder\nrepresents the input span of words and EDUs using a hierarchical biLSTM. The\n\ufb01rst biLSTM layer represents the words inside an EDU, and the second represents\nthe EDU sequence. Given an input sentence w1;w2; :::;wm, the words can be repre-\nsented as usual (by static embeddings, combinations with character embeddings or\ntags, or contextual embeddings) resulting in an input word representation sequence\nxw\n1;xw\n2; :::;xw\nm. The result of the word-level biLSTM is then a sequence of hwvalues:\nhw\n1;hw\n2; :::;hw\nm=biLSTM (xw\n1;xw\n2; :::;xw\nm) (24.17)\nAn EDU of span ws;ws+1; :::;wtthen has biLSTM output representation hw\ns;hw\ns+1; :::;hw\nt,\nand is represented by average pooling:\nxe=1\nt\u0000s+1tX\nk=shw\nk (24.18)",
    "metadata": {
      "source": "24",
      "chunk_id": 15,
      "token_count": 767,
      "chapter_title": ""
    }
  },
  {
    "content": "n}) (3)\nFigure 24.6 Parsing the example of Fig. 24.5 using a shift-reduce parser. Figure from Yu\net al. (2018).\nThe Yu et al. (2018) uses an encoder-decoder architecture, where the encoder\nrepresents the input span of words and EDUs using a hierarchical biLSTM. The\n\ufb01rst biLSTM layer represents the words inside an EDU, and the second represents\nthe EDU sequence. Given an input sentence w1;w2; :::;wm, the words can be repre-\nsented as usual (by static embeddings, combinations with character embeddings or\ntags, or contextual embeddings) resulting in an input word representation sequence\nxw\n1;xw\n2; :::;xw\nm. The result of the word-level biLSTM is then a sequence of hwvalues:\nhw\n1;hw\n2; :::;hw\nm=biLSTM (xw\n1;xw\n2; :::;xw\nm) (24.17)\nAn EDU of span ws;ws+1; :::;wtthen has biLSTM output representation hw\ns;hw\ns+1; :::;hw\nt,\nand is represented by average pooling:\nxe=1\nt\u0000s+1tX\nk=shw\nk (24.18)\nThe second layer uses this input to compute a \ufb01nal representation of the sequence of\nEDU representations he:\nhe\n1;he\n2; :::;he\nn=biLSTM (xe\n1;xe\n2; :::;xe\nn) (24.19)\nThe decoder is then a feedforward network Wthat outputs an action obased on a\nconcatenation of the top three subtrees on the stack ( so;s1;s2) plus the \ufb01rst EDU in\nthe queue (q0):\no=W(ht\ns0;ht\ns1;ht\ns2;he\nq0) (24.20)\nwhere the representation of the EDU on the queue he\nq0comes directly from the\nencoder, and the three hidden vectors representing partial trees are computed by\naverage pooling over the encoder output for the EDUs in those trees:\nhts=1\nj\u0000i+1jX\nk=ihe\nk (24.21)",
    "metadata": {
      "source": "24",
      "chunk_id": 16,
      "token_count": 500,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 9\n\n24.2 \u2022 D ISCOURSE STRUCTURE PARSING 9\nTraining \ufb01rst maps each RST gold parse tree into a sequence of oracle actions, and\nthen uses the standard cross-entropy loss (with l2regularization) to train the system\nto take such actions. Give a state Sand oracle action a, we \ufb01rst compute the decoder\noutput using Eq. 24.20, apply a softmax to get probabilities:\npa=exp(oa)P\na02Aexp(oa0)(24.22)\nand then computing the cross-entropy loss:\nLCE() =\u0000log(pa)+l\n2jjQjj2(24.23)\nRST discourse parsers are evaluated on the test section of the RST Discourse Tree-\nbank, either with gold EDUs or end-to-end, using the RST-Pareval metrics (Marcu,\n2000b). It is standard to \ufb01rst transform the gold RST trees into right-branching bi-\nnary trees, and to report four metrics: trees with no labels (S for Span), labeled\nwith nuclei (N), with relations (R), or both (F for Full), for each metric computing\nmicro-averaged F 1over all spans from all documents (Marcu 2000b, Morey et al.\n2017).\n24.2.3 PDTB discourse parsing\nPDTB discourse parsing, the task of detecting PDTB coherence relations between\nspans, is sometimes called shallow discourse parsing because the task just involvesshallow\ndiscourse\nparsing\ufb02at relationships between text spans, rather than the full trees of RST parsing.\nThe set of four subtasks for PDTB discourse parsing was laid out by Lin et al.\n(2014) in the \ufb01rst complete system, with separate tasks for explicit (tasks 1-3) and\nimplicit (task 4) connectives:\n1. Find the discourse connectives (disambiguating them from non-discourse uses)\n2. Find the two spans for each connective\n3. Label the relationship between these spans\n4. Assign a relation between every adjacent pair of sentences\nMany systems have been proposed for Task 4: taking a pair of adjacent sentences\nas input and assign a coherence relation sense label as output. The setup often fol-\nlows Lin et al. (2009) in assuming gold sentence span boundaries and assigning each\nadjacent span one of the 11 second-level PDTB tags or none (removing the 5 very\nrare tags of the 16 shown in italics in Fig. 24.3).\nA simple but very strong algorithm for Task 4 is to represent each of the two\nspans by BERT embeddings and take the last layer hidden state corresponding to\nthe position of the [CLS] token, pass this through a single layer tanh feedforward\nnetwork and then a softmax for sense classi\ufb01cation (Nie et al., 2019).\nEach of the other tasks also have been addressed. Task 1 is to disambiguat-\ning discourse connectives from their non-discourse use. For example as Pitler and\nNenkova (2009) point out, the word andis a discourse connective linking the two\nclauses by an elaboration/expansion relation in (24.24) while it\u2019s a non-discourse\nNP conjunction in (24.25):\n(24.24) Selling picked up as previous buyers bailed out of their positions and\naggressive short sellers\u2014anticipating further declines\u2014moved in.\n(24.25) My favorite colors are blue and green.",
    "metadata": {
      "source": "24",
      "chunk_id": 17,
      "token_count": 767,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 10\n\n10 CHAPTER 24 \u2022 D ISCOURSE COHERENCE\nSimilarly, once is a discourse connective indicating a temporal relation in (24.26),\nbut simply a non-discourse adverb meaning \u2018formerly\u2019 and modifying used in (24.27):\n(24.26) The asbestos \ufb01ber, crocidolite, is unusually resilient once it enters the\nlungs, with even brief exposures to it causing symptoms that show up\ndecades later, researchers said.\n(24.27) A form of asbestos once used to make Kent cigarette \ufb01lters has caused a\nhigh percentage of cancer deaths among a group of workers exposed to it\nmore than 30 years ago, researchers reported.\nDetermining whether a word is a discourse connective is thus a special case\nof word sense disambiguation. Early work on disambiguation showed that the 4\nPDTB high-level sense classes could be disambiguated with high (94%) accuracy\nused syntactic features from gold parse trees (Pitler and Nenkova, 2009). Recent\nwork performs the task end-to-end from word inputs using a biLSTM-CRF with\nBIO outputs ( B-CONN ,I-CONN ,O) (Yu et al., 2019).\nFor task 2, PDTB spans can be identi\ufb01ed with the same sequence models used to\n\ufb01nd RST EDUs: a biLSTM sequence model with pretrained contextual embedding\n(BERT) inputs (Muller et al., 2019). Simple heuristics also do pretty well as a base-\nline at \ufb01nding spans, since 93% of relations are either completely within a single\nsentence or span two adjacent sentences, with one argument in each sentence (Biran\nand McKeown, 2015).\n24.3 Centering and Entity-Based Coherence\nA second way a discourse can be coherent is by virtue of being \u201cabout\u201d some entity.\nThis idea that at each point in the discourse some entity is salient, and a discourse\nis coherent by continuing to discuss the same entity, appears early in functional lin-\nguistics and the psychology of discourse (Chafe 1976, Kintsch and Van Dijk 1978),\nand soon made its way to computational models. In this section we introduce two\nmodels of this kind of entity-based coherence :Centering Theory (Grosz et al., entity-based\n1995), and the entity grid model of Barzilay and Lapata (2008).\n24.3.1 Centering\nCentering Theory (Grosz et al., 1995) is a theory of both discourse salience andCentering\nTheory\ndiscourse coherence. As a model of discourse salience, Centering proposes that at\nany given point in the discourse one of the entities in the discourse model is salient:\nit is being \u201ccentered\u201d on. As a model of discourse coherence, Centering proposes\nthat discourses in which adjacent sentences CONTINUE to maintain the same salient\nentity are more coherent than those which SHIFT back and forth between multiple\nentities (we will see that CONTINUE and SHIFT are technical terms in the theory).\nThe following two texts from Grosz et al. (1995) which have exactly the same\npropositional content but different saliences, can help in understanding the main\nCentering intuition.\n(24.28) a. John went to his favorite music store to buy a piano.\nb. He had frequented the store for many years.\nc. He was excited that he could \ufb01nally buy a piano.\nd. He arrived just as the store was closing for the day.",
    "metadata": {
      "source": "24",
      "chunk_id": 18,
      "token_count": 775,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 11",
    "metadata": {
      "source": "24",
      "chunk_id": 19,
      "token_count": 4,
      "chapter_title": ""
    }
  },
  {
    "content": "24.3 \u2022 C ENTERING AND ENTITY -BASED COHERENCE 11\n(24.29) a. John went to his favorite music store to buy a piano.\nb. It was a store John had frequented for many years.\nc. He was excited that he could \ufb01nally buy a piano.\nd. It was closing just as John arrived.\nWhile these two texts differ only in how the two entities (John and the store) are\nrealized in the sentences, the discourse in (24.28) is intuitively more coherent than\nthe one in (24.29). As Grosz et al. (1995) point out, this is because the discourse\nin (24.28) is clearly about one individual, John, describing his actions and feelings.\nThe discourse in (24.29), by contrast, focuses \ufb01rst on John, then the store, then back\nto John, then to the store again. It lacks the \u201caboutness\u201d of the \ufb01rst discourse.\nCentering Theory realizes this intuition by maintaining two representations for\neach utterance Un. The backward-looking center ofUn, denoted as Cb(Un), rep-backward-\nlooking\ncenterresents the current salient entity, the one being focused on in the discourse after Un\nis interpreted. The forward-looking centers ofUn, denoted as Cf(Un), are a setforward-looking\ncenter\nof potential future salient entities, the discourse entities evoked by Unany of which\ncould serve as Cb(the salient entity) of the following utterance, i.e. Cb(Un+1).\nThe set of forward-looking centers Cf(Un)are ranked according to factors like\ndiscourse salience and grammatical role (for example subjects are higher ranked\nthan objects, which are higher ranked than all other grammatical roles). We call the\nhighest-ranked forward-looking center Cp(for \u201cpreferred center\u201d). Cpis a kind of\nprediction about what entity will be talked about next. Sometimes the next utterance\nindeed talks about this entity, but sometimes another entity becomes salient instead.\nWe\u2019ll use here the algorithm for centering presented in Brennan et al. (1987),\nwhich de\ufb01nes four intersentential relationships between a pair of utterances Unand\nUn+1that depend on the relationship between Cb(Un+1),Cb(Un), and Cp(Un+1);\nthese are shown in Fig. 24.7.\nCb(Un+1) =Cb(Un) Cb(Un+1)6=Cb(Un)\nor unde\ufb01ned Cb(Un)\nCb(Un+1) =Cp(Un+1) Continue Smooth-Shift\nCb(Un+1)6=Cp(Un+1) Retain Rough-Shift\nFigure 24.7 Centering Transitions for Rule 2 from Brennan et al. (1987).\nThe following rules are used by the algorithm:\nRule 1: If any element of Cf(Un)is realized by a pronoun in utterance\nUn+1, then Cb(Un+1)must be realized as a pronoun also.\nRule 2 :Transition states are ordered. Continue is preferred to Retain is\npreferred to Smooth-Shift is preferred to Rough-Shift.\nRule 1 captures the intuition that pronominalization (including zero-anaphora)\nis a common way to mark discourse salience. If there are multiple pronouns in an\nutterance realizing entities from the previous utterance, one of these pronouns must\nrealize the backward center Cb; if there is only one pronoun, it must be Cb.\nRule 2 captures the intuition that discourses that continue to center the same en-",
    "metadata": {
      "source": "24",
      "chunk_id": 20,
      "token_count": 765,
      "chapter_title": ""
    }
  },
  {
    "content": "these are shown in Fig. 24.7.\nCb(Un+1) =Cb(Un) Cb(Un+1)6=Cb(Un)\nor unde\ufb01ned Cb(Un)\nCb(Un+1) =Cp(Un+1) Continue Smooth-Shift\nCb(Un+1)6=Cp(Un+1) Retain Rough-Shift\nFigure 24.7 Centering Transitions for Rule 2 from Brennan et al. (1987).\nThe following rules are used by the algorithm:\nRule 1: If any element of Cf(Un)is realized by a pronoun in utterance\nUn+1, then Cb(Un+1)must be realized as a pronoun also.\nRule 2 :Transition states are ordered. Continue is preferred to Retain is\npreferred to Smooth-Shift is preferred to Rough-Shift.\nRule 1 captures the intuition that pronominalization (including zero-anaphora)\nis a common way to mark discourse salience. If there are multiple pronouns in an\nutterance realizing entities from the previous utterance, one of these pronouns must\nrealize the backward center Cb; if there is only one pronoun, it must be Cb.\nRule 2 captures the intuition that discourses that continue to center the same en-\ntity are more coherent than ones that repeatedly shift to other centers. The transition\ntable is based on two factors: whether the backward-looking center Cbis the same\nfrom UntoUn+1and whether this discourse entity is the one that is preferred ( Cp)\nin the new utterance Un+1. If both of these hold, a CONTINUE relation, the speaker\nhas been talking about the same entity and is going to continue talking about that",
    "metadata": {
      "source": "24",
      "chunk_id": 21,
      "token_count": 361,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 12\n\n12 CHAPTER 24 \u2022 D ISCOURSE COHERENCE\nentity. In a RETAIN relation, the speaker intends to SHIFT to a new entity in a future\nutterance and meanwhile places the current entity in a lower rank Cf. In a SHIFT\nrelation, the speaker is shifting to a new salient entity.\nLet\u2019s walk though the start of (24.28) again, repeated as (24.30), showing the\nrepresentations after each utterance is processed.\n(24.30) John went to his favorite music store to buy a piano. ( U1)\nHe was excited that he could \ufb01nally buy a piano. ( U2)\nHe arrived just as the store was closing for the day. ( U3)\nIt was closing just as John arrived ( U4)\nUsing the grammatical role hierarchy to order the C f, for sentence U1we get:\nCf(U1):fJohn, music store, piano g\nCp(U1): John\nCb(U1): unde\ufb01ned\nand then for sentence U2:\nCf(U2):fJohn, pianog\nCp(U2): John\nCb(U2): John\nResult: Continue ( Cp(U2)=Cb(U2);Cb(U1)unde\ufb01ned)\nThe transition from U1toU2is thus a CONTINUE . Completing this example is left\nas exercise (1) for the reader\n24.3.2 Entity Grid model\nCentering embodies a particular theory of how entity mentioning leads to coher-\nence: that salient entities appear in subject position or are pronominalized, and that\ndiscourses are salient by means of continuing to mention the same entity in such\nways.\nThe entity grid model of Barzilay and Lapata (2008) is an alternative way to entity grid\ncapture entity-based coherence: instead of having a top-down theory, the entity-grid\nmodel using machine learning to induce the patterns of entity mentioning that make\na discourse more coherent.\nThe model is based around an entity grid , a two-dimensional array that repre-\nsents the distribution of entity mentions across sentences. The rows represent sen-\ntences, and the columns represent discourse entities (most versions of the entity grid\nmodel focus just on nominal mentions). Each cell represents the possible appearance\nof an entity in a sentence, and the values represent whether the entity appears and its\ngrammatical role. Grammatical roles are subject ( S), object ( O), neither ( X), or ab-\nsent (\u2013); in the implementation of Barzilay and Lapata (2008), subjects of passives\nare represented with O, leading to a representation with some of the characteristics\nof thematic roles.\nFig. 24.8 from Barzilay and Lapata (2008) shows a grid for the text shown in\nFig. 24.9. There is one row for each of the six sentences. The second column, for\nthe entity \u2018trial\u2019, is O\u2013 \u2013 \u2013 X, showing that the trial appears in the \ufb01rst sentence as\ndirect object, in the last sentence as an oblique, and does not appear in the middle\nsentences. The third column, for the entity Microsoft, shows that it appears as sub-\nject in sentence 1 (it also appears as the object of the preposition against , but entities\nthat appear multiple times are recorded with their highest-ranked grammatical func-\ntion). Computing the entity grids requires extracting entities and doing coreference",
    "metadata": {
      "source": "24",
      "chunk_id": 22,
      "token_count": 734,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 13",
    "metadata": {
      "source": "24",
      "chunk_id": 23,
      "token_count": 4,
      "chapter_title": ""
    }
  },
  {
    "content": "24.3 \u2022 C ENTERING AND ENTITY -BASED COHERENCE 13\nComputational Linguistics Volume 34, Number 1\nthese patterns can be encoded as feature vectors appropriate for performing coherence-\nrelated ranking and classi\ufb01cation tasks.\n3.1 The Entity-Grid Discourse Representation\nEach text is represented by an entity grid ,at w o - d i m e n s i o n a la r r a yt h a tc a p t u r e s\nthe distribution of discourse entities across text sentences. We follow Miltsakaki and\nKukich (2000) in assuming that our unit of analysis is the traditional sentence (i.e., a\nmain clause with accompanying subordinate and adjunct clauses). The rows of the\ngrid correspond to sentences, and the columns correspond to discourse entities. By\ndiscourse entity we mean a class of coreferent noun phrases (we explain in Section 3.3\nhow coreferent entities are identi\ufb01ed). For each occurrence of a discourse entity in the\ntext, the corresponding grid cell contains information about its presence or absence\nin a sequence of sentences. In addition, for entities present in a given sentence, grid\ncells contain information about their syntactic role. Such information can be expressed\nin many ways (e.g., using constituent labels or thematic role information). Because\ngrammatical relations \ufb01gure prominently in entity-based theories of local coherence (see\nSection 2), they serve as a logical point of departure. Each grid cell thus corresponds to\na string from a set of categories re\ufb02ecting whether the entity in question is a subject ( S),\nobject ( O), or neither ( X). Entities absent from a sentence are signaled by gaps ( \u2013).\nGrammatical role information can be extracted from the output of a broad-coverage\ndependency parser (Lin 2001; Briscoe and Carroll 2002) or any state-of-the art statistical\nparser (Collins 1997; Charniak 2000). We discuss how this information was computed\nfor our experiments in Section 3.3.\nTable 1 illustrates a fragment of an entity grid constructed for the text in Table 2.\nBecause the text contains six sentences, the grid columns are of length six. Consider\nfor instance the grid column for the entity trial ,[O\u2013\u2013\u2013\u2013 X].I tr e c o r d st h a t trial is\npresent in sentences 1 and 6 (as Oand X,r e s p e c t i v e l y )b u ti sa b s e n tf r o mt h er e s to ft h e\nsentences. Also note that the grid in Table 1 takes coreference resolution into account.\nEven though the same entity appears in different linguistic forms, for example, Microsoft\nCorp. ,Microsoft ,a n d the company , it is mapped to a single entry in the grid (see the\ncolumn introduced by Microsoft in Table 1).\nTable 1\nA fragment of the entity grid. Noun phrases are represented by their head nouns. Grid cells\ncorrespond to grammatical roles: subjects ( S), objects ( O), or neither ( X).Department\nTrial\nMicrosoft\nEvidence\nCompetitors\nMarkets\nProducts\nBrands\nCase\nNetscape\nSoftware\nTactics\nGovernment\nSuit\nEarnings\n1SO SXO \u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013 1\n2\u2013\u2013 O\u2013\u2013 XSO \u2013\u2013\u2013\u2013 \u2013\u2013\u2013 2\n3\u2013\u2013 SO \u2013\u2013\u2013\u2013 SOO \u2013\u2013\u2013 \u2013 3\n4\u2013\u2013 S\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013 S\u2013\u2013\u2013 4\n5\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013 SO \u20135\n6\u2013XS \u2013\u2013\u2013\u2013\u2013 \u2013\u2013\u2013 \u2013 \u2013 \u2013 O6\n6",
    "metadata": {
      "source": "24",
      "chunk_id": 24,
      "token_count": 785,
      "chapter_title": ""
    }
  },
  {
    "content": "present in sentences 1 and 6 (as Oand X,r e s p e c t i v e l y )b u ti sa b s e n tf r o mt h er e s to ft h e\nsentences. Also note that the grid in Table 1 takes coreference resolution into account.\nEven though the same entity appears in different linguistic forms, for example, Microsoft\nCorp. ,Microsoft ,a n d the company , it is mapped to a single entry in the grid (see the\ncolumn introduced by Microsoft in Table 1).\nTable 1\nA fragment of the entity grid. Noun phrases are represented by their head nouns. Grid cells\ncorrespond to grammatical roles: subjects ( S), objects ( O), or neither ( X).Department\nTrial\nMicrosoft\nEvidence\nCompetitors\nMarkets\nProducts\nBrands\nCase\nNetscape\nSoftware\nTactics\nGovernment\nSuit\nEarnings\n1SO SXO \u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013 1\n2\u2013\u2013 O\u2013\u2013 XSO \u2013\u2013\u2013\u2013 \u2013\u2013\u2013 2\n3\u2013\u2013 SO \u2013\u2013\u2013\u2013 SOO \u2013\u2013\u2013 \u2013 3\n4\u2013\u2013 S\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013 S\u2013\u2013\u2013 4\n5\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013\u2013 SO \u20135\n6\u2013XS \u2013\u2013\u2013\u2013\u2013 \u2013\u2013\u2013 \u2013 \u2013 \u2013 O6\n6\nFigure 24.8 Part of the entity grid for the text in Fig. 24.9. Entities are listed by their head\nnoun; each cell represents whether an entity appears as subject ( S), object ( O), neither ( X), or\nis absent (\u2013). Figure from Barzilay and Lapata (2008).\nBarzilay and Lapata Modeling Local Coherence\nTable 2\nSummary augmented with syntactic annotations for grid computation.\n1 [The Justice Department]Sis conducting an [anti-trust trial]Oagainst [Microsoft Corp.]X\nwith [evidence]Xthat [the company]Sis increasingly attempting to crush [competitors]O.\n2[ M i c r o s o f t ]Ois accused of trying to forcefully buy into [markets]Xwhere [its own\nproducts]Sare not competitive enough to unseat [established brands]O.\n3[ T h e c a s e ]Srevolves around [evidence]Oof [Microsoft]Saggressively pressuring\n[Netscape]Ointo merging [browser software]O.\n4[ M i c r o s o f t ]Sclaims [its tactics]Sare commonplace and good economically.\n5 [The government]Smay \ufb01le [a civil suit]Oruling that [conspiracy]Sto curb [competition]O\nthrough [collusion]Xis [a violation of the Sherman Act]O.\n6[ M i c r o s o f t ]Scontinues to show [increased earnings]Odespite [the trial]X.\nWhen a noun is attested more than once with a different grammatical role in the\nsame sentence, we default to the role with the highest grammatical ranking: subjects are\nranked higher than objects, which in turn are ranked higher than the rest. For example,\nthe entity Microsoft is mentioned twice in Sentence 1 with the grammatical roles x(for\nMicrosoft Corp. )a n d s(forthe company ), but is represented only by sin the grid (see\nTables 1 and 2).\n3.2 Entity Grids as Feature Vectors",
    "metadata": {
      "source": "24",
      "chunk_id": 25,
      "token_count": 727,
      "chapter_title": ""
    }
  },
  {
    "content": "products]Sare not competitive enough to unseat [established brands]O.\n3[ T h e c a s e ]Srevolves around [evidence]Oof [Microsoft]Saggressively pressuring\n[Netscape]Ointo merging [browser software]O.\n4[ M i c r o s o f t ]Sclaims [its tactics]Sare commonplace and good economically.\n5 [The government]Smay \ufb01le [a civil suit]Oruling that [conspiracy]Sto curb [competition]O\nthrough [collusion]Xis [a violation of the Sherman Act]O.\n6[ M i c r o s o f t ]Scontinues to show [increased earnings]Odespite [the trial]X.\nWhen a noun is attested more than once with a different grammatical role in the\nsame sentence, we default to the role with the highest grammatical ranking: subjects are\nranked higher than objects, which in turn are ranked higher than the rest. For example,\nthe entity Microsoft is mentioned twice in Sentence 1 with the grammatical roles x(for\nMicrosoft Corp. )a n d s(forthe company ), but is represented only by sin the grid (see\nTables 1 and 2).\n3.2 Entity Grids as Feature Vectors\nAf u n d a m e n t a la s s u m p t i o nu n d e r l y i n go u ra p p r o a c hi st h a tt h ed i s t r i b u t i o no fe n t i t i e s\nin coherent texts exhibits certain regularities re\ufb02ected in grid topology. Some of these\nregularities are formalized in Centering Theory as constraints on transitions of the\nlocal focus in adjacent sentences. Grids of coherent texts are likely to have some dense\ncolumns (i.e., columns with just a few gaps, such as Microsoft in Table 1) and many\nsparse columns which will consist mostly of gaps (see markets andearnings in Table 1).\nOne would further expect that entities corresponding to dense columns are more often\nsubjects or objects. These characteristics will be less pronounced in low-coherence texts.\nInspired by Centering Theory, our analysis revolves around patterns of local entity\ntransitions. A local entity transition is a sequence {S,O,X,\u2013}nthat represents entity\noccurrences and their syntactic roles in nadjacent sentences. Local transitions can be\neasily obtained from a grid as continuous subsequences of each column. Each transition\nwill have a certain probability in a given grid. For instance, the probability of the\ntransition [S\u2013]in the grid from Table 1 is 0 .08 (computed as a ratio of its frequency\n[i.e., six] divided by the total number of transitions of length two [i.e., 75]). Each text\ncan thus be viewed as a distribution de\ufb01ned over transition types.\nWe can now go one step further and represent each text by a \ufb01xed set of transition\nsequences using a standard feature vector notation. Each grid rendering jof a document\ndicorresponds to a feature vector \u03a6(xij)=(p1(xij),p2(xij),... ,pm(xij)), where mis the\nnumber of all prede\ufb01ned entity transitions, and pt(xij)t h ep r o b a b i l i t yo ft r a n s i t i o n t",
    "metadata": {
      "source": "24",
      "chunk_id": 26,
      "token_count": 732,
      "chapter_title": ""
    }
  },
  {
    "content": "One would further expect that entities corresponding to dense columns are more often\nsubjects or objects. These characteristics will be less pronounced in low-coherence texts.\nInspired by Centering Theory, our analysis revolves around patterns of local entity\ntransitions. A local entity transition is a sequence {S,O,X,\u2013}nthat represents entity\noccurrences and their syntactic roles in nadjacent sentences. Local transitions can be\neasily obtained from a grid as continuous subsequences of each column. Each transition\nwill have a certain probability in a given grid. For instance, the probability of the\ntransition [S\u2013]in the grid from Table 1 is 0 .08 (computed as a ratio of its frequency\n[i.e., six] divided by the total number of transitions of length two [i.e., 75]). Each text\ncan thus be viewed as a distribution de\ufb01ned over transition types.\nWe can now go one step further and represent each text by a \ufb01xed set of transition\nsequences using a standard feature vector notation. Each grid rendering jof a document\ndicorresponds to a feature vector \u03a6(xij)=(p1(xij),p2(xij),... ,pm(xij)), where mis the\nnumber of all prede\ufb01ned entity transitions, and pt(xij)t h ep r o b a b i l i t yo ft r a n s i t i o n t\nin grid xij.T h i sf e a t u r ev e c t o rr e p r e s e n t a t i o ni su s e f u l l ya m e n a b l et om a c h i n el e a r n i n g\nalgorithms (see our experiments in Sections 4\u20136). Furthermore, it allows the consid-\neration of large numbers of transitions which could potentially uncover novel entity\ndistribution patterns relevant for coherence assessment or other coherence-related tasks.\nNote that considerable latitude is available when specifying the transition types to\nbe included in a feature vector. These can be all transitions of a given length (e.g., two\nor three) or the most frequent transitions within a document collection. An example of\n7\nFigure 24.9 A discourse with the entities marked and annotated with grammatical func-\ntions. Figure from Barzilay and Lapata (2008).\nresolution to cluster them into discourse entities (Chapter 23) as well as parsing the\nsentences to get grammatical roles.\nIn the resulting grid, columns that are dense (like the column for Microsoft) in-\ndicate entities that are mentioned often in the texts; sparse columns (like the column\nfor earnings) indicate entities that are mentioned rarely.\nIn the entity grid model, coherence is measured by patterns of local entity tran-\nsition . For example, Department is a subject in sentence 1, and then not men-\ntioned in sentence 2; this is the transition [ S\u2013]. The transitions are thus sequences\nfS,O X, \u2013gnwhich can be extracted as continuous cells from each column. Each\ntransition has a probability; the probability of [ S\u2013] in the grid from Fig. 24.8 is 0.08\n(it occurs 6 times out of the 75 total transitions of length two). Fig. 24.10 shows the\ndistribution over transitions of length 2 for the text of Fig. 24.9 (shown as the \ufb01rst\nrowd1), and 2 other documents.\nComputational Linguistics Volume 34, Number 1",
    "metadata": {
      "source": "24",
      "chunk_id": 27,
      "token_count": 739,
      "chapter_title": ""
    }
  },
  {
    "content": "7\nFigure 24.9 A discourse with the entities marked and annotated with grammatical func-\ntions. Figure from Barzilay and Lapata (2008).\nresolution to cluster them into discourse entities (Chapter 23) as well as parsing the\nsentences to get grammatical roles.\nIn the resulting grid, columns that are dense (like the column for Microsoft) in-\ndicate entities that are mentioned often in the texts; sparse columns (like the column\nfor earnings) indicate entities that are mentioned rarely.\nIn the entity grid model, coherence is measured by patterns of local entity tran-\nsition . For example, Department is a subject in sentence 1, and then not men-\ntioned in sentence 2; this is the transition [ S\u2013]. The transitions are thus sequences\nfS,O X, \u2013gnwhich can be extracted as continuous cells from each column. Each\ntransition has a probability; the probability of [ S\u2013] in the grid from Fig. 24.8 is 0.08\n(it occurs 6 times out of the 75 total transitions of length two). Fig. 24.10 shows the\ndistribution over transitions of length 2 for the text of Fig. 24.9 (shown as the \ufb01rst\nrowd1), and 2 other documents.\nComputational Linguistics Volume 34, Number 1\naf e a t u r es p a c ew i t ht r a n s i t i o n so fl e n g t ht w oi si l l u s t r a t e di nT a b l e3 .T h es e c o n dr o w\n(introduced by d1)i st h ef e a t u r ev e c t o rr e p r e s e n t a t i o no ft h eg r i di nT a b l e1 .\n3.3 Grid Construction: Linguistic Dimensions\nOne of the central research issues in developing entity-based models of coherence is\ndetermining what sources of linguistic knowledge are essential for accurate prediction,\nand how to encode them succinctly in a discourse representation. Previous approaches\ntend to agree on the features of entity distribution related to local coherence\u2014the\ndisagreement lies in the way these features are modeled.\nOur study of alternative encodings is not a mere duplication of previous ef-\nforts (Poesio et al. 2004) that focus on linguistic aspects of parameterization. Because we\nare interested in an automatically constructed model, we have to take into account com-\nputational and learning issues when considering alternative representations. Therefore,\nour exploration of the parameter space is guided by three considerations: the linguistic\nimportance of a parameter, the accuracy of its automatic computation, and the size of the\nresulting feature space. From the linguistic side, we focus on properties of entity distri-\nbution that are tightly linked to local coherence, and at the same time allow for multiple\ninterpretations during the encoding process. Computational considerations prevent us\nfrom considering discourse representations that cannot be computed reliably by exist-\ning tools. For instance, we could not experiment with the granularity of an utterance\u2014\nsentence versus clause\u2014because available clause separators introduce substantial noise\ninto a grid construction. Finally, we exclude representations that will explode the size of\nthe feature space, thereby increasing the amount of data required for training the model.\nEntity Ex traction. The accurate computation of entity classes is key to computing mean-\ningful entity grids. In previous implementations of entity-based models, classes of coref-\nerent nouns have been extracted manually (Miltsakaki and Kukich 2000; Karamanis",
    "metadata": {
      "source": "24",
      "chunk_id": 28,
      "token_count": 762,
      "chapter_title": ""
    }
  },
  {
    "content": "Our study of alternative encodings is not a mere duplication of previous ef-\nforts (Poesio et al. 2004) that focus on linguistic aspects of parameterization. Because we\nare interested in an automatically constructed model, we have to take into account com-\nputational and learning issues when considering alternative representations. Therefore,\nour exploration of the parameter space is guided by three considerations: the linguistic\nimportance of a parameter, the accuracy of its automatic computation, and the size of the\nresulting feature space. From the linguistic side, we focus on properties of entity distri-\nbution that are tightly linked to local coherence, and at the same time allow for multiple\ninterpretations during the encoding process. Computational considerations prevent us\nfrom considering discourse representations that cannot be computed reliably by exist-\ning tools. For instance, we could not experiment with the granularity of an utterance\u2014\nsentence versus clause\u2014because available clause separators introduce substantial noise\ninto a grid construction. Finally, we exclude representations that will explode the size of\nthe feature space, thereby increasing the amount of data required for training the model.\nEntity Ex traction. The accurate computation of entity classes is key to computing mean-\ningful entity grids. In previous implementations of entity-based models, classes of coref-\nerent nouns have been extracted manually (Miltsakaki and Kukich 2000; Karamanis\net al. 2004; Poesio et al. 2004), but this is not an option for our model. An obvious\nsolution for identifying entity classes is to employ an automatic coreference resolution\ntool that determines which noun phrases refer to the same entity in a document.\nCurrent approaches recast coreference resolution as a classi\ufb01cation task. A pair\nof NPs is classi\ufb01ed as coreferring or not based on constraints that are learned from\nan annotated corpus. A separate clustering mechanism then coordinates the possibly\ncontradictory pairwise classi\ufb01cations and constructs a partition on the set of NPs. In\nour experiments, we employ Ng and Cardie\u2019s (2002) coreference resolution system.\nThe system decides whether two NPs are coreferent by exploiting a wealth of lexical,\ngrammatical, semantic, and positional features. It is trained on the MUC (6\u20137) data sets\nand yields state-of-the-art performance (70.4 F-measure on MUC-6 and 63.4 on MUC-7).\nTable 3\nExample of a feature-vector document representation using all transitions of length two given\nsyntactic categories S,O,X,a n d \u2013.\nSS SO SX S \u2013OS OO OX O \u2013XS XO XX X \u2013\u2013 S\u2013O\u2013X\u2013\u2013\nd1.01 .01 0 .08 .01 0 0 .09 0 0 0 .03 .05 .07 .03 .59\nd2.02 .01 .01 .02 0 .07 0 .02 .14 .14 .06 .04 .03 .07 0.1 .36\nd3.02 0 0 .03 .09 0 .09 .06 0 0 0 .05 .03 .07 .17 .39\n8\nFigure 24.10 A feature vector for representing documents using all transitions of length 2.\nDocument d1is the text in Fig. 24.9. Figure from Barzilay and Lapata (2008).\nThe transitions and their probabilities can then be used as features for a machine\nlearning model. This model can be a text classi\ufb01er trained to produce human-labeled\ncoherence scores (for example from humans labeling each text as coherent or inco-",
    "metadata": {
      "source": "24",
      "chunk_id": 29,
      "token_count": 779,
      "chapter_title": ""
    }
  },
  {
    "content": "and yields state-of-the-art performance (70.4 F-measure on MUC-6 and 63.4 on MUC-7).\nTable 3\nExample of a feature-vector document representation using all transitions of length two given\nsyntactic categories S,O,X,a n d \u2013.\nSS SO SX S \u2013OS OO OX O \u2013XS XO XX X \u2013\u2013 S\u2013O\u2013X\u2013\u2013\nd1.01 .01 0 .08 .01 0 0 .09 0 0 0 .03 .05 .07 .03 .59\nd2.02 .01 .01 .02 0 .07 0 .02 .14 .14 .06 .04 .03 .07 0.1 .36\nd3.02 0 0 .03 .09 0 .09 .06 0 0 0 .05 .03 .07 .17 .39\n8\nFigure 24.10 A feature vector for representing documents using all transitions of length 2.\nDocument d1is the text in Fig. 24.9. Figure from Barzilay and Lapata (2008).\nThe transitions and their probabilities can then be used as features for a machine\nlearning model. This model can be a text classi\ufb01er trained to produce human-labeled\ncoherence scores (for example from humans labeling each text as coherent or inco-\nherent). But such data is expensive to gather. Barzilay and Lapata (2005) introduced\na simplifying innovation: coherence models can be trained by self-supervision :\ntrained to distinguish the natural original order of sentences in a discourse from",
    "metadata": {
      "source": "24",
      "chunk_id": 30,
      "token_count": 345,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 14\n\n14 CHAPTER 24 \u2022 D ISCOURSE COHERENCE\na modi\ufb01ed order (such as a randomized order). We turn to these evaluations in the\nnext section.\n24.3.3 Evaluating Neural and Entity-based coherence\nEntity-based coherence models, as well as the neural models we introduce in the\nnext section, are generally evaluated in one of two ways.\nFirst, we can have humans rate the coherence of a document and train a classi\ufb01er\nto predict these human ratings, which can be categorial (high/low, or high/mid/low)\nor continuous. This is the best evaluation to use if we have some end task in mind,\nlike essay grading, where human raters are the correct de\ufb01nition of the \ufb01nal label.\nAlternatively, since it\u2019s very expensive to get human labels, and we might not\nyet have an end-task in mind, we can use natural texts to do self-supervision. In\nself-supervision we pair up a natural discourse with a pseudo-document created by\nchanging the ordering. Since naturally-ordered discourses are more coherent than\nrandom permutation (Lin et al., 2011), a successful coherence algorithm should pre-\nfer the original ordering.\nSelf-supervision has been implemented in 3 ways. In the sentence order dis-\ncrimination task (Barzilay and Lapata, 2005), we compare a document to a random\npermutation of its sentences. A model is considered correct for an (original, per-\nmuted) test pair if it ranks the original document higher. Given kdocuments, we can\ncompute npermutations, resulting in knpairs each with one original document and\none permutation, to use in training and testing.\nIn the sentence insertion task (Chen et al., 2007) we take a document, remove\none of the nsentences s, and create n\u00001 copies of the document with sinserted into\neach position. The task is to decide which of the ndocuments is the one with the\noriginal ordering, distinguishing the original position for sfrom all other positions.\nInsertion is harder than discrimination since we are comparing documents that differ\nby only one sentence.\nFinally, in the sentence order reconstruction task (Lapata, 2003), we take a\ndocument, randomize the sentences, and train the model to put them back in the\ncorrect order. Again given kdocuments, we can compute npermutations, resulting\ninknpairs each with one original document and one permutation, to use in training\nand testing. Reordering is of course a much harder task than simple classi\ufb01cation.\n24.4 Representation learning models for local coherence\nThe third kind of local coherence is topical or semantic \ufb01eld coherence. Discourses\ncohere by talking about the same topics and subtopics, and drawing on the same\nsemantic \ufb01elds in doing so.\nThe \ufb01eld was pioneered by a series of unsupervised models in the 1990s of this\nkind of coherence that made use of lexical cohesion (Halliday and Hasan, 1976): lexical cohesion\nthe sharing of identical or semantically related words in nearby sentences. Morris\nand Hirst (1991) computed lexical chains of words (like pine,bush trees ,trunk ) that\noccurred through a discourse and that were related in Roget\u2019s Thesaurus (by being in\nthe same category, or linked categories). They showed that the number and density\nof chain correlated with the topic structure. The TextTiling algorithm of Hearst TextTiling\n(1997) computed the cosine between neighboring text spans (the normalized dot\nproduct of vectors of raw word counts), again showing that sentences or paragraph in",
    "metadata": {
      "source": "24",
      "chunk_id": 31,
      "token_count": 788,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 15\n\n24.4 \u2022 R EPRESENTATION LEARNING MODELS FOR LOCAL COHERENCE 15\na subtopic have high cosine with each other, but not with sentences in a neighboring\nsubtopic.\nA third early model, the LSA Coherence method of Foltz et al. (1998) was the\n\ufb01rst to use embeddings, modeling the coherence between two sentences as the co-\nsine between their LSA sentence embedding vectors1, computing embeddings for a\nsentence sby summing the embeddings of its words w:\nsim(s;t) = cos(s;t)\n=cos(X\nw2sw;X\nw2tw) (24.31)\nand de\ufb01ning the overall coherence of a text as the average similarity over all pairs of\nadjacent sentences siandsi+1:\ncoherence (T) =1\nn\u00001n\u00001X\ni=1cos(si;si+1) (24.32)\nModern neural representation-learning coherence models, beginning with Li et al.\n(2014), draw on the intuitions of these early unsupervised models for learning sen-\ntence representations and measuring how they change between neighboring sen-\ntences. But the new models also draw on the idea pioneered by Barzilay and Lapata\n(2005) of self-supervision. That is, unlike say coherence relation models, which\ntrain on hand-labeled representations for RST or PDTB, these models are trained to\ndistinguish natural discourses from unnatural discourses formed by scrambling the\norder of sentences, thus using representation learning to discover the features that\nmatter for at least the ordering aspect of coherence.\nHere we present one such model, the local coherence discriminator (LCD) (Xu\net al., 2019). Like early models, LCD computes the coherence of a text as the av-\nerage of coherence scores between consecutive pairs of sentences. But unlike the\nearly unsupervised models, LCD is a self-supervised model trained to discriminate\nconsecutive sentence pairs (si;si+1)in the training documents (assumed to be coher-\nent) from (constructed) incoherent pairs (si;s0). All consecutive pairs are positive\nexamples, and the negative (incoherent) partner for a sentence siis another sentence\nuniformly sampled from the same document as si.\nFig. 24.11 describes the architecture of the model fq, which takes a sentence\npair and returns a score, higher scores for more coherent pairs. Given an input\nsentence pair sandt, the model computes sentence embeddings sandt(using any\nsentence embeddings algorithm), and then concatenates four features of the pair: (1)\nthe concatenation of the two vectors (2) their difference s\u0000t; (3) the absolute value\nof their difference js\u0000tj; (4) their element-wise product s\ft. These are passed\nthrough a one-layer feedforward network to output the coherence score.\nThe model is trained to make this coherence score higher for real pairs than for\nnegative pairs. More formally, the training objective for a corpus Cof documents d,\neach of which consists of a list of sentences si, is:\nLq=X\nd2CX\nsi2dE\np(s0jsi)[L(fq(si;si+1);fq(si;s0))] (24.33)\nEp(s0jsi)is the expectation with respect to the negative sampling distribution con-\nditioned on si: given a sentence sithe algorithms samples a negative sentence s0\n1See Chapter 6 for more on LSA embeddings; they are computed by applying SVD to the term-\ndocument matrix (each cell weighted by log frequency and normalized by entropy), and then the \ufb01rst\n300 dimensions are used as the embedding.",
    "metadata": {
      "source": "24",
      "chunk_id": 32,
      "token_count": 794,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 16",
    "metadata": {
      "source": "24",
      "chunk_id": 33,
      "token_count": 4,
      "chapter_title": ""
    }
  },
  {
    "content": "16 CHAPTER 24 \u2022 D ISCOURSE COHERENCE\n681Loss function: The role of the loss function is\nto encourage f+=f\u2713(si,si+1)to be high while\nf\u0000=f\u2713(si,s0)to be low. Common losses such as\nmargin or log loss can all be used. Through exper-\nimental validation, we found that margin loss to\nbe superior for this problem. Speci\ufb01cally, Ltakes\non the form: L(f+,f\u0000) = max(0 ,\u2318\u0000f++f\u0000)\nwhere \u2318is the margin hyperparameter.\nNegative samples: Technically, we are free to\nchoose any sentence s0to form a negative pair\nwith si. However, because of potential differ-\nences in genre, topic and writing style, such neg-\natives might cause the discriminative model to\nlearn cues unrelated to coherence. Therefore, we\nonly select sentences from the same document to\nconstruct negative pairs. Speci\ufb01cally, suppose si\ncomes from document dkwith length nk, then\np(s0|si)is a uniform distribution over the nk\u00001\nsentences {sj}j6=ifrom dk. For a document with\nnsentences, there are n\u00001positive pairs, and\n(n\u00001)\u21e4(n\u00002)/2negative pairs. It turns out that\nthe quadratic number of negatives provides a rich\nenough learning signal, while at the same time, is\nnot too prohibitively large to be effectively cov-\nered by a sampling procedure. In practice, we\nsample a new set of negatives each time we see\na document, hence after many epochs, we can ef-\nfectively cover the space for even very long doc-\numents. Section 5.7discusses further details on\nsampling.\n4.1 Model Architecture\nThe speci\ufb01c neural architecture that we use for f\u2713\nis illustrated in Figure 1. We assume the use of\nsome pre-trained sentence encoder, which is dis-\ncussed in the next section.\nGiven an input sentence pair, the sentence en-\ncoder maps the sentences to real-valued vectors S\nandT. We then compute the concatenation of the\nfollowing features: (1)concatenation of the two\nvectors (S, T);(2)element-wise difference S\u0000T;\n(3)element-wise product S\u21e4T;(4)absolute value\nof element-wise difference |S\u0000T|. The concate-\nnated feature representation is then fed to a one-\nlayer MLP to output the coherence score.\nIn practice, we make our overall coherence\nmodel bidirectional, by training a forward model\nwith input (S, T)and a backward model with in-\nput(T,S)with the same architecture but separate\nparameters. The coherence score is then the aver-\nage from the two models.\nFigure 1: Generic architecture for our proposed model.\n4.2 Pre-trained Generative Model as the\nSentence Encoder\nOur model can work with any pre-trained sen-\ntence encoder, ranging from the most simplistic\naverage GloVe ( Pennington et al. ,2014 ) embed-\ndings to more sophisticated supervised or unsu-\npervised pre-trained sentence encoders ( Conneau\net al. ,2017 ). As mentioned in the introduction,\nsince generative models can often be turned into\nsentence encoder, generative coherence model can\nbe leveraged by our model to bene\ufb01t from the\nadvantages of both generative and discriminative\ntraining, similar to ( Kiros et al. ,2015 ;Peters et al. ,",
    "metadata": {
      "source": "24",
      "chunk_id": 34,
      "token_count": 773,
      "chapter_title": ""
    }
  },
  {
    "content": "vectors (S, T);(2)element-wise difference S\u0000T;\n(3)element-wise product S\u21e4T;(4)absolute value\nof element-wise difference |S\u0000T|. The concate-\nnated feature representation is then fed to a one-\nlayer MLP to output the coherence score.\nIn practice, we make our overall coherence\nmodel bidirectional, by training a forward model\nwith input (S, T)and a backward model with in-\nput(T,S)with the same architecture but separate\nparameters. The coherence score is then the aver-\nage from the two models.\nFigure 1: Generic architecture for our proposed model.\n4.2 Pre-trained Generative Model as the\nSentence Encoder\nOur model can work with any pre-trained sen-\ntence encoder, ranging from the most simplistic\naverage GloVe ( Pennington et al. ,2014 ) embed-\ndings to more sophisticated supervised or unsu-\npervised pre-trained sentence encoders ( Conneau\net al. ,2017 ). As mentioned in the introduction,\nsince generative models can often be turned into\nsentence encoder, generative coherence model can\nbe leveraged by our model to bene\ufb01t from the\nadvantages of both generative and discriminative\ntraining, similar to ( Kiros et al. ,2015 ;Peters et al. ,\n2018 ). After initialization, we freeze the genera-\ntive model parameters to avoid over\ufb01tting.\nIn Section 5, we will experimentally show that\nwhile we do bene\ufb01t from strong pre-trained en-\ncoders, the fact that our local discriminative model\nimproves over previous methods is independent of\nthe choice of sentence encoder.\n5 Experiments\n5.1 Evaluation Tasks\nFollowing Nguyen and Joty (2017 ) and other pre-\nvious work, we evaluate our models on the dis-\ncrimination and insertion tasks. Additionally, we\nevaluate on the paragraph reconstruction task in\nopen-domain settings, in a similar manner to Li\nand Jurafsky (2017 ).\nIn the discrimination task, a document is com-\npared to a random permutation of its sentences,\nand the model is considered correct if it scores the\noriginal document higher than the permuted one.\nTwenty permutations are used in the test set in ac-\ncordance with previous work.\nFigure 24.11 The architecture of the LCD model of document coherence, showing the\ncomputation of the score for a pair of sentences sandt. Figure from Xu et al. (2019).\nuniformly over the other sentences in the same document. Lis a loss function that\ntakes two scores, one for a positive pair and one for a negative pair, with the goal of\nencouraging f+=fq(si;si+1)to be high and f\u0000=fq(si;s0))to be low. Fig. 24.11\nuse the margin loss l(f+;f\u0000) =max(0;h\u0000f++f\u0000)where his the margin hyper-\nparameter.\nXu et al. (2019) also give a useful baseline algorithm that itself has quite high\nperformance in measuring perplexity: train an RNN language model on the data,\nand compute the log likelihood of sentence siin two ways, once given the preceding\ncontext (conditional log likelihood) and once with no context (marginal log likeli-\nhood). The difference between these values tells us how much the preceding context\nimproved the predictability of si, a predictability measure of coherence.\nTraining models to predict longer contexts than just consecutive pairs of sen-\ntences can result in even stronger discourse representations. For example a Trans-",
    "metadata": {
      "source": "24",
      "chunk_id": 35,
      "token_count": 764,
      "chapter_title": ""
    }
  },
  {
    "content": "cordance with previous work.\nFigure 24.11 The architecture of the LCD model of document coherence, showing the\ncomputation of the score for a pair of sentences sandt. Figure from Xu et al. (2019).\nuniformly over the other sentences in the same document. Lis a loss function that\ntakes two scores, one for a positive pair and one for a negative pair, with the goal of\nencouraging f+=fq(si;si+1)to be high and f\u0000=fq(si;s0))to be low. Fig. 24.11\nuse the margin loss l(f+;f\u0000) =max(0;h\u0000f++f\u0000)where his the margin hyper-\nparameter.\nXu et al. (2019) also give a useful baseline algorithm that itself has quite high\nperformance in measuring perplexity: train an RNN language model on the data,\nand compute the log likelihood of sentence siin two ways, once given the preceding\ncontext (conditional log likelihood) and once with no context (marginal log likeli-\nhood). The difference between these values tells us how much the preceding context\nimproved the predictability of si, a predictability measure of coherence.\nTraining models to predict longer contexts than just consecutive pairs of sen-\ntences can result in even stronger discourse representations. For example a Trans-\nformer language model trained with a contrastive sentence objective to predict text\nup to a distance of \u00062 sentences improves performance on various discourse coher-\nence tasks (Iter et al., 2020).\nLanguage-model style models are generally evaluated by the methods of Sec-\ntion 24.3.3, although they can also be evaluated on the RST and PDTB coherence\nrelation tasks.\n24.5 Global Coherence\nA discourse must also cohere globally rather than just at the level of pairs of sen-\ntences. Consider stories, for example. The narrative structure of stories is one of\nthe oldest kinds of global coherence to be studied. In his in\ufb02uential Morphology of\nthe Folktale , Propp (1968) models the discourse structure of Russian folktales via\na kind of plot grammar. His model includes a set of character categories he called\ndramatis personae , like Hero, Villain, Donor, or Helper, and a set of events he\ncalled functions (like \u201cVillain commits kidnapping\u201d, \u201cDonor tests Hero\u201d, or \u201cHero\nis pursued\u201d) that have to occur in particular order, along with other components.\nPropp shows that the plots of each of the fairy tales he studies can be represented as",
    "metadata": {
      "source": "24",
      "chunk_id": 36,
      "token_count": 547,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 17",
    "metadata": {
      "source": "24",
      "chunk_id": 37,
      "token_count": 4,
      "chapter_title": ""
    }
  },
  {
    "content": "24.5 \u2022 G LOBAL COHERENCE 17\na sequence of these functions, different tales choosing different subsets of functions,\nbut always in the same order. Indeed Lakoff (1972) showed that Propp\u2019s model\namounted to a discourse grammar of stories, and in recent computational work Fin-\nlayson (2016) demonstrates that some of these Proppian functions could be induced\nfrom corpora of folktale texts by detecting events that have similar actions across\nstories. Bamman et al. (2013) showed that generalizations over dramatis personae\ncould be induced from movie plot summaries on Wikipedia. Their model induced\nlatent personae from features like the actions the character takes (e.g., Villains stran-\ngle), the actions done to them (e.g., Villains are foiled and arrested) or the descriptive\nwords used of them (Villains are evil).\nIn this section we introduce two kinds of such global discourse structure that\nhave been widely studied computationally. The \ufb01rst is the structure of arguments:\nthe way people attempt to convince each other in persuasive essays by offering\nclaims and supporting premises. The second is somewhat related: the structure of\nscienti\ufb01c papers, and the way authors present their goals, results, and relationship to\nprior work in their papers.\n24.5.1 Argumentation Structure\nThe \ufb01rst type of global discourse structure is the structure of arguments . Analyzing\npeople\u2019s argumentation computationally is often called argumentation mining .argumentation\nmining\nThe study of arguments dates back to Aristotle, who in his Rhetorics described\nthree components of a good argument: pathos (appealing to the emotions of the pathos\nlistener), ethos (appealing to the speaker\u2019s personal character), and logos (the logical ethos\nlogos structure of the argument).\nMost of the discourse structure studies of argumentation have focused on logos ,\nparticularly via building and training on annotated datasets of persuasive essays or\nother arguments (Reed et al. 2008, Stab and Gurevych 2014a, Peldszus and Stede\n2016, Habernal and Gurevych 2017, Musi et al. 2018). Such corpora, for exam-\nple, often include annotations of argumentative components like claims (the central claims\ncomponent of the argument that is controversial and needs support) and premises premises\n(the reasons given by the author to persuade the reader by supporting or attacking\nthe claim or other premises), as well as the argumentative relations between themargumentative\nrelations\nlike SUPPORT and ATTACK .\nConsider the following example of a persuasive essay from Stab and Gurevych\n(2014b). The \ufb01rst sentence (1) presents a claim (in bold). (2) and (3) present two\npremises supporting the claim. (4) gives a premise supporting premise (3).\n\u201c(1) Museums and art galleries provide a better understanding\nabout arts than Internet. (2) In most museums and art galleries, de-\ntailed descriptions in terms of the background, history and author are\nprovided. (3) Seeing an artwork online is not the same as watching it\nwith our own eyes, as (4) the picture online does not show the texture\nor three-dimensional structure of the art, which is important to study.\u201d\nThus this example has three argumentative relations: SUPPORT (2,1), SUPPORT (3,1)\nand SUPPORT (4,3). Fig. 24.12 shows the structure of a much more complex argu-\nment.\nWhile argumentation mining is clearly related to rhetorical structure and other",
    "metadata": {
      "source": "24",
      "chunk_id": 38,
      "token_count": 764,
      "chapter_title": ""
    }
  },
  {
    "content": "ple, often include annotations of argumentative components like claims (the central claims\ncomponent of the argument that is controversial and needs support) and premises premises\n(the reasons given by the author to persuade the reader by supporting or attacking\nthe claim or other premises), as well as the argumentative relations between themargumentative\nrelations\nlike SUPPORT and ATTACK .\nConsider the following example of a persuasive essay from Stab and Gurevych\n(2014b). The \ufb01rst sentence (1) presents a claim (in bold). (2) and (3) present two\npremises supporting the claim. (4) gives a premise supporting premise (3).\n\u201c(1) Museums and art galleries provide a better understanding\nabout arts than Internet. (2) In most museums and art galleries, de-\ntailed descriptions in terms of the background, history and author are\nprovided. (3) Seeing an artwork online is not the same as watching it\nwith our own eyes, as (4) the picture online does not show the texture\nor three-dimensional structure of the art, which is important to study.\u201d\nThus this example has three argumentative relations: SUPPORT (2,1), SUPPORT (3,1)\nand SUPPORT (4,3). Fig. 24.12 shows the structure of a much more complex argu-\nment.\nWhile argumentation mining is clearly related to rhetorical structure and other\nkinds of coherence relations, arguments tend to be much less local; often a persua-\nsive essay will have only a single main claim, with premises spread throughout the\ntext, without the local coherence we see in coherence relations.",
    "metadata": {
      "source": "24",
      "chunk_id": 39,
      "token_count": 337,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 18",
    "metadata": {
      "source": "24",
      "chunk_id": 40,
      "token_count": 4,
      "chapter_title": ""
    }
  },
  {
    "content": "18 CHAPTER 24 \u2022 D ISCOURSE COHERENCE\nStab and Gurevych Parsing Argumentation Structures\ncloning. This example illustrates that knowing argumentative relations is important for\nseparating several arguments in a paragraph. The example also shows that argument\ncomponents frequently exhibit preceding text units that are not relevant to the argument\nbut helpful for recognizing the argument component type. For example, preceding dis-\ncourse connectors like \u201ctherefore\u201d, \u201cconsequently\u201d, or \u201cthus\u201d can signal a subsequent\nclaim. Discourse markers like \u201cbecause\u201d, \u201csince\u201d, or \u201cfurthermore\u201d could indicate a\npremise. Formally, these preceding tokens of an argument component starting at token\ntiare de\ufb01ned as the tokens ti\u0000m,...,ti\u00001that are not covered by another argument\ncomponent in the sentence s=t1,t2,...,tnwhere 1 \uf8ffi\uf8ffnand i\u0000m\u00001. The third body\nparagraph illustrates a contra argument and argumentative attack relations:\nAdmittedly, [ cloning could bemisused formilitary purposes] Claim 5. For example,\n[:it:::::could:::be:::::used::to::::::::::manipulate:::::::human::::::genes::in::::::order::to::::::create::::::::obedient:::::::soldiers\n::::with::::::::::::extraordinary:::::::abilities] Premise 9. However, because [::::moral::::and:::::::ethical::::::values:::are\n::::::::::::internationally::::::shared] Premise 10,[:it:::is::::very::::::::unlikely::::that:::::::cloning::::will::be::::::::misused:::for\n::::::militant:::::::::objectives] Premise 11.\nThe paragraph begins with Claim 5, which attacks the stance of the author. It is supported\nbyPremise 9in the second sentence. The third sentence includes two premises, both of\nwhich defend the stance of the author. Premise 11is an attack of Claim 5, and Premise 10\nsupports Premise 11. The last paragraph (conclusion) restates the major claim and sum-\nmarizes the main aspects of the essay:\nTo sum up, although [ permitting cloning might bear some risks like misuse for\nmilitary purposes] Claim 6, I strongly believe that [ this technology is bene\ufb01cial to\nhumanity ]MajorClaim 2. It is likely that [ thistechnologybears some important cures which\nwill significantly improve lifeconditions] Claim 7.\nThe conclusion of the essay starts with an attacking claim followed by the restatement of\nthe major claim. The last sentence includes another claim that summarizes the most im-\nportant points of the author\u2019s argumentation. Figure 2 shows the entire argumentation\nstructure of the example essay.\nFigure 2Argumentation structure of the example essay. Arrows indicate argumentative relations.Arrowheads denote argumentative support relations and circleheads attack relations. Dashedlines indicate relations that are encoded in the stance attributes of claims. \u201cP\u201d denotes premises.629\nFigure 24.12 Argumentation structure of a persuasive essay. Arrows indicate argumentation relations, ei-\nther of SUPPORT (with arrowheads) or ATTACK (with circleheads); P denotes premises. Figure from Stab and\nGurevych (2017).\nAlgorithms for detecting argumentation structure often include classi\ufb01ers for\ndistinguishing claims, premises, or non-argumentation, together with relation clas-\nsi\ufb01ers for deciding if two spans have the SUPPORT ,ATTACK , or neither relation\n(Peldszus and Stede, 2013). While these are the main focus of much computational\nwork, there is also preliminary efforts on annotating and detecting richer semantic",
    "metadata": {
      "source": "24",
      "chunk_id": 41,
      "token_count": 785,
      "chapter_title": ""
    }
  },
  {
    "content": "humanity ]MajorClaim 2. It is likely that [ thistechnologybears some important cures which\nwill significantly improve lifeconditions] Claim 7.\nThe conclusion of the essay starts with an attacking claim followed by the restatement of\nthe major claim. The last sentence includes another claim that summarizes the most im-\nportant points of the author\u2019s argumentation. Figure 2 shows the entire argumentation\nstructure of the example essay.\nFigure 2Argumentation structure of the example essay. Arrows indicate argumentative relations.Arrowheads denote argumentative support relations and circleheads attack relations. Dashedlines indicate relations that are encoded in the stance attributes of claims. \u201cP\u201d denotes premises.629\nFigure 24.12 Argumentation structure of a persuasive essay. Arrows indicate argumentation relations, ei-\nther of SUPPORT (with arrowheads) or ATTACK (with circleheads); P denotes premises. Figure from Stab and\nGurevych (2017).\nAlgorithms for detecting argumentation structure often include classi\ufb01ers for\ndistinguishing claims, premises, or non-argumentation, together with relation clas-\nsi\ufb01ers for deciding if two spans have the SUPPORT ,ATTACK , or neither relation\n(Peldszus and Stede, 2013). While these are the main focus of much computational\nwork, there is also preliminary efforts on annotating and detecting richer semantic\nrelationships (Park and Cardie 2014, Hidey et al. 2017) such as detecting argumen-\ntation schemes , larger-scale structures for argument like argument from example ,argumentation\nschemes\norargument from cause to effect , orargument from consequences (Feng and\nHirst, 2011).\nAnother important line of research is studying how these argument structure (or\nother features) are associated with the success or persuasiveness of an argument\n(Habernal and Gurevych 2016, Tan et al. 2016, Hidey et al. 2017. Indeed, while it\nis Aristotle\u2019s logos that is most related to discourse structure, Aristotle\u2019s ethos and\npathos techniques are particularly relevant in the detection of mechanisms of this\nsort of persuasion . For example scholars have investigated the linguistic realization persuasion\nof features studied by social scientists like reciprocity (people return favors), social\nproof (people follow others\u2019 choices), authority (people are in\ufb02uenced by those\nwith power), and scarcity (people value things that are scarce), all of which can\nbe brought up in a persuasive argument (Cialdini, 1984). Rosenthal and McKeown\n(2017) showed that these features could be combined with argumentation structure\nto predict who in\ufb02uences whom on social media, Althoff et al. (2014) found that\nlinguistic models of reciprocity and authority predicted success in online requests,\nwhile the semisupervised model of Yang et al. (2019) detected mentions of scarcity,\ncommitment, and social identity to predict the success of peer-to-peer lending plat-\nforms.\nSee Stede and Schneider (2018) for a comprehensive survey of argument mining.\n24.5.2 The structure of scienti\ufb01c discourse\nScienti\ufb01c papers have a very speci\ufb01c global structure: somewhere in the course of\nthe paper the authors must indicate a scienti\ufb01c goal, develop a method for a solu-\ntion, provide evidence for the solution, and compare to prior work. One popular",
    "metadata": {
      "source": "24",
      "chunk_id": 42,
      "token_count": 740,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 19\n\n24.6 \u2022 S UMMARY 19\nannotation scheme for modeling these rhetorical goals is the argumentative zon-\ningmodel of Teufel et al. (1999) and Teufel et al. (2009), which is informed by theargumentative\nzoning\nidea that each scienti\ufb01c paper tries to make a knowledge claim about a new piece\nof knowledge being added to the repository of the \ufb01eld (Myers, 1992). Sentences\nin a scienti\ufb01c paper can be assigned one of 15 tags; Fig. 24.13 shows 7 (shortened)\nexamples of labeled sentences.\nCategory Description Example\nAIM Statement of speci\ufb01c research goal, or\nhypothesis of current paper\u201cThe aim of this process is to examine the role that\ntraining plays in the tagging process\u201d\nOWNMETHOD New Knowledge claim, own work:\nmethods\u201cIn order for it to be useful for our purposes, the\nfollowing extensions must be made:\u201d\nOWNRESULTS Measurable/objective outcome of own\nwork\u201cAll the curves have a generally upward trend but\nalways lie far below backoff (51% error rate)\u201d\nUSE Other work is used in own work \u201cWe use the framework for the allocation and\ntransfer of control of Whittaker....\u201d\nGAPWEAK Lack of solution in \ufb01eld, problem with\nother solutions\u201cHere, we will produce experimental evidence\nsuggesting that this simple model leads to serious\noverestimates\u201d\nSUPPORT Other work supports current work or is\nsupported by current work\u201cWork similar to that described here has been car-\nried out by Merialdo (1994), with broadly similar\nconclusions.\u201d\nANTISUPPORT Clash with other\u2019s results or theory; su-\nperiority of own work\u201cThis result challenges the claims of...\u201d\nFigure 24.13 Examples for 7 of the 15 labels from the Argumentative Zoning labelset (Teufel et al., 2009).\nTeufel et al. (1999) and Teufel et al. (2009) develop labeled corpora of scienti\ufb01c\narticles from computational linguistics and chemistry, which can be used as supervi-\nsion for training standard sentence-classi\ufb01cation architecture to assign the 15 labels.\n24.6 Summary\nIn this chapter we introduced local and global models for discourse coherence .\n\u2022 Discourses are not arbitrary collections of sentences; they must be coherent .\nAmong the factors that make a discourse coherent are coherence relations\nbetween the sentences, entity-based coherence, and topical coherence.\n\u2022 Various sets of coherence relations andrhetorical relations have been pro-\nposed. The relations in Rhetorical Structure Theory ( RST ) hold between\nspans of text and are structured into a tree. Because of this, shift-reduce\nand other parsing algorithms are generally used to assign these structures.\nThe Penn Discourse Treebank ( PDTB ) labels only relations between pairs of\nspans, and the labels are generally assigned by sequence models.\n\u2022Entity-based coherence captures the intuition that discourses are about an\nentity, and continue mentioning the entity from sentence to sentence. Cen-\ntering Theory is a family of models describing how salience is modeled for\ndiscourse entities, and hence how coherence is achieved by virtue of keeping\nthe same discourse entities salient over the discourse. The entity grid model\ngives a more bottom-up way to compute which entity realization transitions\nlead to coherence.",
    "metadata": {
      "source": "24",
      "chunk_id": 43,
      "token_count": 727,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 20",
    "metadata": {
      "source": "24",
      "chunk_id": 44,
      "token_count": 4,
      "chapter_title": ""
    }
  },
  {
    "content": "20 CHAPTER 24 \u2022 D ISCOURSE COHERENCE\n\u2022 Many different genres have different types of global coherence . Persuasive\nessays have claims and premises that are extracted in the \ufb01eld of argument\nmining , scienti\ufb01c articles have structure related to aims, methods, results, and\ncomparisons.\nBibliographical and Historical Notes\nCoherence relations arose from the independent development of a number of schol-\nars, including Hobbs (1979) idea that coherence relations play an inferential role for\nthe hearer, and the investigations by Mann and Thompson (1987) of the discourse\nstructure of large texts. Other approaches to coherence relations and their extrac-\ntion include Segmented Discourse Representation Theory ( SDRT ) (Asher and Las- SDRT\ncarides 2003, Baldridge et al. 2007) and the Linguistic Discourse Model (Polanyi\n1988, Scha and Polanyi 1988, Polanyi et al. 2004). Wolf and Gibson (2005) argue\nthat coherence structure includes crossed bracketings, which make it impossible to\nrepresent as a tree, and propose a graph representation instead. A compendium of\nover 350 relations that have been proposed in the literature can be found in Hovy\n(1990).\nRST parsing was \ufb01rst proposed by Marcu (1997), and early work was rule-based,\nfocused on discourse markers (Marcu, 2000a). The creation of the RST Discourse\nTreeBank (Carlson et al. 2001, Carlson and Marcu 2001) enabled a wide variety\nof machine learning algorithms, beginning with the shift-reduce parser of Marcu\n(1999) that used decision trees to choose actions, and continuing with a wide variety\nof machine learned parsing methods (Soricut and Marcu 2003, Sagae 2009, Hernault\net al. 2010, Feng and Hirst 2014, Surdeanu et al. 2015, Joty et al. 2015) and chunkers\n(Sporleder and Lapata, 2005). Subba and Di Eugenio (2009) integrated sophisticated\nsemantic information into RST parsing. Ji and Eisenstein (2014) \ufb01rst applied neural\nmodels to RST parsing neural models, leading to the modern set of neural RST\nmodels (Li et al. 2014, Li et al. 2016, Braud et al. 2017, Yu et al. 2018, inter alia) as\nwell as neural segmenters (Wang et al. 2018). and neural PDTB parsing models (Ji\nand Eisenstein 2015, Qin et al. 2016, Qin et al. 2017).\nBarzilay and Lapata (2005) pioneered the idea of self-supervision for coher-\nence: training a coherence model to distinguish true orderings of sentences from\nrandom permutations. Li et al. (2014) \ufb01rst applied this paradigm to neural sentence-\nrepresentation, and many neural self-supervised models followed (Li and Jurafsky\n2017, Logeswaran et al. 2018, Lai and Tetreault 2018, Xu et al. 2019, Iter et al.\n2020)\nAnother aspect of global coherence is the global topic structure of a text, the way\nthe topics shift over the course of the document. Barzilay and Lee (2004) introduced\nan HMM model for capturing topics for coherence, and later work expanded this",
    "metadata": {
      "source": "24",
      "chunk_id": 45,
      "token_count": 770,
      "chapter_title": ""
    }
  },
  {
    "content": "models to RST parsing neural models, leading to the modern set of neural RST\nmodels (Li et al. 2014, Li et al. 2016, Braud et al. 2017, Yu et al. 2018, inter alia) as\nwell as neural segmenters (Wang et al. 2018). and neural PDTB parsing models (Ji\nand Eisenstein 2015, Qin et al. 2016, Qin et al. 2017).\nBarzilay and Lapata (2005) pioneered the idea of self-supervision for coher-\nence: training a coherence model to distinguish true orderings of sentences from\nrandom permutations. Li et al. (2014) \ufb01rst applied this paradigm to neural sentence-\nrepresentation, and many neural self-supervised models followed (Li and Jurafsky\n2017, Logeswaran et al. 2018, Lai and Tetreault 2018, Xu et al. 2019, Iter et al.\n2020)\nAnother aspect of global coherence is the global topic structure of a text, the way\nthe topics shift over the course of the document. Barzilay and Lee (2004) introduced\nan HMM model for capturing topics for coherence, and later work expanded this\nintuition (Soricut and Marcu 2006, Elsner et al. 2007, Louis and Nenkova 2012, Li\nand Jurafsky 2017).\nThe relationship between explicit and implicit discourse connectives has been\na fruitful one for research. Marcu and Echihabi (2002) \ufb01rst proposed to use sen-\ntences with explicit relations to help provide training data for implicit relations, by\nremoving the explicit relations and trying to re-predict them as a way of improv-\ning performance on implicit connectives; this idea was re\ufb01ned by Sporleder and\nLascarides (2005), (Pitler et al., 2009), and Rutherford and Xue (2015). This rela-",
    "metadata": {
      "source": "24",
      "chunk_id": 46,
      "token_count": 443,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 21",
    "metadata": {
      "source": "24",
      "chunk_id": 47,
      "token_count": 4,
      "chapter_title": ""
    }
  },
  {
    "content": "BIBLIOGRAPHICAL AND HISTORICAL NOTES 21\ntionship can also be used as a way to create discourse-aware representations. The\nDisSent algorithm (Nie et al., 2019) creates the task of predicting explicit discourse\nmarkers between two sentences. They show that representations learned to be good\nat this task also function as powerful sentence representations for other discourse\ntasks.\nThe idea of entity-based coherence seems to have arisen in multiple \ufb01elds in the\nmid-1970s, in functional linguistics (Chafe, 1976), in the psychology of discourse\nprocessing (Kintsch and Van Dijk, 1978), and in the roughly contemporaneous work\nof Grosz, Sidner, Joshi, and their colleagues. Grosz (1977) addressed the focus of\nattention that conversational participants maintain as the discourse unfolds. She de-\n\ufb01ned two levels of focus; entities relevant to the entire discourse were said to be in\nglobal focus, whereas entities that are locally in focus (i.e., most central to a partic-\nular utterance) were said to be in immediate focus. Sidner 1979; 1983 described a\nmethod for tracking (immediate) discourse foci and their use in resolving pronouns\nand demonstrative noun phrases. She made a distinction between the current dis-\ncourse focus and potential foci, which are the predecessors to the backward- and\nforward-looking centers of Centering theory, respectively. The name and further\nroots of the centering approach lie in papers by Joshi and Kuhn (1979) and Joshi\nand Weinstein (1981), who addressed the relationship between immediate focus and\nthe inferences required to integrate the current utterance into the discourse model.\nGrosz et al. (1983) integrated this work with the prior work of Sidner and Grosz.\nThis led to a manuscript on centering which, while widely circulated since 1986,\nremained unpublished until Grosz et al. (1995). A collection of centering papers ap-\npears in Walker et al. (1998). See Karamanis et al. (2004) and Poesio et al. (2004) for\na deeper exploration of centering and its parameterizations, and the History section\nof Chapter 23 for more on the use of centering on coreference.\nThe grid model of entity-based coherence was \ufb01rst proposed by Barzilay and\nLapata (2005) drawing on earlier work by Lapata (2003) and Barzilay, and then\nextended by them Barzilay and Lapata (2008) and others with additional features\n(Elsner and Charniak 2008, 2011, Feng et al. 2014, Lin et al. 2011) a model that\nprojects entities into a global graph for the discourse (Guinaudeau and Strube 2013,\nMesgar and Strube 2016), and a convolutional model to capture longer-range entity\ndependencies (Nguyen and Joty, 2017).\nTheories of discourse coherence have also been used in algorithms for interpret-\ning discourse-level linguistic phenomena, including verb phrase ellipsis and gap-\nping (Asher 1993, Kehler 1993), and tense interpretation (Lascarides and Asher\n1993, Kehler 1994, Kehler 2000). An extensive investigation into the relationship\nbetween coherence relations and discourse connectives can be found in Knott and\nDale (1994).\nUseful surveys of discourse processing and structure include Stede (2011) and\nWebber et al. (2012).",
    "metadata": {
      "source": "24",
      "chunk_id": 48,
      "token_count": 776,
      "chapter_title": ""
    }
  },
  {
    "content": "of Chapter 23 for more on the use of centering on coreference.\nThe grid model of entity-based coherence was \ufb01rst proposed by Barzilay and\nLapata (2005) drawing on earlier work by Lapata (2003) and Barzilay, and then\nextended by them Barzilay and Lapata (2008) and others with additional features\n(Elsner and Charniak 2008, 2011, Feng et al. 2014, Lin et al. 2011) a model that\nprojects entities into a global graph for the discourse (Guinaudeau and Strube 2013,\nMesgar and Strube 2016), and a convolutional model to capture longer-range entity\ndependencies (Nguyen and Joty, 2017).\nTheories of discourse coherence have also been used in algorithms for interpret-\ning discourse-level linguistic phenomena, including verb phrase ellipsis and gap-\nping (Asher 1993, Kehler 1993), and tense interpretation (Lascarides and Asher\n1993, Kehler 1994, Kehler 2000). An extensive investigation into the relationship\nbetween coherence relations and discourse connectives can be found in Knott and\nDale (1994).\nUseful surveys of discourse processing and structure include Stede (2011) and\nWebber et al. (2012).\nAndy Kehler wrote the Discourse chapter for the 2000 \ufb01rst edition of this text-\nbook, which we used as the starting point for the second-edition chapter, and there\nare some remnants of Andy\u2019s lovely prose still in this third-edition coherence chap-\nter.",
    "metadata": {
      "source": "24",
      "chunk_id": 49,
      "token_count": 352,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 22\n\n22 CHAPTER 24 \u2022 D ISCOURSE COHERENCE\nExercises\n24.1 Finish the Centering Theory processing of the last two utterances of (24.30),\nand show how (24.29) would be processed. Does the algorithm indeed mark\n(24.29) as less coherent?\n24.2 Select an editorial column from your favorite newspaper, and determine the\ndiscourse structure for a 10\u201320 sentence portion. What problems did you\nencounter? Were you helped by super\ufb01cial cues the speaker included (e.g.,\ndiscourse connectives) in any places?",
    "metadata": {
      "source": "24",
      "chunk_id": 50,
      "token_count": 129,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 23",
    "metadata": {
      "source": "24",
      "chunk_id": 51,
      "token_count": 4,
      "chapter_title": ""
    }
  },
  {
    "content": "Exercises 23\nAlthoff, T., C. Danescu-Niculescu-Mizil, and D. Jurafsky.\n2014. How to ask for a favor: A case study on the suc-\ncess of altruistic requests. ICWSM 2014 .\nAsher, N. 1993. Reference to Abstract Objects in Dis-\ncourse . Studies in Linguistics and Philosophy (SLAP)\n50, Kluwer.\nAsher, N. and A. Lascarides. 2003. Logics of Conversation .\nCambridge University Press.\nBaldridge, J., N. Asher, and J. Hunter. 2007. Annotation for\nand robust parsing of discourse structure on unrestricted\ntexts. Zeitschrift f \u00a8ur Sprachwissenschaft , 26:213\u2013239.\nBamman, D., B. O\u2019Connor, and N. A. Smith. 2013. Learning\nlatent personas of \ufb01lm characters. ACL.\nBarzilay, R. and M. Lapata. 2005. Modeling local coherence:\nAn entity-based approach. ACL.\nBarzilay, R. and M. Lapata. 2008. Modeling local coher-\nence: An entity-based approach. Computational Linguis-\ntics, 34(1):1\u201334.\nBarzilay, R. and L. Lee. 2004. Catching the drift: Prob-\nabilistic content models, with applications to generation\nand summarization. HLT-NAACL .\nBedi, G., F. Carrillo, G. A. Cecchi, D. F. Slezak, M. Sig-\nman, N. B. Mota, S. Ribeiro, D. C. Javitt, M. Copelli,\nand C. M. Corcoran. 2015. Automated analysis of free\nspeech predicts psychosis onset in high-risk youths. npj\nSchizophrenia , 1.\nBiran, O. and K. McKeown. 2015. PDTB discourse parsing\nas a tagging task: The two taggers approach. SIGDIAL .\nBraud, C., M. Coavoux, and A. S\u00f8gaard. 2017. Cross-lingual\nRST discourse parsing. EACL .\nBrennan, S. E., M. W. Friedman, and C. Pollard. 1987. A\ncentering approach to pronouns. ACL.\nCarlson, L. and D. Marcu. 2001. Discourse tagging manual.\nTechnical Report ISI-TR-545, ISI.\nCarlson, L., D. Marcu, and M. E. Okurowski. 2001. Building\na discourse-tagged corpus in the framework of rhetorical\nstructure theory. SIGDIAL .\nChafe, W. L. 1976. Givenness, contrastiveness, de\ufb01niteness,\nsubjects, topics, and point of view. In C. N. Li, ed., Sub-\nject and Topic , 25\u201355. Academic Press.\nChen, E., B. Snyder, and R. Barzilay. 2007. Incre-\nmental text structuring with online hierarchical ranking.\nEMNLP/CoNLL .\nCialdini, R. B. 1984. In\ufb02uence: The psychology of persua-\nsion. Morrow.\nDitman, T. and G. R. Kuperberg. 2010. Building coherence:\nA framework for exploring the breakdown of links across",
    "metadata": {
      "source": "24",
      "chunk_id": 52,
      "token_count": 756,
      "chapter_title": ""
    }
  },
  {
    "content": "RST discourse parsing. EACL .\nBrennan, S. E., M. W. Friedman, and C. Pollard. 1987. A\ncentering approach to pronouns. ACL.\nCarlson, L. and D. Marcu. 2001. Discourse tagging manual.\nTechnical Report ISI-TR-545, ISI.\nCarlson, L., D. Marcu, and M. E. Okurowski. 2001. Building\na discourse-tagged corpus in the framework of rhetorical\nstructure theory. SIGDIAL .\nChafe, W. L. 1976. Givenness, contrastiveness, de\ufb01niteness,\nsubjects, topics, and point of view. In C. N. Li, ed., Sub-\nject and Topic , 25\u201355. Academic Press.\nChen, E., B. Snyder, and R. Barzilay. 2007. Incre-\nmental text structuring with online hierarchical ranking.\nEMNLP/CoNLL .\nCialdini, R. B. 1984. In\ufb02uence: The psychology of persua-\nsion. Morrow.\nDitman, T. and G. R. Kuperberg. 2010. Building coherence:\nA framework for exploring the breakdown of links across\nclause boundaries in schizophrenia. Journal of neurolin-\nguistics , 23(3):254\u2013269.\nElsner, M., J. Austerweil, and E. Charniak. 2007. A uni\ufb01ed\nlocal and global model for discourse coherence. NAACL-\nHLT.\nElsner, M. and E. Charniak. 2008. Coreference-inspired co-\nherence modeling. ACL.\nElsner, M. and E. Charniak. 2011. Extending the entity grid\nwith entity-speci\ufb01c features. ACL.Elvev \u02daag, B., P. W. Foltz, D. R. Weinberger, and T. E. Gold-\nberg. 2007. Quantifying incoherence in speech: an auto-\nmated methodology and novel application to schizophre-\nnia.Schizophrenia research , 93(1-3):304\u2013316.\nFeng, V . W. and G. Hirst. 2011. Classifying arguments by\nscheme. ACL.\nFeng, V . W. and G. Hirst. 2014. A linear-time bottom-up\ndiscourse parser with constraints and post-editing. ACL.\nFeng, V . W., Z. Lin, and G. Hirst. 2014. The impact of deep\nhierarchical discourse structures in the evaluation of text\ncoherence. COLING .\nFinlayson, M. A. 2016. Inferring Propp\u2019s functions from se-\nmantically annotated text. The Journal of American Folk-\nlore, 129(511):55\u201377.\nFoltz, P. W., W. Kintsch, and T. K. Landauer. 1998. The\nmeasurement of textual coherence with latent semantic\nanalysis. Discourse processes , 25(2-3):285\u2013307.\nGrosz, B. J. 1977. The representation and use of focus in\na system for understanding dialogs. IJCAI-77 . Morgan\nKaufmann.\nGrosz, B. J., A. K. Joshi, and S. Weinstein. 1983. Provid-\ning a uni\ufb01ed account of de\ufb01nite noun phrases in English.",
    "metadata": {
      "source": "24",
      "chunk_id": 53,
      "token_count": 764,
      "chapter_title": ""
    }
  },
  {
    "content": "Feng, V . W. and G. Hirst. 2011. Classifying arguments by\nscheme. ACL.\nFeng, V . W. and G. Hirst. 2014. A linear-time bottom-up\ndiscourse parser with constraints and post-editing. ACL.\nFeng, V . W., Z. Lin, and G. Hirst. 2014. The impact of deep\nhierarchical discourse structures in the evaluation of text\ncoherence. COLING .\nFinlayson, M. A. 2016. Inferring Propp\u2019s functions from se-\nmantically annotated text. The Journal of American Folk-\nlore, 129(511):55\u201377.\nFoltz, P. W., W. Kintsch, and T. K. Landauer. 1998. The\nmeasurement of textual coherence with latent semantic\nanalysis. Discourse processes , 25(2-3):285\u2013307.\nGrosz, B. J. 1977. The representation and use of focus in\na system for understanding dialogs. IJCAI-77 . Morgan\nKaufmann.\nGrosz, B. J., A. K. Joshi, and S. Weinstein. 1983. Provid-\ning a uni\ufb01ed account of de\ufb01nite noun phrases in English.\nACL.\nGrosz, B. J., A. K. Joshi, and S. Weinstein. 1995. Center-\ning: A framework for modeling the local coherence of\ndiscourse. Computational Linguistics , 21(2):203\u2013225.\nGuinaudeau, C. and M. Strube. 2013. Graph-based local co-\nherence modeling. ACL.\nHabernal, I. and I. Gurevych. 2016. Which argument is more\nconvincing? Analyzing and predicting convincingness of\nWeb arguments using bidirectional LSTM. ACL.\nHabernal, I. and I. Gurevych. 2017. Argumentation mining\nin user-generated web discourse. Computational Linguis-\ntics, 43(1):125\u2013179.\nHalliday, M. A. K. and R. Hasan. 1976. Cohesion in English .\nLongman. English Language Series, Title No. 9.\nHearst, M. A. 1997. Texttiling: Segmenting text into multi-\nparagraph subtopic passages. Computational Linguistics ,\n23:33\u201364.\nHernault, H., H. Prendinger, D. A. duVerle, and M. Ishizuka.\n2010. Hilda: A discourse parser using support vector ma-\nchine classi\ufb01cation. Dialogue & Discourse , 1(3).\nHidey, C., E. Musi, A. Hwang, S. Muresan, and K. McKe-\nown. 2017. Analyzing the semantic types of claims and\npremises in an online persuasive forum. 4th Workshop on\nArgument Mining .\nHobbs, J. R. 1979. Coherence and coreference. Cognitive\nScience , 3:67\u201390.\nHovy, E. H. 1990. Parsimonious and pro\ufb02igate approaches to\nthe question of discourse structure relations. Proceedings\nof the 5th International Workshop on Natural Language\nGeneration .\nIter, D., K. Guu, L. Lansing, and D. Jurafsky. 2020. Pretrain-\ning with contrastive sentence objectives improves dis-\ncourse performance of language models. ACL.",
    "metadata": {
      "source": "24",
      "chunk_id": 54,
      "token_count": 758,
      "chapter_title": ""
    }
  },
  {
    "content": "Longman. English Language Series, Title No. 9.\nHearst, M. A. 1997. Texttiling: Segmenting text into multi-\nparagraph subtopic passages. Computational Linguistics ,\n23:33\u201364.\nHernault, H., H. Prendinger, D. A. duVerle, and M. Ishizuka.\n2010. Hilda: A discourse parser using support vector ma-\nchine classi\ufb01cation. Dialogue & Discourse , 1(3).\nHidey, C., E. Musi, A. Hwang, S. Muresan, and K. McKe-\nown. 2017. Analyzing the semantic types of claims and\npremises in an online persuasive forum. 4th Workshop on\nArgument Mining .\nHobbs, J. R. 1979. Coherence and coreference. Cognitive\nScience , 3:67\u201390.\nHovy, E. H. 1990. Parsimonious and pro\ufb02igate approaches to\nthe question of discourse structure relations. Proceedings\nof the 5th International Workshop on Natural Language\nGeneration .\nIter, D., K. Guu, L. Lansing, and D. Jurafsky. 2020. Pretrain-\ning with contrastive sentence objectives improves dis-\ncourse performance of language models. ACL.\nIter, D., J. Yoon, and D. Jurafsky. 2018. Automatic detec-\ntion of incoherent speech for diagnosing schizophrenia.\nFifth Workshop on Computational Linguistics and Clini-\ncal Psychology .",
    "metadata": {
      "source": "24",
      "chunk_id": 55,
      "token_count": 335,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 24",
    "metadata": {
      "source": "24",
      "chunk_id": 56,
      "token_count": 4,
      "chapter_title": ""
    }
  },
  {
    "content": "24 Chapter 24 \u2022 Discourse Coherence\nJi, Y . and J. Eisenstein. 2014. Representation learning for\ntext-level discourse parsing. ACL.\nJi, Y . and J. Eisenstein. 2015. One vector is not enough:\nEntity-augmented distributed semantics for discourse re-\nlations. TACL , 3:329\u2013344.\nJoshi, A. K. and S. Kuhn. 1979. Centered logic: The role\nof entity centered sentence representation in natural lan-\nguage inferencing. IJCAI-79 .\nJoshi, A. K. and S. Weinstein. 1981. Control of inference:\nRole of some aspects of discourse structure \u2013 centering.\nIJCAI-81 .\nJoty, S., G. Carenini, and R. T. Ng. 2015. CODRA: A novel\ndiscriminative framework for rhetorical analysis. Compu-\ntational Linguistics , 41(3):385\u2013435.\nKaramanis, N., M. Poesio, C. Mellish, and J. Oberlander.\n2004. Evaluating centering-based metrics of coherence\nfor text structuring using a reliably annotated corpus.\nACL.\nKehler, A. 1993. The effect of establishing coherence in el-\nlipsis and anaphora resolution. ACL.\nKehler, A. 1994. Temporal relations: Reference or discourse\ncoherence? ACL.\nKehler, A. 2000. Coherence, Reference, and the Theory of\nGrammar . CSLI Publications.\nKintsch, W. and T. A. Van Dijk. 1978. Toward a model of\ntext comprehension and production. Psychological re-\nview, 85(5):363\u2013394.\nKnott, A. and R. Dale. 1994. Using linguistic phenomena\nto motivate a set of coherence relations. Discourse Pro-\ncesses , 18(1):35\u201362.\nLai, A. and J. Tetreault. 2018. Discourse coherence in the\nwild: A dataset, evaluation and methods. SIGDIAL .\nLakoff, G. 1972. Structural complexity in fairy tales. In The\nStudy of Man , 128\u201350. School of Social Sciences, Uni-\nversity of California, Irvine, CA.\nLapata, M. 2003. Probabilistic text structuring: Experiments\nwith sentence ordering. ACL.\nLascarides, A. and N. Asher. 1993. Temporal interpretation,\ndiscourse relations, and common sense entailment. Lin-\nguistics and Philosophy , 16(5):437\u2013493.\nLi, J. and D. Jurafsky. 2017. Neural net models of open-\ndomain discourse coherence. EMNLP .\nLi, J., R. Li, and E. H. Hovy. 2014. Recursive deep models\nfor discourse parsing. EMNLP .\nLi, Q., T. Li, and B. Chang. 2016. Discourse parsing with\nattention-based hierarchical neural networks. EMNLP .\nLin, Z., M.-Y . Kan, and H. T. Ng. 2009. Recognizing im-\nplicit discourse relations in the Penn Discourse Treebank.\nEMNLP .\nLin, Z., H. T. Ng, and M.-Y . Kan. 2011. Automatically eval-\nuating text coherence using discourse relations. ACL.",
    "metadata": {
      "source": "24",
      "chunk_id": 57,
      "token_count": 742,
      "chapter_title": ""
    }
  },
  {
    "content": "Lakoff, G. 1972. Structural complexity in fairy tales. In The\nStudy of Man , 128\u201350. School of Social Sciences, Uni-\nversity of California, Irvine, CA.\nLapata, M. 2003. Probabilistic text structuring: Experiments\nwith sentence ordering. ACL.\nLascarides, A. and N. Asher. 1993. Temporal interpretation,\ndiscourse relations, and common sense entailment. Lin-\nguistics and Philosophy , 16(5):437\u2013493.\nLi, J. and D. Jurafsky. 2017. Neural net models of open-\ndomain discourse coherence. EMNLP .\nLi, J., R. Li, and E. H. Hovy. 2014. Recursive deep models\nfor discourse parsing. EMNLP .\nLi, Q., T. Li, and B. Chang. 2016. Discourse parsing with\nattention-based hierarchical neural networks. EMNLP .\nLin, Z., M.-Y . Kan, and H. T. Ng. 2009. Recognizing im-\nplicit discourse relations in the Penn Discourse Treebank.\nEMNLP .\nLin, Z., H. T. Ng, and M.-Y . Kan. 2011. Automatically eval-\nuating text coherence using discourse relations. ACL.\nLin, Z., H. T. Ng, and M.-Y . Kan. 2014. A pdtb-styled end-\nto-end discourse parser. Natural Language Engineering ,\n20(2):151\u2013184.\nLogeswaran, L., H. Lee, and D. Radev. 2018. Sentence\nordering and coherence modeling using recurrent neural\nnetworks. AAAI .Louis, A. and A. Nenkova. 2012. A coherence model based\non syntactic patterns. EMNLP .\nLukasik, M., B. Dadachev, K. Papineni, and G. Sim \u02dcoes.\n2020. Text segmentation by cross segment attention.\nEMNLP .\nMann, W. C. and S. A. Thompson. 1987. Rhetorical structure\ntheory: A theory of text organization. Technical Report\nRS-87-190, Information Sciences Institute.\nMarcu, D. 1997. The rhetorical parsing of natural language\ntexts. ACL.\nMarcu, D. 1999. A decision-based approach to rhetorical\nparsing. ACL.\nMarcu, D. 2000a. The rhetorical parsing of unrestricted\ntexts: A surface-based approach. Computational Linguis-\ntics, 26(3):395\u2013448.\nMarcu, D., ed. 2000b. The Theory and Practice of Discourse\nParsing and Summarization . MIT Press.\nMarcu, D. and A. Echihabi. 2002. An unsupervised approach\nto recognizing discourse relations. ACL.\nMesgar, M. and M. Strube. 2016. Lexical coherence graph\nmodeling using word embeddings. ACL.\nMiltsakaki, E., R. Prasad, A. K. Joshi, and B. L. Webber.\n2004. The Penn Discourse Treebank. LREC .\nMorey, M., P. Muller, and N. Asher. 2017. How much\nprogress have we made on RST discourse parsing? a\nreplication study of recent results on the rst-dt. EMNLP .\nMorris, J. and G. Hirst. 1991. Lexical cohesion computed by",
    "metadata": {
      "source": "24",
      "chunk_id": 58,
      "token_count": 758,
      "chapter_title": ""
    }
  },
  {
    "content": "RS-87-190, Information Sciences Institute.\nMarcu, D. 1997. The rhetorical parsing of natural language\ntexts. ACL.\nMarcu, D. 1999. A decision-based approach to rhetorical\nparsing. ACL.\nMarcu, D. 2000a. The rhetorical parsing of unrestricted\ntexts: A surface-based approach. Computational Linguis-\ntics, 26(3):395\u2013448.\nMarcu, D., ed. 2000b. The Theory and Practice of Discourse\nParsing and Summarization . MIT Press.\nMarcu, D. and A. Echihabi. 2002. An unsupervised approach\nto recognizing discourse relations. ACL.\nMesgar, M. and M. Strube. 2016. Lexical coherence graph\nmodeling using word embeddings. ACL.\nMiltsakaki, E., R. Prasad, A. K. Joshi, and B. L. Webber.\n2004. The Penn Discourse Treebank. LREC .\nMorey, M., P. Muller, and N. Asher. 2017. How much\nprogress have we made on RST discourse parsing? a\nreplication study of recent results on the rst-dt. EMNLP .\nMorris, J. and G. Hirst. 1991. Lexical cohesion computed by\nthesaural relations as an indicator of the structure of text.\nComputational Linguistics , 17(1):21\u201348.\nMuller, P., C. Braud, and M. Morey. 2019. ToNy: Contextual\nembeddings for accurate multilingual discourse segmen-\ntation of full documents. Workshop on Discourse Relation\nParsing and Treebanking .\nMusi, E., M. Stede, L. Kriese, S. Muresan, and A. Rocci.\n2018. A multi-layer annotated corpus of argumenta-\ntive text: From argument schemes to discourse relations.\nLREC .\nMyers, G. 1992. \u201cIn this paper we report...\u201d: Speech acts and\nscienti\ufb01c facts. Journal of Pragmatics , 17(4):295\u2013313.\nNguyen, D. T. and S. Joty. 2017. A neural local coherence\nmodel. ACL.\nNie, A., E. Bennett, and N. Goodman. 2019. DisSent: Learn-\ning sentence representations from explicit discourse rela-\ntions. ACL.\nPark, J. and C. Cardie. 2014. Identifying appropriate support\nfor propositions in online user comments. First workshop\non argumentation mining .\nPeldszus, A. and M. Stede. 2013. From argument diagrams\nto argumentation mining in texts: A survey. International\nJournal of Cognitive Informatics and Natural Intelligence\n(IJCINI) , 7(1):1\u201331.\nPeldszus, A. and M. Stede. 2016. An annotated corpus of\nargumentative microtexts. 1st European Conference on\nArgumentation .\nPitler, E., A. Louis, and A. Nenkova. 2009. Automatic sense\nprediction for implicit discourse relations in text. ACL\nIJCNLP .\nPitler, E. and A. Nenkova. 2009. Using syntax to disam-\nbiguate explicit discourse connectives in text. ACL IJC-\nNLP.",
    "metadata": {
      "source": "24",
      "chunk_id": 59,
      "token_count": 735,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 25",
    "metadata": {
      "source": "24",
      "chunk_id": 60,
      "token_count": 4,
      "chapter_title": ""
    }
  },
  {
    "content": "Exercises 25\nPoesio, M., R. Stevenson, B. Di Eugenio, and J. Hitzeman.\n2004. Centering: A parametric theory and its instantia-\ntions. Computational Linguistics , 30(3):309\u2013363.\nPolanyi, L. 1988. A formal model of the structure of dis-\ncourse. Journal of Pragmatics , 12.\nPolanyi, L., C. Culy, M. van den Berg, G. L. Thione, and\nD. Ahn. 2004. A rule based approach to discourse pars-\ning. Proceedings of SIGDIAL .\nPrasad, R., N. Dinesh, A. Lee, E. Miltsakaki, L. Robaldo,\nA. K. Joshi, and B. L. Webber. 2008. The Penn Discourse\nTreeBank 2.0. LREC .\nPrasad, R., B. L. Webber, and A. Joshi. 2014. Re\ufb02ections on\nthe Penn Discourse Treebank, comparable corpora, and\ncomplementary annotation. Computational Linguistics ,\n40(4):921\u2013950.\nPropp, V . 1968. Morphology of the Folktale , 2nd edition.\nUniversity of Texas Press. Original Russian 1928. Trans-\nlated by Laurence Scott.\nQin, L., Z. Zhang, and H. Zhao. 2016. A stacking gated\nneural architecture for implicit discourse relation classi\ufb01-\ncation. EMNLP .\nQin, L., Z. Zhang, H. Zhao, Z. Hu, and E. Xing. 2017. Ad-\nversarial connective-exploiting networks for implicit dis-\ncourse relation classi\ufb01cation. ACL.\nReed, C., R. Mochales Palau, G. Rowe, and M.-F. Moens.\n2008. Language resources for studying argument. LREC .\nRosenthal, S. and K. McKeown. 2017. Detecting in\ufb02uencers\nin multiple online genres. ACM Transactions on Internet\nTechnology (TOIT) , 17(2).\nRutherford, A. and N. Xue. 2015. Improving the inference\nof implicit discourse relations via classifying explicit dis-\ncourse connectives. NAACL HLT .\nSagae, K. 2009. Analysis of discourse structure with syn-\ntactic dependencies and data-driven shift-reduce parsing.\nIWPT-09 .\nScha, R. and L. Polanyi. 1988. An augmented context free\ngrammar for discourse. COLING .\nSidner, C. L. 1979. Towards a computational theory of de\ufb01-\nnite anaphora comprehension in English discourse. Tech-\nnical Report 537, MIT Arti\ufb01cial Intelligence Laboratory,\nCambridge, MA.\nSidner, C. L. 1983. Focusing in the comprehension of de\ufb01-\nnite anaphora. In M. Brady and R. C. Berwick, eds, Com-\nputational Models of Discourse , 267\u2013330. MIT Press.\nSomasundaran, S., J. Burstein, and M. Chodorow. 2014.\nLexical chaining for measuring discourse coherence qual-\nity in test-taker essays. COLING .\nSoricut, R. and D. Marcu. 2003. Sentence level discourse\nparsing using syntactic and lexical information. HLT-",
    "metadata": {
      "source": "24",
      "chunk_id": 61,
      "token_count": 758,
      "chapter_title": ""
    }
  },
  {
    "content": "Rutherford, A. and N. Xue. 2015. Improving the inference\nof implicit discourse relations via classifying explicit dis-\ncourse connectives. NAACL HLT .\nSagae, K. 2009. Analysis of discourse structure with syn-\ntactic dependencies and data-driven shift-reduce parsing.\nIWPT-09 .\nScha, R. and L. Polanyi. 1988. An augmented context free\ngrammar for discourse. COLING .\nSidner, C. L. 1979. Towards a computational theory of de\ufb01-\nnite anaphora comprehension in English discourse. Tech-\nnical Report 537, MIT Arti\ufb01cial Intelligence Laboratory,\nCambridge, MA.\nSidner, C. L. 1983. Focusing in the comprehension of de\ufb01-\nnite anaphora. In M. Brady and R. C. Berwick, eds, Com-\nputational Models of Discourse , 267\u2013330. MIT Press.\nSomasundaran, S., J. Burstein, and M. Chodorow. 2014.\nLexical chaining for measuring discourse coherence qual-\nity in test-taker essays. COLING .\nSoricut, R. and D. Marcu. 2003. Sentence level discourse\nparsing using syntactic and lexical information. HLT-\nNAACL .\nSoricut, R. and D. Marcu. 2006. Discourse generation using\nutility-trained coherence models. COLING/ACL .\nSporleder, C. and A. Lascarides. 2005. Exploiting linguistic\ncues to classify rhetorical relations. RANLP-05 .\nSporleder, C. and M. Lapata. 2005. Discourse chunking and\nits application to sentence compression. EMNLP .\nStab, C. and I. Gurevych. 2014a. Annotating argument com-\nponents and relations in persuasive essays. COLING .Stab, C. and I. Gurevych. 2014b. Identifying argumentative\ndiscourse structures in persuasive essays. EMNLP .\nStab, C. and I. Gurevych. 2017. Parsing argumentation struc-\ntures in persuasive essays. Computational Linguistics ,\n43(3):619\u2013659.\nStede, M. 2011. Discourse processing . Morgan & Claypool.\nStede, M. and J. Schneider. 2018. Argumentation Mining .\nMorgan & Claypool.\nSubba, R. and B. Di Eugenio. 2009. An effective discourse\nparser that uses rich linguistic information. NAACL HLT .\nSurdeanu, M., T. Hicks, and M. A. Valenzuela-Escarcega.\n2015. Two practical rhetorical structure theory parsers.\nNAACL HLT .\nTan, C., V . Niculae, C. Danescu-Niculescu-Mizil, and\nL. Lee. 2016. Winning arguments: Interaction dynam-\nics and persuasion strategies in good-faith online discus-\nsions. WWW-16 .\nTeufel, S., J. Carletta, and M. Moens. 1999. An annotation\nscheme for discourse-level argumentation in research ar-\nticles. EACL .\nTeufel, S., A. Siddharthan, and C. Batchelor. 2009. To-\nwards domain-independent argumentative zoning: Ev-\nidence from chemistry and computational linguistics.\nEMNLP .",
    "metadata": {
      "source": "24",
      "chunk_id": 62,
      "token_count": 752,
      "chapter_title": ""
    }
  },
  {
    "content": "tures in persuasive essays. Computational Linguistics ,\n43(3):619\u2013659.\nStede, M. 2011. Discourse processing . Morgan & Claypool.\nStede, M. and J. Schneider. 2018. Argumentation Mining .\nMorgan & Claypool.\nSubba, R. and B. Di Eugenio. 2009. An effective discourse\nparser that uses rich linguistic information. NAACL HLT .\nSurdeanu, M., T. Hicks, and M. A. Valenzuela-Escarcega.\n2015. Two practical rhetorical structure theory parsers.\nNAACL HLT .\nTan, C., V . Niculae, C. Danescu-Niculescu-Mizil, and\nL. Lee. 2016. Winning arguments: Interaction dynam-\nics and persuasion strategies in good-faith online discus-\nsions. WWW-16 .\nTeufel, S., J. Carletta, and M. Moens. 1999. An annotation\nscheme for discourse-level argumentation in research ar-\nticles. EACL .\nTeufel, S., A. Siddharthan, and C. Batchelor. 2009. To-\nwards domain-independent argumentative zoning: Ev-\nidence from chemistry and computational linguistics.\nEMNLP .\nWalker, M. A., A. K. Joshi, and E. Prince, eds. 1998. Cen-\ntering in Discourse . Oxford University Press.\nWang, Y ., S. Li, and J. Yang. 2018. Toward fast and accurate\nneural discourse segmentation. EMNLP .\nWebber, B. L., M. Egg, and V . Kordoni. 2012. Discourse\nstructure and language technology. Natural Language\nEngineering , 18(4):437\u2013490.\nWolf, F. and E. Gibson. 2005. Representing discourse coher-\nence: A corpus-based analysis. Computational Linguis-\ntics, 31(2):249\u2013287.\nXu, P., H. Saghir, J. S. Kang, T. Long, A. J. Bose, Y . Cao,\nand J. C. K. Cheung. 2019. A cross-domain transferable\nneural coherence model. ACL.\nXue, N., H. T. Ng, S. Pradhan, A. Rutherford, B. L. Web-\nber, C. Wang, and H. Wang. 2016. CoNLL 2016 shared\ntask on multilingual shallow discourse parsing. CoNLL-\n16 shared task .\nYang, D., J. Chen, Z. Yang, D. Jurafsky, and E. H. Hovy.\n2019. Let\u2019s make your request more persuasive: Model-\ning persuasive strategies via semi-supervised neural nets\non crowdfunding platforms. NAACL HLT .\nYu, N., M. Zhang, and G. Fu. 2018. Transition-based neural\nRST parsing with implicit syntax features. COLING .\nYu, Y ., Y . Zhu, Y . Liu, Y . Liu, S. Peng, M. Gong, and\nA. Zeldes. 2019. GumDrop at the DISRPT2019 shared\ntask: A model stacking approach to discourse unit seg-\nmentation and connective detection. Workshop on Dis-\ncourse Relation Parsing and Treebanking 2019 .\nZhou, Y . and N. Xue. 2015. The Chinese Discourse Tree-\nBank: a Chinese corpus annotated with discourse rela-",
    "metadata": {
      "source": "24",
      "chunk_id": 63,
      "token_count": 758,
      "chapter_title": ""
    }
  },
  {
    "content": "neural coherence model. ACL.\nXue, N., H. T. Ng, S. Pradhan, A. Rutherford, B. L. Web-\nber, C. Wang, and H. Wang. 2016. CoNLL 2016 shared\ntask on multilingual shallow discourse parsing. CoNLL-\n16 shared task .\nYang, D., J. Chen, Z. Yang, D. Jurafsky, and E. H. Hovy.\n2019. Let\u2019s make your request more persuasive: Model-\ning persuasive strategies via semi-supervised neural nets\non crowdfunding platforms. NAACL HLT .\nYu, N., M. Zhang, and G. Fu. 2018. Transition-based neural\nRST parsing with implicit syntax features. COLING .\nYu, Y ., Y . Zhu, Y . Liu, Y . Liu, S. Peng, M. Gong, and\nA. Zeldes. 2019. GumDrop at the DISRPT2019 shared\ntask: A model stacking approach to discourse unit seg-\nmentation and connective detection. Workshop on Dis-\ncourse Relation Parsing and Treebanking 2019 .\nZhou, Y . and N. Xue. 2015. The Chinese Discourse Tree-\nBank: a Chinese corpus annotated with discourse rela-\ntions. Language Resources and Evaluation , 49(2):397\u2013\n431.",
    "metadata": {
      "source": "24",
      "chunk_id": 64,
      "token_count": 294,
      "chapter_title": ""
    }
  }
]