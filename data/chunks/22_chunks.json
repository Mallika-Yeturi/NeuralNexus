[
  {
    "content": "# 22\n\n## Page 1\n\nSpeech and Language Processing. Daniel Jurafsky & James H. Martin. Copyright \u00a92024. All\nrights reserved. Draft of January 12, 2025.\nCHAPTER\n22Lexicons for Sentiment, Affect,\nand Connotation\nSome day we\u2019ll be able to measure the power of words\nMaya Angelou\nIn this chapter we turn to tools for interpreting affective meaning, extending our affective\nstudy of sentiment analysis in Chapter 4. We use the word \u2018affective\u2019, following the\ntradition in affective computing (Picard, 1995) to mean emotion, sentiment, per-\nsonality, mood, and attitudes. Affective meaning is closely related to subjectivity , subjectivity\nthe study of a speaker or writer\u2019s evaluations, opinions, emotions, and speculations\n(Wiebe et al., 1999).\nHow should affective meaning be de\ufb01ned? One in\ufb02uential typology of affec-\ntive states comes from Scherer (2000), who de\ufb01nes each class of affective states by\nfactors like its cognitive realization and time course (Fig. 22.1).\nEmotion: Relatively brief episode of response to the evaluation of an external\nor internal event as being of major signi\ufb01cance.\n(angry, sad, joyful, fearful, ashamed, proud, elated, desperate )\nMood: Diffuse affect state, most pronounced as change in subjective feeling, of\nlow intensity but relatively long duration, often without apparent cause.\n(cheerful, gloomy, irritable, listless, depressed, buoyant )\nInterpersonal stance: Affective stance taken toward another person in a spe-\nci\ufb01c interaction, coloring the interpersonal exchange in that situation.\n(distant, cold, warm, supportive, contemptuous, friendly )\nAttitude: Relatively enduring, affectively colored beliefs, preferences, and pre-\ndispositions towards objects or persons.\n(liking, loving, hating, valuing, desiring )\nPersonality traits: Emotionally laden, stable personality dispositions and be-\nhavior tendencies, typical for a person.\n(nervous, anxious, reckless, morose, hostile, jealous )\nFigure 22.1 The Scherer typology of affective states (Scherer, 2000).\nWe can design extractors for each of these kinds of affective states. Chapter 4\nalready introduced sentiment analysis , the task of extracting the positive or negative\norientation that a writer expresses in a text. This corresponds in Scherer\u2019s typology\nto the extraction of attitudes : \ufb01guring out what people like or dislike, from affect-\nrich texts like consumer reviews of books or movies, newspaper editorials, or public\nsentiment in blogs or tweets.\nDetecting emotion andmoods is useful for detecting whether a student is con-\nfused, engaged, or certain when interacting with a tutorial system, whether a caller\nto a help line is frustrated, whether someone\u2019s blog posts or tweets indicated depres-\nsion. Detecting emotions like fear in novels, for example, could help us trace what\ngroups or situations are feared and how that changes over time.",
    "metadata": {
      "source": "22",
      "chunk_id": 0,
      "token_count": 673,
      "chapter_title": "22"
    }
  },
  {
    "content": "## Page 2",
    "metadata": {
      "source": "22",
      "chunk_id": 1,
      "token_count": 4,
      "chapter_title": ""
    }
  },
  {
    "content": "2CHAPTER 22 \u2022 L EXICONS FOR SENTIMENT , AFFECT ,AND CONNOTATION\nDetecting different interpersonal stances can be useful when extracting infor-\nmation from human-human conversations. The goal here is to detect stances like\nfriendliness or awkwardness in interviews or friendly conversations, for example for\nsummarizing meetings or \ufb01nding parts of a conversation where people are especially\nexcited or engaged, conversational hot spots that can help in meeting summariza-\ntion. Detecting the personality of a user\u2014such as whether the user is an extrovert\nor the extent to which they are open to experience \u2014 can help improve conversa-\ntional agents, which seem to work better if they match users\u2019 personality expecta-\ntions (Mairesse and Walker, 2008). And affect is important for generation as well\nas recognition; synthesizing affect is important for conversational agents in various\ndomains, including literacy tutors such as children\u2019s storybooks, or computer games.\nIn Chapter 4 we introduced the use of naive Bayes classi\ufb01cation to classify a\ndocument\u2019s sentiment. Various classi\ufb01ers have been successfully applied to many of\nthese tasks, using all the words in the training set as input to a classi\ufb01er which then\ndetermines the affect status of the text.\nIn this chapter we focus on an alternative model, in which instead of using every\nword as a feature, we focus only on certain words, ones that carry particularly strong\ncues to affect or sentiment. We call these lists of words affective lexicons orsenti-\nment lexicons . These lexicons presuppose a fact about semantics: that words have\naffective meanings orconnotations . The word connotation has different meanings connotations\nin different \ufb01elds, but here we use it to mean the aspects of a word\u2019s meaning that\nare related to a writer or reader\u2019s emotions, sentiment, opinions, or evaluations. In\naddition to their ability to help determine the affective status of a text, connotation\nlexicons can be useful features for other kinds of affective tasks, and for computa-\ntional social science analysis.\nIn the next sections we introduce basic theories of emotion, show how sentiment\nlexicons are a special case of emotion lexicons, and mention some useful lexicons.\nWe then survey three ways for building lexicons: human labeling, semi-supervised,\nand supervised. Finally, we talk about how to detect affect toward a particular entity,\nand introduce connotation frames.\n22.1 De\ufb01ning Emotion\nOne of the most important affective classes is emotion , which Scherer (2000) de\ufb01nes emotion\nas a \u201crelatively brief episode of response to the evaluation of an external or internal\nevent as being of major signi\ufb01cance\u201d.\nDetecting emotion has the potential to improve a number of language processing\ntasks. Emotion recognition could help dialogue systems like tutoring systems detect\nthat a student was unhappy, bored, hesitant, con\ufb01dent, and so on. Automatically\ndetecting emotions in reviews or customer responses (anger, dissatisfaction, trust)\ncould help businesses recognize speci\ufb01c problem areas or ones that are going well.\nEmotion can play a role in medical NLP tasks like helping diagnose depression or\nsuicidal intent. Detecting emotions expressed toward characters in novels might\nplay a role in understanding how different social groups were viewed by society at\ndifferent times.\nComputational models of emotion in NLP have mainly been based on two fami-\nlies of theories of emotion (out of the many studied in the \ufb01eld of affective science).",
    "metadata": {
      "source": "22",
      "chunk_id": 2,
      "token_count": 768,
      "chapter_title": ""
    }
  },
  {
    "content": "We then survey three ways for building lexicons: human labeling, semi-supervised,\nand supervised. Finally, we talk about how to detect affect toward a particular entity,\nand introduce connotation frames.\n22.1 De\ufb01ning Emotion\nOne of the most important affective classes is emotion , which Scherer (2000) de\ufb01nes emotion\nas a \u201crelatively brief episode of response to the evaluation of an external or internal\nevent as being of major signi\ufb01cance\u201d.\nDetecting emotion has the potential to improve a number of language processing\ntasks. Emotion recognition could help dialogue systems like tutoring systems detect\nthat a student was unhappy, bored, hesitant, con\ufb01dent, and so on. Automatically\ndetecting emotions in reviews or customer responses (anger, dissatisfaction, trust)\ncould help businesses recognize speci\ufb01c problem areas or ones that are going well.\nEmotion can play a role in medical NLP tasks like helping diagnose depression or\nsuicidal intent. Detecting emotions expressed toward characters in novels might\nplay a role in understanding how different social groups were viewed by society at\ndifferent times.\nComputational models of emotion in NLP have mainly been based on two fami-\nlies of theories of emotion (out of the many studied in the \ufb01eld of affective science).\nIn one of these families, emotions are viewed as \ufb01xed atomic units, limited in num-\nber, and from which others are generated, often called basic emotions (Tomkins basic emotions",
    "metadata": {
      "source": "22",
      "chunk_id": 3,
      "token_count": 313,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 3\n\n22.1 \u2022 D EFINING EMOTION 3\n1962, Plutchik 1962), a model dating back to Darwin. Perhaps the most well-known\nof this family of theories are the 6 emotions proposed by Ekman (e.g., Ekman 1999)\nto be universally present in all cultures: surprise, happiness, anger, fear, disgust,\nsadness . Another atomic theory is the Plutchik (1980) wheel of emotion, consisting\nof 8 basic emotions in four opposing pairs: joy\u2013sadness ,anger\u2013fear ,trust\u2013disgust ,\nandanticipation\u2013surprise , together with the emotions derived from them, shown in\nFig. 22.2.\nFigure 22.2 Plutchik wheel of emotion.\nThe second class of emotion theories widely used in NLP views emotion as a\nspace in 2 or 3 dimensions (Russell, 1980). Most models include the two dimensions\nvalence andarousal , and many add a third, dominance . These can be de\ufb01ned as:\nvalence: the pleasantness of the stimulus\narousal: the level of alertness, activeness, or energy provoked by the stimulus\ndominance: the degree of control or dominance exerted by the stimulus or the\nemotion\nSentiment can be viewed as a special case of this second view of emotions as points\nin space. In particular, the valence dimension, measuring how pleasant or unpleasant\na word is, is often used directly as a measure of sentiment.\nIn these lexicon-based models of affect, the affective meaning of a word is gen-\nerally \ufb01xed, irrespective of the linguistic context in which a word is used, or the\ndialect or culture of the speaker. By contrast, other models in affective science repre-\nsent emotions as much richer processes involving cognition (Barrett et al., 2007). In\nappraisal theory , for example, emotions are complex processes, in which a person\nconsiders how an event is congruent with their goals, taking into account variables\nlike the agency, certainty, urgency, novelty and control associated with the event\n(Moors et al., 2013). Computational models in NLP taking into account these richer\ntheories of emotion will likely play an important role in future work.",
    "metadata": {
      "source": "22",
      "chunk_id": 4,
      "token_count": 494,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 4",
    "metadata": {
      "source": "22",
      "chunk_id": 5,
      "token_count": 4,
      "chapter_title": ""
    }
  },
  {
    "content": "4CHAPTER 22 \u2022 L EXICONS FOR SENTIMENT , AFFECT ,AND CONNOTATION\n22.2 Available Sentiment and Affect Lexicons\nA wide variety of affect lexicons have been created and released. The most basic\nlexicons label words along one dimension of semantic variability, generally called\n\u201csentiment\u201d or \u201cvalence\u201d.\nIn the simplest lexicons this dimension is represented in a binary fashion, with\na wordlist for positive words and a wordlist for negative words. The oldest is the\nGeneral Inquirer (Stone et al., 1966), which drew on content analysis and on earlyGeneral\nInquirer\nwork in the cognitive psychology of word meaning (Osgood et al., 1957). The Gen-\neral Inquirer has a lexicon of 1915 positive words and a lexicon of 2291 negative\nwords (as well as other lexicons discussed below). The MPQA Subjectivity lexicon\n(Wilson et al., 2005) has 2718 positive and 4912 negative words drawn from prior\nlexicons plus a bootstrapped list of subjective words and phrases (Riloff and Wiebe,\n2003). Each entry in the lexicon is hand-labeled for sentiment and also labeled for\nreliability (strongly subjective or weakly subjective). The polarity lexicon of Hu\nand Liu (2004) gives 2006 positive and 4783 negative words, drawn from product\nreviews, labeled using a bootstrapping method from WordNet.\nPositive admire, amazing, assure, celebration, charm, eager, enthusiastic, excellent, fancy, fan-\ntastic, frolic, graceful, happy, joy, luck, majesty, mercy, nice, patience, perfect, proud,\nrejoice, relief, respect, satisfactorily, sensational, super, terri\ufb01c, thank, vivid, wise, won-\nderful, zest\nNegative abominable, anger, anxious, bad, catastrophe, cheap, complaint, condescending, deceit,\ndefective, disappointment, embarrass, fake, fear, \ufb01lthy, fool, guilt, hate, idiot, in\ufb02ict, lazy,\nmiserable, mourn, nervous, objection, pest, plot, reject, scream, silly, terrible, unfriendly,\nvile, wicked\nFigure 22.3 Some words with consistent sentiment across the General Inquirer (Stone et al., 1966), the\nMPQA Subjectivity lexicon (Wilson et al., 2005), and the polarity lexicon of Hu and Liu (2004).\nSlightly more general than these sentiment lexicons are lexicons that assign each\nword a value on all three affective dimensions. The NRC Valence, Arousal, and\nDominance (V AD) lexicon (Mohammad, 2018a) assigns valence, arousal, and dom-\ninance scores to 20,000 words. Some examples are shown in Fig. 22.4.\nValence Arousal Dominance\nvacation .840 enraged .962 powerful .991\ndelightful .918 party .840 authority .935\nwhistle .653 organized .337 saxophone .482\nconsolation .408 effortless .120 discouraged .0090\ntorture .115 napping .046 weak .045\nFigure 22.4 Values of sample words on the emotional dimensions of Mohammad (2018a).\nThe NRC Word-Emotion Association Lexicon, also called EmoLex (Moham- EmoLex\nmad and Turney, 2013), uses the Plutchik (1980) 8 basic emotions de\ufb01ned above.\nThe lexicon includes around 14,000 words including words from prior lexicons as",
    "metadata": {
      "source": "22",
      "chunk_id": 6,
      "token_count": 781,
      "chapter_title": ""
    }
  },
  {
    "content": "MPQA Subjectivity lexicon (Wilson et al., 2005), and the polarity lexicon of Hu and Liu (2004).\nSlightly more general than these sentiment lexicons are lexicons that assign each\nword a value on all three affective dimensions. The NRC Valence, Arousal, and\nDominance (V AD) lexicon (Mohammad, 2018a) assigns valence, arousal, and dom-\ninance scores to 20,000 words. Some examples are shown in Fig. 22.4.\nValence Arousal Dominance\nvacation .840 enraged .962 powerful .991\ndelightful .918 party .840 authority .935\nwhistle .653 organized .337 saxophone .482\nconsolation .408 effortless .120 discouraged .0090\ntorture .115 napping .046 weak .045\nFigure 22.4 Values of sample words on the emotional dimensions of Mohammad (2018a).\nThe NRC Word-Emotion Association Lexicon, also called EmoLex (Moham- EmoLex\nmad and Turney, 2013), uses the Plutchik (1980) 8 basic emotions de\ufb01ned above.\nThe lexicon includes around 14,000 words including words from prior lexicons as\nwell as frequent nouns, verbs, adverbs and adjectives. Values from the lexicon for\nsome sample words:",
    "metadata": {
      "source": "22",
      "chunk_id": 7,
      "token_count": 295,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 5\n\n22.3 \u2022 C REATING AFFECT LEXICONS BY HUMAN LABELING 5\nWord\nanger\nanticipation\ndisgust\nfear\njoy\nsadness\nsurprise\ntrust\npositive\nnegative\nreward 0100101110\nworry 0101010001\ntenderness 0000100010\nsweetheart 0100110110\nsuddenly 0000001000\nthirst 0100011000\ngarbage 0010000001\nFor a smaller set of 5,814 words, the NRC Emotion/Affect Intensity Lexicon\n(Mohammad, 2018b) contains real-valued scores of association for anger, fear, joy,\nand sadness; Fig. 22.5 shows examples.\nAnger Fear Joy Sadness\noutraged 0.964 horror 0.923 superb 0.864 sad 0.844\nviolence 0.742 anguish 0.703 cheered 0.773 guilt 0.750\ncoup 0.578 pestilence 0.625 rainbow 0.531 unkind 0.547\noust 0.484 stressed 0.531 gesture 0.387 dif\ufb01culties 0.421\nsuspicious 0.484 failing 0.531 warms 0.391 beggar 0.422\nnurture 0.059 con\ufb01dent 0.094 hardship .031 sing 0.017\nFigure 22.5 Sample emotional intensities for words for anger, fear, joy, and sadness from\nMohammad (2018b).\nLIWC ,Linguistic Inquiry and Word Count , is a widely used set of 73 lex- LIWC\nicons containing over 2300 words (Pennebaker et al., 2007), designed to capture\naspects of lexical meaning relevant for social psychological tasks. In addition to\nsentiment-related lexicons like ones for negative emotion ( bad, weird, hate, prob-\nlem, tough ) and positive emotion ( love, nice, sweet ), LIWC includes lexicons for\ncategories like anger, sadness, cognitive mechanisms, perception, tentative, and in-\nhibition, shown in Fig. 22.6.\nThere are various other hand-built affective lexicons. The General Inquirer in-\ncludes additional lexicons for dimensions like strong vs. weak, active vs. passive,\noverstated vs. understated, as well as lexicons for categories like pleasure, pain,\nvirtue, vice, motivation, and cognitive orientation.\nAnother useful feature for various tasks is the distinction between concrete concrete\nwords like banana orbathrobe andabstract words like belief andalthough . The abstract\nlexicon in Brysbaert et al. (2014) used crowdsourcing to assign a rating from 1 to 5\nof the concreteness of 40,000 words, thus assigning banana ,bathrobe , and bagel 5,\nbelief 1.19, although 1.07, and in between words like brisk a 2.5.\n22.3 Creating Affect Lexicons by Human Labeling\nThe earliest method used to build affect lexicons, and still in common use, is to have\nhumans label each word. This is now most commonly done via crowdsourcing : crowdsourcing\nbreaking the task into small pieces and distributing them to a large number of anno-",
    "metadata": {
      "source": "22",
      "chunk_id": 8,
      "token_count": 718,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 6\n\n6CHAPTER 22 \u2022 L EXICONS FOR SENTIMENT , AFFECT ,AND CONNOTATION\nPositive Negative\nEmotion Emotion Insight Inhibition Family Negate\nappreciat* anger* aware* avoid* brother* aren\u2019t\ncomfort* bore* believe careful* cousin* cannot\ngreat cry decid* hesitat* daughter* didn\u2019t\nhappy despair* feel limit* family neither\ninterest fail* \ufb01gur* oppos* father* never\njoy* fear know prevent* grandf* no\nperfect* griev* knew reluctan* grandm* nobod*\nplease* hate* means safe* husband none\nsafe* panic* notice* stop mom nor\nterri\ufb01c suffers recogni* stubborn* mother nothing\nvalue terrify sense wait niece* nowhere\nwow* violent* think wary wife without\nFigure 22.6 Samples from 5 of the 73 lexical categories in LIWC (Pennebaker et al., 2007).\nThe * means the previous letters are a word pre\ufb01x and all words with that pre\ufb01x are included\nin the category.\ntators. Let\u2019s take a look at some of the methodological choices for two crowdsourced\nemotion lexicons.\nThe NRC Emotion Lexicon (EmoLex) (Mohammad and Turney, 2013), labeled\nemotions in two steps. To ensure that the annotators were judging the correct sense\nof the word, they \ufb01rst answered a multiple-choice synonym question that primed\nthe correct sense of the word (without requiring the annotator to read a potentially\nconfusing sense de\ufb01nition). These were created automatically using the headwords\nassociated with the thesaurus category of the sense in question in the Macquarie\ndictionary and the headwords of 3 random distractor categories. An example:\nWhich word is closest in meaning (most related) to startle?\n\u2022automobile\n\u2022shake\n\u2022honesty\n\u2022entertain\nFor each word (e.g. startle ), the annotator was then asked to rate how associated\nthat word is with each of the 8 emotions ( joy,fear,anger , etc.). The associations\nwere rated on a scale of not,weakly ,moderately , and strongly associated. Outlier\nratings were removed, and then each term was assigned the class chosen by the ma-\njority of the annotators, with ties broken by choosing the stronger intensity, and then\nthe 4 levels were mapped into a binary label for each word (no and weak mapped to\n0, moderate and strong mapped to 1).\nThe NRC V AD Lexicon (Mohammad, 2018a) was built by selecting words and\nemoticons from prior lexicons and annotating them with crowd-sourcing using best-\nworst scaling (Louviere et al. 2015, Kiritchenko and Mohammad 2017). In best-best-worst\nscaling\nworst scaling, annotators are given N items (usually 4) and are asked which item is\nthebest (highest) and which is the worst (lowest) in terms of some property. The\nset of words used to describe the ends of the scales are taken from prior literature.\nFor valence, for example, the raters were asked:\nQ1. Which of the four words below is associated with the MOST happi-\nness / pleasure / positiveness / satisfaction / contentedness / hopefulness\nOR LEAST unhappiness / annoyance / negativeness / dissatisfaction /",
    "metadata": {
      "source": "22",
      "chunk_id": 9,
      "token_count": 745,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 7\n\n22.4 \u2022 S EMI-SUPERVISED INDUCTION OF AFFECT LEXICONS 7\nmelancholy / despair? (Four words listed as options.)\nQ2. Which of the four words below is associated with the LEAST hap-\npiness / pleasure / positiveness / satisfaction / contentedness / hopeful-\nness OR MOST unhappiness / annoyance / negativeness / dissatisfaction\n/ melancholy / despair? (Four words listed as options.)\nThe score for each word in the lexicon is the proportion of times the item was chosen\nas the best (highest V/A/D) minus the proportion of times the item was chosen as the\nworst (lowest V/A/D). The agreement between annotations are evaluated by split-\nhalf reliability : split the corpus in half and compute the correlations between thesplit-half\nreliability\nannotations in the two halves.\n22.4 Semi-supervised Induction of Affect Lexicons\nAnother common way to learn sentiment lexicons is to start from a set of seed words\nthat de\ufb01ne two poles of a semantic axis (words like good orbad), and then \ufb01nd ways\nto label each word wby its similarity to the two seed sets. Here we summarize two\nfamilies of seed-based semi-supervised lexicon induction algorithms, axis-based and\ngraph-based.\n22.4.1 Semantic Axis Methods\nOne of the most well-known lexicon induction methods, the Turney and Littman\n(2003) algorithm, is given seed words like good orbad, and then for each word wto\nbe labeled, measures both how similar it is to good and how different it is from bad.\nHere we describe a slight extension of the algorithm due to An et al. (2018), which\nis based on computing a semantic axis .\nIn the \ufb01rst step, we choose seed words by hand. There are two methods for\ndealing with the fact that the affect of a word is different in different contexts: (1)\nstart with a single large seed lexicon and rely on the induction algorithm to \ufb01ne-tune\nit to the domain, or (2) choose different seed words for different genres. Hellrich\net al. (2019) suggests that for modeling affect across different historical time periods,\nstarting with a large modern affect dictionary is better than small seedsets tuned to\nbe stable across time. As an example of the second approach, Hamilton et al. (2016)\nde\ufb01ne one set of seed words for general sentiment analysis, a different set for Twitter,\nand yet another set for sentiment in \ufb01nancial text:\nDomain Positive seeds Negative seeds\nGeneral good, lovely, excellent, fortunate, pleas-\nant, delightful, perfect, loved, love,\nhappybad, horrible, poor, unfortunate, un-\npleasant, disgusting, evil, hated, hate,\nunhappy\nTwitter love, loved, loves, awesome, nice,\namazing, best, fantastic, correct, happyhate, hated, hates, terrible, nasty, awful,\nworst, horrible, wrong, sad\nFinance successful, excellent, pro\ufb01t, bene\ufb01cial,\nimproving, improved, success, gains,\npositivenegligent, loss, volatile, wrong, losses,\ndamages, bad, litigation, failure, down,\nnegative\nIn the second step, we compute embeddings for each of the pole words. These\nembeddings can be off-the-shelf word2vec embeddings, or can be computed directly",
    "metadata": {
      "source": "22",
      "chunk_id": 10,
      "token_count": 731,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 8\n\n8CHAPTER 22 \u2022 L EXICONS FOR SENTIMENT , AFFECT ,AND CONNOTATION\non a speci\ufb01c corpus (for example using a \ufb01nancial corpus if a \ufb01nance lexicon is the\ngoal), or we can \ufb01ne-tune off-the-shelf embeddings to a corpus. Fine-tuning is espe-\ncially important if we have a very speci\ufb01c genre of text but don\u2019t have enough data\nto train good embeddings. In \ufb01ne-tuning, we begin with off-the-shelf embeddings\nlike word2vec, and continue training them on the small target corpus.\nOnce we have embeddings for each pole word, we create an embedding that\nrepresents each pole by taking the centroid of the embeddings of each of the seed\nwords; recall that the centroid is the multidimensional version of the mean. Given\na set of embeddings for the positive seed words S+=fE(w+\n1);E(w+\n2);:::;E(w+\nn)g,\nand embeddings for the negative seed words S\u0000=fE(w\u0000\n1);E(w\u0000\n2);:::;E(w\u0000\nm)g, the\npole centroids are:\nV+=1\nnnX\n1E(w+\ni)\nV\u0000=1\nmmX\n1E(w\u0000\ni) (22.1)\nThe semantic axis de\ufb01ned by the poles is computed just by subtracting the two vec-\ntors:\nVaxis=V+\u0000V\u0000(22.2)\nVaxis, the semantic axis, is a vector in the direction of positive sentiment. Finally,\nwe compute (via cosine similarity) the angle between the vector in the direction of\npositive sentiment and the direction of w\u2019s embedding. A higher cosine means that\nwis more aligned with S+than S\u0000.\nscore (w) = cos\u0000\nE(w);Vaxis\u0001\n=E(w)\u0001Vaxis\nkE(w)kkVaxisk(22.3)\nIf a dictionary of words with sentiment scores is suf\ufb01cient, we\u2019re done! Or if we\nneed to group words into a positive and a negative lexicon, we can use a threshold\nor other method to give us discrete lexicons.\n22.4.2 Label Propagation\nAn alternative family of methods de\ufb01nes lexicons by propagating sentiment labels\non graphs, an idea suggested in early work by Hatzivassiloglou and McKeown\n(1997). We\u2019ll describe the simple SentProp (Sentiment Propagation) algorithm of\nHamilton et al. (2016), which has four steps:\n1.De\ufb01ne a graph : Given word embeddings, build a weighted lexical graph by\nconnecting each word with its knearest neighbors (according to cosine simi-\nlarity). The weights of the edge between words wiandwjare set as:\nEi;j=arccos \n\u0000wi>wj\nkwikkwjk!\n: (22.4)\n2.De\ufb01ne a seed set: Choose positive and negative seed words.",
    "metadata": {
      "source": "22",
      "chunk_id": 11,
      "token_count": 649,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 9\n\n22.4 \u2022 S EMI-SUPERVISED INDUCTION OF AFFECT LEXICONS 9\n3.Propagate polarities from the seed set: Now we perform a random walk on\nthis graph, starting at the seed set. In a random walk, we start at a node and\nthen choose a node to move to with probability proportional to the edge prob-\nability. A word\u2019s polarity score for a seed set is proportional to the probability\nof a random walk from the seed set landing on that word (Fig. 22.7).\n4.Create word scores : We walk from both positive and negative seed sets,\nresulting in positive (rawscore+(wi)) and negative (rawscore\u0000(wi)) raw label\nscores. We then combine these values into a positive-polarity score as:\nscore+(wi) =rawscore+(wi)\nrawscore+(wi) +rawscore\u0000(wi)(22.5)\nIt\u2019s often helpful to standardize the scores to have zero mean and unit variance\nwithin a corpus.\n5.Assign con\ufb01dence to each score: Because sentiment scores are in\ufb02uenced by\nthe seed set, we\u2019d like to know how much the score of a word would change if\na different seed set is used. We can use bootstrap sampling to get con\ufb01dence\nregions, by computing the propagation Btimes over random subsets of the\npositive and negative seed sets (for example using B=50 and choosing 7 of\nthe 10 seed words each time). The standard deviation of the bootstrap sampled\npolarity scores gives a con\ufb01dence measure.\nidolize\nlove\nadore\nappreciate\nlike\n\ufb01nd\ndislike\nsee\nnotice\ndisapprove\nabhor\nhate\nloathe\ndespise\nuncover\nidolize\nlove\nadore\nappreciate\nlike\n\ufb01nd\ndislike\nsee\nnotice\ndisapprove\nabhor\nhate\nloathe\ndespise\nuncover\n(a) (b)\nFigure 22.7 Intuition of the S ENTPROP algorithm. (a) Run random walks from the seed words. (b) Assign\npolarity scores (shown here as colors green or red) based on the frequency of random walk visits.\n22.4.3 Other Methods\nThe core of semisupervised algorithms is the metric for measuring similarity with\nthe seed words. The Turney and Littman (2003) and Hamilton et al. (2016) ap-\nproaches above used embedding cosine as the distance metric: words were labeled\nas positive basically if their embeddings had high cosines with positive seeds and\nlow cosines with negative seeds. Other methods have chosen other kinds of distance\nmetrics besides embedding cosine.\nFor example the Hatzivassiloglou and McKeown (1997) algorithm uses syntactic\ncues; two adjectives are considered similar if they were frequently conjoined by and\nand rarely conjoined by but. This is based on the intuition that adjectives conjoined\nby the words andtend to have the same polarity; positive adjectives are generally\ncoordinated with positive, negative with negative:\nfair and legitimate, corrupt and brutal\nbut less often positive adjectives coordinated with negative:\n*fair and brutal, *corrupt and legitimate",
    "metadata": {
      "source": "22",
      "chunk_id": 12,
      "token_count": 705,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 10",
    "metadata": {
      "source": "22",
      "chunk_id": 13,
      "token_count": 4,
      "chapter_title": ""
    }
  },
  {
    "content": "10 CHAPTER 22 \u2022 L EXICONS FOR SENTIMENT , AFFECT ,AND CONNOTATION\nBy contrast, adjectives conjoined by butare likely to be of opposite polarity:\nfair but brutal\nAnother cue to opposite polarity comes from morphological negation ( un-,im-,\n-less). Adjectives with the same root but differing in a morphological negative ( ad-\nequate/inadequate ,thoughtful/thoughtless ) tend to be of opposite polarity.\nYet another method for \ufb01nding words that have a similar polarity to seed words\nis to make use of a thesaurus like WordNet (Kim and Hovy 2004, Hu and Liu 2004).\nA word\u2019s synonyms presumably share its polarity while a word\u2019s antonyms probably\nhave the opposite polarity. After a seed lexicon is built, each lexicon is updated as\nfollows, possibly iterated.\nLex+: Add synonyms of positive words ( well) and antonyms (like \ufb01ne) of negative\nwords\nLex\u0000: Add synonyms of negative words ( awful ) and antonyms (like evil) of positive\nwords\nAn extension of this algorithm assigns polarity to WordNet senses, called Senti-\nWordNet (Baccianella et al., 2010). Fig. 22.8 shows some examples. SentiWordNet\nSynset Pos Neg Obj\ngood#6 \u2018agreeable or pleasing\u2019 1 0 0\nrespectable#2 honorable#4 good#4 estimable#2 \u2018deserving of esteem\u2019 0.75 0 0.25\nestimable#3 computable#1 \u2018may be computed or estimated\u2019 0 0 1\nsting#1 burn#4 bite#2 \u2018cause a sharp or stinging pain\u2019 0 0.875 .125\nacute#6 \u2018of critical importance and consequence\u2019 0.625 0.125 .250\nacute#4 \u2018of an angle; less than 90 degrees\u2019 0 0 1\nacute#1 \u2018having or experiencing a rapid onset and short but severe course\u2019 0 0.5 0.5\nFigure 22.8 Examples from SentiWordNet 3.0 (Baccianella et al., 2010). Note the differences between senses\nof homonymous words: estimable#3 is purely objective, while estimable#2 is positive; acute can be positive\n(acute#6 ), negative ( acute#1 ), or neutral ( acute #4 ).\nIn this algorithm, polarity is assigned to entire synsets rather than words. A\npositive lexicon is built from all the synsets associated with 7 positive words, and a\nnegative lexicon from synsets associated with 7 negative words. A classi\ufb01er is then\ntrained from this data to take a WordNet gloss and decide if the sense being de\ufb01ned\nis positive, negative or neutral. A further step (involving a random-walk algorithm)\nassigns a score to each WordNet synset for its degree of positivity, negativity, and\nneutrality.\nIn summary, semisupervised algorithms use a human-de\ufb01ned set of seed words\nfor the two poles of a dimension, and use similarity metrics like embedding cosine,\ncoordination, morphology, or thesaurus structure to score words by how similar they\nare to the positive seeds and how dissimilar to the negative seeds.\n22.5 Supervised Learning of Word Sentiment\nSemi-supervised methods require only minimal human supervision (in the form of\nseed sets). But sometimes a supervision signal exists in the world and can be made\nuse of. One such signal is the scores associated with online reviews .",
    "metadata": {
      "source": "22",
      "chunk_id": 14,
      "token_count": 777,
      "chapter_title": ""
    }
  },
  {
    "content": "of homonymous words: estimable#3 is purely objective, while estimable#2 is positive; acute can be positive\n(acute#6 ), negative ( acute#1 ), or neutral ( acute #4 ).\nIn this algorithm, polarity is assigned to entire synsets rather than words. A\npositive lexicon is built from all the synsets associated with 7 positive words, and a\nnegative lexicon from synsets associated with 7 negative words. A classi\ufb01er is then\ntrained from this data to take a WordNet gloss and decide if the sense being de\ufb01ned\nis positive, negative or neutral. A further step (involving a random-walk algorithm)\nassigns a score to each WordNet synset for its degree of positivity, negativity, and\nneutrality.\nIn summary, semisupervised algorithms use a human-de\ufb01ned set of seed words\nfor the two poles of a dimension, and use similarity metrics like embedding cosine,\ncoordination, morphology, or thesaurus structure to score words by how similar they\nare to the positive seeds and how dissimilar to the negative seeds.\n22.5 Supervised Learning of Word Sentiment\nSemi-supervised methods require only minimal human supervision (in the form of\nseed sets). But sometimes a supervision signal exists in the world and can be made\nuse of. One such signal is the scores associated with online reviews .\nThe web contains an enormous number of online reviews for restaurants, movies,\nbooks, or other products, each of which have the text of the review along with an",
    "metadata": {
      "source": "22",
      "chunk_id": 15,
      "token_count": 326,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 11",
    "metadata": {
      "source": "22",
      "chunk_id": 16,
      "token_count": 4,
      "chapter_title": ""
    }
  },
  {
    "content": "22.5 \u2022 S UPERVISED LEARNING OF WORD SENTIMENT 11\nassociated review score: a value that may range from 1 star to 5 stars, or scoring 1\nto 10. Fig. 22.9 shows samples extracted from restaurant, book, and movie reviews.\nMovie review excerpts (IMDb)\n10A great movie. This \ufb01lm is just a wonderful experience. It\u2019s surreal, zany, witty and slapstick\nall at the same time. And terri\ufb01c performances too.\n1This was probably the worst movie I have ever seen. The story went nowhere even though they\ncould have done some interesting stuff with it.\nRestaurant review excerpts (Yelp)\n5The service was impeccable. The food was cooked and seasoned perfectly... The watermelon\nwas perfectly square ... The grilled octopus was ... mouthwatering...\n2...it took a while to get our waters, we got our entree before our starter, and we never received\nsilverware or napkins until we requested them...\nBook review excerpts (GoodReads)\n1I am going to try and stop being deceived by eye-catching titles. I so wanted to like this book\nand was so disappointed by it.\n5This book is hilarious. I would recommend it to anyone looking for a satirical read with a\nromantic twist and a narrator that keeps butting in\nProduct review excerpts (Amazon)\n5The lid on this blender though is probably what I like the best about it... enables you to pour\ninto something without even taking the lid off! ... the perfect pitcher! ... works fantastic.\n1I hate this blender... It is nearly impossible to get frozen fruit and ice to turn into a smoothie...\nYou have to add a TON of liquid. I also wish it had a spout ...\nFigure 22.9 Excerpts from some reviews from various review websites, all on a scale of 1 to 5 stars except\nIMDb, which is on a scale of 1 to 10 stars.\nWe can use this review score as supervision: positive words are more likely to\nappear in 5-star reviews; negative words in 1-star reviews. And instead of just a\nbinary polarity, this kind of supervision allows us to assign a word a more complex\nrepresentation of its polarity: its distribution over stars (or other scores).\nThus in a ten-star system we could represent the sentiment of each word as a\n10-tuple, each number a score representing the word\u2019s association with that polarity\nlevel. This association can be a raw count, or a likelihood P(wjc), or some other\nfunction of the count, for each class cfrom 1 to 10.\nFor example, we could compute the IMDb likelihood of a word like disap-\npoint(ed/ing) occurring in a 1 star review by dividing the number of times disap-\npoint(ed/ing) occurs in 1-star reviews in the IMDb dataset (8,557) by the total num-\nber of words occurring in 1-star reviews (25,395,214), so the IMDb estimate of\nP(disappointingj1)is .0003.\nA slight modi\ufb01cation of this weighting, the normalized likelihood, can be used\nas an illuminating visualization (Potts, 2011)1\nP(wjc) =count (w;c)P\nw2Ccount (w;c)\nPottsScore (w) =P(wjc)P\ncP(wjc)(22.6)\nDividing the IMDb estimate P(disappointingj1)of .0003 by the sum of the likeli-\nhood P(wjc)over all categories gives a Potts score of 0.10. The word disappointing",
    "metadata": {
      "source": "22",
      "chunk_id": 17,
      "token_count": 774,
      "chapter_title": ""
    }
  },
  {
    "content": "Thus in a ten-star system we could represent the sentiment of each word as a\n10-tuple, each number a score representing the word\u2019s association with that polarity\nlevel. This association can be a raw count, or a likelihood P(wjc), or some other\nfunction of the count, for each class cfrom 1 to 10.\nFor example, we could compute the IMDb likelihood of a word like disap-\npoint(ed/ing) occurring in a 1 star review by dividing the number of times disap-\npoint(ed/ing) occurs in 1-star reviews in the IMDb dataset (8,557) by the total num-\nber of words occurring in 1-star reviews (25,395,214), so the IMDb estimate of\nP(disappointingj1)is .0003.\nA slight modi\ufb01cation of this weighting, the normalized likelihood, can be used\nas an illuminating visualization (Potts, 2011)1\nP(wjc) =count (w;c)P\nw2Ccount (w;c)\nPottsScore (w) =P(wjc)P\ncP(wjc)(22.6)\nDividing the IMDb estimate P(disappointingj1)of .0003 by the sum of the likeli-\nhood P(wjc)over all categories gives a Potts score of 0.10. The word disappointing\n1Each element of the Potts score of a word wand category ccan be shown to be a variant of the\npointwise mutual information pmi (w;c)without the log term; see Exercise 22.1.",
    "metadata": {
      "source": "22",
      "chunk_id": 18,
      "token_count": 334,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 12",
    "metadata": {
      "source": "22",
      "chunk_id": 19,
      "token_count": 4,
      "chapter_title": ""
    }
  },
  {
    "content": "12 CHAPTER 22 \u2022 L EXICONS FOR SENTIMENT , AFFECT ,AND CONNOTATION\nthus is associated with the vector [.10, .12, .14, .14, .13, .11, .08, .06, .06, .05]. The\nPotts diagram (Potts, 2011) is a visualization of these word scores, representing the Potts diagram\nprior sentiment of a word as a distribution over the rating categories.\nFig. 22.10 shows the Potts diagrams for 3 positive and 3 negative scalar adjec-\ntives. Note that the curve for strongly positive scalars have the shape of the letter\nJ, while strongly negative scalars look like a reverse J. By contrast, weakly posi-\ntive and negative scalars have a hump-shape, with the maximum either below the\nmean (weakly negative words like disappointing ) or above the mean (weakly pos-\nitive words like good ). These shapes offer an illuminating typology of affective\nmeaning.\nOverviewDataMethodsCategorizationScale inductionLooking aheadExample: attenuators\nIMDB \u2013 53,775 tokens\nCategory-0.50-0.39-0.28-0.17-0.060.060.170.280.390.500.050.090.15Cat = 0.33 (p = 0.004)Cat^2 = -4.02 (p < 0.001)OpenTable \u2013 3,890 tokens\nCategory-0.50-0.250.000.250.500.080.38Cat = 0.11 (p = 0.707)Cat^2 = -6.2 (p = 0.014)Goodreads \u2013 3,424 tokens\nCategory-0.50-0.250.000.250.500.080.190.36Cat = -0.55 (p = 0.128)Cat^2 = -5.04 (p = 0.016)Amazon/Tripadvisor \u2013 2,060 tokens\nCategory-0.50-0.250.000.250.500.120.28Cat = 0.42 (p = 0.207)Cat^2 = -2.74 (p = 0.05)somewhat/r\nIMDB \u2013 33,515 tokens\nCategory-0.50-0.39-0.28-0.17-0.060.060.170.280.390.500.040.090.17Cat = -0.13 (p = 0.284)Cat^2 = -5.37 (p < 0.001)OpenTable \u2013 2,829 tokens\nCategory-0.50-0.250.000.250.500.080.31Cat = 0.2 (p = 0.265)Cat^2 = -4.16 (p = 0.007)Goodreads \u2013 1,806 tokens\nCategory-0.50-0.250.000.250.500.050.120.180.35Cat = -0.87 (p = 0.016)Cat^2 = -5.74 (p = 0.004)Amazon/Tripadvisor \u2013 2,158 tokens\nCategory-0.50-0.250.000.250.500.110.29Cat = 0.54 (p = 0.183)Cat^2 = -3.32 (p = 0.045)fairly/r\nIMDB \u2013 176,264 tokens",
    "metadata": {
      "source": "22",
      "chunk_id": 20,
      "token_count": 757,
      "chapter_title": ""
    }
  },
  {
    "content": "IMDB \u2013 33,515 tokens\nCategory-0.50-0.39-0.28-0.17-0.060.060.170.280.390.500.040.090.17Cat = -0.13 (p = 0.284)Cat^2 = -5.37 (p < 0.001)OpenTable \u2013 2,829 tokens\nCategory-0.50-0.250.000.250.500.080.31Cat = 0.2 (p = 0.265)Cat^2 = -4.16 (p = 0.007)Goodreads \u2013 1,806 tokens\nCategory-0.50-0.250.000.250.500.050.120.180.35Cat = -0.87 (p = 0.016)Cat^2 = -5.74 (p = 0.004)Amazon/Tripadvisor \u2013 2,158 tokens\nCategory-0.50-0.250.000.250.500.110.29Cat = 0.54 (p = 0.183)Cat^2 = -3.32 (p = 0.045)fairly/r\nIMDB \u2013 176,264 tokens\nCategory-0.50-0.39-0.28-0.17-0.060.060.170.280.390.500.050.090.13Cat = -0.43 (p < 0.001)Cat^2 = -3.6 (p < 0.001)OpenTable \u2013 8,982 tokens\nCategory-0.50-0.250.000.250.500.080.140.190.32Cat = -0.64 (p = 0.035)Cat^2 = -4.47 (p = 0.007)Goodreads \u2013 11,895 tokens\nCategory-0.50-0.250.000.250.500.070.150.34Cat = -0.71 (p = 0.072)Cat^2 = -4.59 (p = 0.018)Amazon/Tripadvisor \u2013 5,980 tokens",
    "metadata": {
      "source": "22",
      "chunk_id": 21,
      "token_count": 468,
      "chapter_title": ""
    }
  },
  {
    "content": "Category-0.50-0.250.000.250.500.110.29Cat = 0.54 (p = 0.183)Cat^2 = -3.32 (p = 0.045)fairly/r\nIMDB \u2013 176,264 tokens\nCategory-0.50-0.39-0.28-0.17-0.060.060.170.280.390.500.050.090.13Cat = -0.43 (p < 0.001)Cat^2 = -3.6 (p < 0.001)OpenTable \u2013 8,982 tokens\nCategory-0.50-0.250.000.250.500.080.140.190.32Cat = -0.64 (p = 0.035)Cat^2 = -4.47 (p = 0.007)Goodreads \u2013 11,895 tokens\nCategory-0.50-0.250.000.250.500.070.150.34Cat = -0.71 (p = 0.072)Cat^2 = -4.59 (p = 0.018)Amazon/Tripadvisor \u2013 5,980 tokens\nCategory-0.50-0.250.000.250.500.150.28Cat = 0.26 (p = 0.496)Cat^2 = -2.23 (p = 0.131)pretty/r\u201cPotts&diagrams\u201dPotts,&Christopher .& 2011.&NSF&workshop&on&restructuring& adjectives.goodgreatexcellentdisappointingbadterribletotallyabsolutelyutterlysomewhatfairlyprettyPositive scalarsNegative scalarsEmphaticsAttenuators1  2  3  4  5  6  7  8  9  10rating1  2  3  4  5  6  7  8  9  10rating1  2  3  4  5  6  7  8  9  10rating1  2  3  4  5  6  7  8  9  10rating1  2  3  4  5  6  7  8  9  10rating1  2  3  4  5  6  7  8  9  10rating1  2  3  4  5  6  7  8  9  10rating1  2  3  4  5  6  7  8  9  10rating1  2  3  4  5  6  7  8  9  10rating1  2  3  4  5  6  7  8  9  10rating1  2  3  4  5  6  7  8  9  10rating1  2  3  4  5  6  7  8  9  10rating\nFigure 22.10 Potts diagrams (Potts, 2011) for positive and negative scalar adjectives, show-\ning the J-shape and reverse J-shape for strongly positive and negative adjectives, and the\nhump-shape for more weakly polarized adjectives.",
    "metadata": {
      "source": "22",
      "chunk_id": 22,
      "token_count": 785,
      "chapter_title": ""
    }
  },
  {
    "content": "Figure 22.10 Potts diagrams (Potts, 2011) for positive and negative scalar adjectives, show-\ning the J-shape and reverse J-shape for strongly positive and negative adjectives, and the\nhump-shape for more weakly polarized adjectives.\nFig. 22.11 shows the Potts diagrams for emphasizing and attenuating adverbs.\nNote that emphatics tend to have a J-shape (most likely to occur in the most posi-\ntive reviews) or a U-shape (most likely to occur in the strongly positive and nega-\ntive). Attenuators all have the hump-shape, emphasizing the middle of the scale and\ndownplaying both extremes. The diagrams can be used both as a typology of lexical\nsentiment, and also play a role in modeling sentiment compositionality.\nIn addition to functions like posterior P(cjw), likelihood P(wjc), or normalized\nlikelihood (Eq. 22.6) many other functions of the count of a word occurring with a\nsentiment label have been used. We\u2019ll introduce some of these on page 16, including\nideas like normalizing the counts per writer in Eq. 22.14.\n22.5.1 Log Odds Ratio Informative Dirichlet Prior\nOne thing we often want to do with word polarity is to distinguish between words\nthat are more likely to be used in one category of texts than in another. We may, for\nexample, want to know the words most associated with 1 star reviews versus those\nassociated with 5 star reviews. These differences may not be just related to senti-\nment. We might want to \ufb01nd words used more often by Democratic than Republican",
    "metadata": {
      "source": "22",
      "chunk_id": 23,
      "token_count": 357,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 13",
    "metadata": {
      "source": "22",
      "chunk_id": 24,
      "token_count": 4,
      "chapter_title": ""
    }
  },
  {
    "content": "22.5 \u2022 S UPERVISED LEARNING OF WORD SENTIMENT 13\nOverviewDataMethodsCategorizationScale inductionLooking aheadExample: attenuators\nIMDB \u2013 53,775 tokens\nCategory-0.50-0.39-0.28-0.17-0.060.060.170.280.390.500.050.090.15Cat = 0.33 (p = 0.004)Cat^2 = -4.02 (p < 0.001)OpenTable \u2013 3,890 tokens\nCategory-0.50-0.250.000.250.500.080.38Cat = 0.11 (p = 0.707)Cat^2 = -6.2 (p = 0.014)Goodreads \u2013 3,424 tokens\nCategory-0.50-0.250.000.250.500.080.190.36Cat = -0.55 (p = 0.128)Cat^2 = -5.04 (p = 0.016)Amazon/Tripadvisor \u2013 2,060 tokens\nCategory-0.50-0.250.000.250.500.120.28Cat = 0.42 (p = 0.207)Cat^2 = -2.74 (p = 0.05)somewhat/r\nIMDB \u2013 33,515 tokens\nCategory-0.50-0.39-0.28-0.17-0.060.060.170.280.390.500.040.090.17Cat = -0.13 (p = 0.284)Cat^2 = -5.37 (p < 0.001)OpenTable \u2013 2,829 tokens\nCategory-0.50-0.250.000.250.500.080.31Cat = 0.2 (p = 0.265)Cat^2 = -4.16 (p = 0.007)Goodreads \u2013 1,806 tokens\nCategory-0.50-0.250.000.250.500.050.120.180.35Cat = -0.87 (p = 0.016)Cat^2 = -5.74 (p = 0.004)Amazon/Tripadvisor \u2013 2,158 tokens\nCategory-0.50-0.250.000.250.500.110.29Cat = 0.54 (p = 0.183)Cat^2 = -3.32 (p = 0.045)fairly/r\nIMDB \u2013 176,264 tokens\nCategory-0.50-0.39-0.28-0.17-0.060.060.170.280.390.500.050.090.13Cat = -0.43 (p < 0.001)Cat^2 = -3.6 (p < 0.001)OpenTable \u2013 8,982 tokens\nCategory-0.50-0.250.000.250.500.080.140.190.32Cat = -0.64 (p = 0.035)Cat^2 = -4.47 (p = 0.007)Goodreads \u2013 11,895 tokens\nCategory-0.50-0.250.000.250.500.070.150.34Cat = -0.71 (p = 0.072)Cat^2 = -4.59 (p = 0.018)Amazon/Tripadvisor \u2013 5,980 tokens",
    "metadata": {
      "source": "22",
      "chunk_id": 25,
      "token_count": 759,
      "chapter_title": ""
    }
  },
  {
    "content": "Category-0.50-0.250.000.250.500.110.29Cat = 0.54 (p = 0.183)Cat^2 = -3.32 (p = 0.045)fairly/r\nIMDB \u2013 176,264 tokens\nCategory-0.50-0.39-0.28-0.17-0.060.060.170.280.390.500.050.090.13Cat = -0.43 (p < 0.001)Cat^2 = -3.6 (p < 0.001)OpenTable \u2013 8,982 tokens\nCategory-0.50-0.250.000.250.500.080.140.190.32Cat = -0.64 (p = 0.035)Cat^2 = -4.47 (p = 0.007)Goodreads \u2013 11,895 tokens\nCategory-0.50-0.250.000.250.500.070.150.34Cat = -0.71 (p = 0.072)Cat^2 = -4.59 (p = 0.018)Amazon/Tripadvisor \u2013 5,980 tokens\nCategory-0.50-0.250.000.250.500.150.28Cat = 0.26 (p = 0.496)Cat^2 = -2.23 (p = 0.131)pretty/r\u201cPotts&diagrams\u201dPotts,&Christopher .& 2011.&NSF&workshop&on&restructuring& adjectives.goodgreatexcellentdisappointingbadterribletotallyabsolutelyutterlysomewhatfairlyprettyPositive scalarsNegative scalarsEmphaticsAttenuators1  2  3  4  5  6  7  8  9  10rating1  2  3  4  5  6  7  8  9  10rating1  2  3  4  5  6  7  8  9  10rating1  2  3  4  5  6  7  8  9  10rating1  2  3  4  5  6  7  8  9  10rating1  2  3  4  5  6  7  8  9  10rating1  2  3  4  5  6  7  8  9  10rating1  2  3  4  5  6  7  8  9  10rating1  2  3  4  5  6  7  8  9  10rating1  2  3  4  5  6  7  8  9  10rating1  2  3  4  5  6  7  8  9  10rating1  2  3  4  5  6  7  8  9  10rating\nFigure 22.11 Potts diagrams (Potts, 2011) for emphatic and attenuating adverbs.\nmembers of Congress, or words used more often in menus of expensive restaurants\nthan cheap restaurants.\nGiven two classes of documents, to \ufb01nd words more associated with one cate-",
    "metadata": {
      "source": "22",
      "chunk_id": 26,
      "token_count": 786,
      "chapter_title": ""
    }
  },
  {
    "content": "Figure 22.11 Potts diagrams (Potts, 2011) for emphatic and attenuating adverbs.\nmembers of Congress, or words used more often in menus of expensive restaurants\nthan cheap restaurants.\nGiven two classes of documents, to \ufb01nd words more associated with one cate-\ngory than another, we could measure the difference in frequencies (is a word wmore\nfrequent in class Aor class B?). Or instead of the difference in frequencies we could\ncompute the ratio of frequencies, or compute the log odds ratio (the log of the ratio\nbetween the odds of the two words). We could then sort words by whichever associ-\nation measure we pick, ranging from words overrepresented in category Ato words\noverrepresented in category B.\nThe problem with simple log-likelihood or log odds methods is that they overem-\nphasize differences in very rare words, and often also in very frequent words. Very\nrare words will seem to occur very differently in the two corpora since with tiny\ncounts there may be statistical \ufb02uctations, or even zero occurrences in one corpus\ncompared to non-zero occurrences in the other. Very frequent words will also seem\ndifferent since all counts are large.\nIn this section we walk through the details of one solution to this problem: the\n\u201clog odds ratio informative Dirichlet prior\u201d method of Monroe et al. (2008) that is a\nparticularly useful method for \ufb01nding words that are statistically overrepresented in\none particular category of texts compared to another. It\u2019s based on the idea of using\nanother large corpus to get a prior estimate of what we expect the frequency of each\nword to be.\nLet\u2019s start with the goal: assume we want to know whether the word horrible\noccurs more in corpus ior corpus j. We could compute the log likelihood ratio ,log likelihood\nratio\nusing fi(w)to mean the frequency of word win corpus i, and nito mean the total\nnumber of words in corpus i:\nllr(horrible ) = logPi(horrible )\nPj(horrible )\n=logPi(horrible )\u0000logPj(horrible )\n=logfi(horrible )\nni\u0000logfj(horrible )\nnj(22.7)",
    "metadata": {
      "source": "22",
      "chunk_id": 27,
      "token_count": 471,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 14\n\n14 CHAPTER 22 \u2022 L EXICONS FOR SENTIMENT , AFFECT ,AND CONNOTATION\nInstead, let\u2019s compute the log odds ratio : does horrible have higher odds in ior in log odds ratio\nj:\nlor(horrible ) = log\u0012Pi(horrible )\n1\u0000Pi(horrible )\u0013\n\u0000log\u0012Pj(horrible )\n1\u0000Pj(horrible )\u0013\n=log0\nB@fi(horrible )\nni\n1\u0000fi(horrible )\nni1\nCA\u0000log0\nB@fj(horrible )\nnj\n1\u0000fj(horrible )\nnj1\nCA\n=log\u0012fi(horrible )\nni\u0000fi(horrible )\u0013\n\u0000log\u0012fj(horrible )\nnj\u0000fj(horrible )\u0013\n(22.8)\nThe Dirichlet intuition is to use a large background corpus to get a prior estimate of\nwhat we expect the frequency of each word wto be. We\u2019ll do this very simply by\nadding the counts from that corpus to the numerator and denominator, so that we\u2019re\nessentially shrinking the counts toward that prior. It\u2019s like asking how large are the\ndifferences between iand jgiven what we would expect given their frequencies in\na well-estimated large background corpus.\nThe method estimates the difference between the frequency of word win two\ncorpora iandjvia the prior-modi\ufb01ed log odds ratio for w,d(i\u0000j)\nw, which is estimated\nas:\nd(i\u0000j)\nw =log\u0012fi\nw+aw\nni+a0\u0000(fiw+aw)\u0013\n\u0000log \nfj\nw+aw\nnj+a0\u0000(fj\nw+aw)!\n(22.9)\n(where niis the size of corpus i,njis the size of corpus j,fi\nwis the count of word\nwin corpus i,fj\nwis the count of word win corpus j,a0is the scaled size of the\nbackground corpus, and awis the scaled count of word win the background corpus.)\nIn addition, Monroe et al. (2008) make use of an estimate for the variance of the\nlog\u2013odds\u2013ratio:\ns2\u0010\n\u02c6d(i\u0000j)\nw\u0011\n\u00191\nfiw+aw+1\nfj\nw+aw(22.10)\nThe \ufb01nal statistic for a word is then the z\u2013score of its log\u2013odds\u2013ratio:\n\u02c6d(i\u0000j)\nwr\ns2\u0010\n\u02c6d(i\u0000j)\nw\u0011(22.11)\nThe Monroe et al. (2008) method thus modi\ufb01es the commonly used log odds ratio\nin two ways: it uses the z-scores of the log odds ratio, which controls for the amount\nof variance in a word\u2019s frequency, and it uses counts from a background corpus to\nprovide a prior count for words.\nFig. 22.12 shows the method applied to a dataset of restaurant reviews from\nYelp, comparing the words used in 1-star reviews to the words used in 5-star reviews\n(Jurafsky et al., 2014). The largest difference is in obvious sentiment words, with the\n1-star reviews using negative sentiment words like worse, bad, awful and the 5-star\nreviews using positive sentiment words like great, best, amazing . But there are other\nilluminating differences. 1-star reviews use logical negation ( no, not ), while 5-star\nreviews use emphatics and emphasize universality ( very, highly, every, always ). 1-\nstar reviews use \ufb01rst person plurals ( we, us, our ) while 5 star reviews use the second",
    "metadata": {
      "source": "22",
      "chunk_id": 28,
      "token_count": 791,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 15\n\n22.6 \u2022 U SING LEXICONS FOR SENTIMENT RECOGNITION 15\nperson. 1-star reviews talk about people ( manager, waiter, customer ) while 5-star\nreviews talk about dessert and properties of expensive restaurants like courses and\natmosphere. See Jurafsky et al. (2014) for more details.\nClass Words in 1-star reviews Class Words in 5-star reviews\nNegative worst, rude, terrible, horrible, bad,\nawful, disgusting, bland, tasteless,\ngross, mediocre, overpriced, worse,\npoorPositive great, best, love(d), delicious, amazing,\nfavorite, perfect, excellent, awesome,\nfriendly, fantastic, fresh, wonderful, in-\ncredible, sweet, yum(my)\nNegation no, not Emphatics/\nuniversalsvery, highly, perfectly, de\ufb01nitely, abso-\nlutely, everything, every, always\n1Pl pro we, us, our 2 pro you\n3 pro she, he, her, him Articles a, the\nPast verb was, were, asked, told, said, did,\ncharged, waited, left, tookAdvice try, recommend\nSequencers after, then Conjunct also, as, well, with, and\nNouns manager, waitress, waiter, customer,\ncustomers, attitude, waste, poisoning,\nmoney, bill, minutesNouns atmosphere, dessert, chocolate, wine,\ncourse, menu\nIrrealis\nmodalswould, should Auxiliaries is/\u2019s, can, \u2019ve, are\nComp to, that Prep, other in, of, die, city, mouth\nFigure 22.12 The top 50 words associated with one\u2013star and \ufb01ve-star restaurant reviews in a Yelp dataset of\n900,000 reviews, using the Monroe et al. (2008) method (Jurafsky et al., 2014).\n22.6 Using Lexicons for Sentiment Recognition\nIn Chapter 4 we introduced the naive Bayes algorithm for sentiment analysis. The\nlexicons we have focused on throughout the chapter so far can be used in a number\nof ways to improve sentiment detection.\nIn the simplest case, lexicons can be used when we don\u2019t have suf\ufb01cient training\ndata to build a supervised sentiment analyzer; it can often be expensive to have a\nhuman assign sentiment to each document to train the supervised classi\ufb01er.\nIn such situations, lexicons can be used in a rule-based algorithm for classi\ufb01ca-\ntion. The simplest version is just to use the ratio of positive to negative words: if a\ndocument has more positive than negative words (using the lexicon to decide the po-\nlarity of each word in the document), it is classi\ufb01ed as positive. Often a threshold l\nis used, in which a document is classi\ufb01ed as positive only if the ratio is greater than\nl. If the sentiment lexicon includes positive and negative weights for each word,\nq+\nwandq\u0000\nw, these can be used as well. Here\u2019s a simple such sentiment algorithm:\nf+=X\nws.t.w2positivelexiconq+\nwcount (w)\nf\u0000=X\nws.t.w2negativelexiconq\u0000\nwcount (w)\nsentiment =8\n>>><\n>>>:+iff+\nf\u0000>l\n\u0000iff\u0000\nf+>l\n0 otherwise.(22.12)",
    "metadata": {
      "source": "22",
      "chunk_id": 29,
      "token_count": 726,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 16\n\n16 CHAPTER 22 \u2022 L EXICONS FOR SENTIMENT , AFFECT ,AND CONNOTATION\nIf supervised training data is available, these counts computed from sentiment lex-\nicons, sometimes weighted or normalized in various ways, can also be used as fea-\ntures in a classi\ufb01er along with other lexical or non-lexical features. We return to\nsuch algorithms in Section 22.7.\n22.7 Using Lexicons for Affect Recognition\nDetection of emotion (and the other kinds of affective meaning described by Scherer\n(2000)) can be done by generalizing the algorithms described above for detecting\nsentiment.\nThe most common algorithms involve supervised classi\ufb01cation: a training set is\nlabeled for the affective meaning to be detected, and a classi\ufb01er is built using features\nextracted from the training set. As with sentiment analysis, if the training set is large\nenough, and the test set is suf\ufb01ciently similar to the training set, simply using all\nthe words or all the bigrams as features in a powerful classi\ufb01er like SVM or logistic\nregression, as described in Fig. ??in Chapter 4, is an excellent algorithm whose\nperformance is hard to beat. Thus we can treat affective meaning classi\ufb01cation of a\ntext sample as simple document classi\ufb01cation.\nSome modi\ufb01cations are nonetheless often necessary for very large datasets. For\nexample, the Schwartz et al. (2013) study of personality, gender, and age using 700\nmillion words of Facebook posts used only a subset of the n-grams of lengths 1-\n3. Only words and phrases used by at least 1% of the subjects were included as\nfeatures, and 2-grams and 3-grams were only kept if they had suf\ufb01ciently high PMI\n(PMI greater than 2 \u0003length , where length is the number of words):\npmi(phrase ) =logp(phrase )Y\nw2phrasep(w)(22.13)\nVarious weights can be used for the features, including the raw count in the training\nset, or some normalized probability or log probability. Schwartz et al. (2013), for\nexample, turn feature counts into phrase likelihoods by normalizing them by each\nsubject\u2019s total word use.\np(phrasejsubject ) =freq(phrase ;subject )X\nphrase02vocab (subject )freq(phrase0;subject )(22.14)\nIf the training data is sparser, or not as similar to the test set, any of the lexicons\nwe\u2019ve discussed can play a helpful role, either alone or in combination with all the\nwords and n-grams.\nMany possible values can be used for lexicon features. The simplest is just an\nindicator function, in which the value of a feature fLtakes the value 1 if a particular\ntext has any word from the relevant lexicon L. Using the notation of Chapter 4, in\nwhich a feature value is de\ufb01ned for a particular output class cand document x.\nfL(c;x) =\u001a1 if9w:w2L&w2x&class =c\n0 otherwise",
    "metadata": {
      "source": "22",
      "chunk_id": 30,
      "token_count": 680,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 17\n\n22.8 \u2022 L EXICON -BASED METHODS FOR ENTITY -CENTRIC AFFECT 17\nAlternatively the value of a feature fLfor a particular lexicon Lcan be the total\nnumber of word tokens in the document that occur in L:\nfL=X\nw2Lcount (w)\nFor lexica in which each word is associated with a score or weight, the count can be\nmultiplied by a weight qL\nw:\nfL=X\nw2LqL\nwcount (w)\nCounts can alternatively be logged or normalized per writer as in Eq. 22.14.\nHowever they are de\ufb01ned, these lexicon features are then used in a supervised\nclassi\ufb01er to predict the desired affective category for the text or document. Once\na classi\ufb01er is trained, we can examine which lexicon features are associated with\nwhich classes. For a classi\ufb01er like logistic regression the feature weight gives an\nindication of how associated the feature is with the class.\n22.8 Lexicon-based methods for Entity-Centric Affect\nWhat if we want to get an affect score not for an entire document, but for a particular\nentity in the text? The entity-centric method of Field and Tsvetkov (2019) combines\naffect lexicons with contextual embeddings to assign an affect score to an entity in\ntext. In the context of affect about people, they relabel the Valence/Arousal/Dominance\ndimension as Sentiment/Agency/Power. The algorithm \ufb01rst trains classi\ufb01ers to map\nembeddings to scores:\n1. For each word win the training corpus:\n(a) Use off-the-shelf pretrained encoders (like BERT) to extract a contextual\nembedding efor each instance of the word. No additional \ufb01ne-tuning is\ndone.\n(b) Average over the eembeddings of each instance of wto obtain a single\nembedding vector for one training point w.\n(c) Use the NRC V AD Lexicon to get S, A, and P scores for w.\n2. Train (three) regression models on all words wto predict V , A, D scores from\na word\u2019s average embedding.\nNow given an entity mention min a text, we assign affect scores as follows:\n1. Use the same pretrained LM to get contextual embeddings for min context.\n2. Feed this embedding through the 3 regression models to get S, A, P scores for\nthe entity.\nThis results in a (S,A,P) tuple for a given entity mention; To get scores for the rep-\nresentation of an entity in a complete document, we can run coreference resolution\nand average the (S,A,P) scores for all the mentions. Fig. 22.13 shows the scores\nfrom their algorithm for characters from the movie The Dark Knight when run on\nWikipedia plot summary texts with gold coreference.",
    "metadata": {
      "source": "22",
      "chunk_id": 31,
      "token_count": 614,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 18",
    "metadata": {
      "source": "22",
      "chunk_id": 32,
      "token_count": 4,
      "chapter_title": ""
    }
  },
  {
    "content": "18 CHAPTER 22 \u2022 L EXICONS FOR SENTIMENT , AFFECT ,AND CONNOTATION\nPower ScoreweaklyRachelDentGordanBatmanJokerpowerfully\nSentiment ScorenegativeJokerDentGordanRachelBatmanpositive\nAgency ScoredullDentGordanRachelBatmanJokerscaryFigure 1: Power, sentiment, and agency scores for char-\nacters in The Dark Night as learned through the regres-\nsion model with ELMo embeddings. Scores generally\nalign with character archetypes, i.e. the antagonist has\nthe lowest sentiment score.\nment have resulted in his effective removal from\nthe industry. While articles about the #MeToo\nmovement portray men like Weinstein as unpow-\nerful, we can speculate that the corpora used to\ntrain ELMo and BERT portray them as powerful.\nThus, in a corpus where traditional power roles\nhave been inverted, the embeddings extracted\nfrom ELMo and BERT perform worse than ran-\ndom, as they are biased towards the power struc-\ntures in the data they are trained on. Further ev-\nidence of this exists in the performance of the\nBERT-masked embeddings - whereas these em-\nbeddings generally capture power poorly as com-\npared to the unmasked embeddings (Table 2),\nthey outperform the unmasked embeddings on this\ntask, and even outperform the frequency baseline\nin one setting. Nevertheless, they do not outper-\nform Field et al. (2019 ), likely because they do not\ncapture affect information as well as the unmasked\nembeddings (Table 2).\n4.3 Qualitative Document-level Analysis\nFinally, we qualitatively analyze how well our\nmethod captures affect dimensions by analyzing\nsingle documents in detail. We conduct this anal-\nysis in a domain where we expect entities to ful\ufb01ll\ntraditional power roles and where entity portray-\nals are known. Following Bamman et al. (2013 ),\nwe analyze the Wikipedia plot summary of the\nmovie The Dark Knight ,7focusing on Batman\n(protagonist),8the Joker (antagonist), Jim Gordan\n(law enforcement of\ufb01cer, ally to Batman), Har-\n7http://bit.ly/2XmhRDR\n8We consider Batman/Bruce Wayne to be the same entity.Power Scoreweakly Rachel Joker Dent Gordan Batmanpowerfully\nSentiment Scorenegative Joker Gordan Batman Dent Rachel positive",
    "metadata": {
      "source": "22",
      "chunk_id": 33,
      "token_count": 504,
      "chapter_title": ""
    }
  },
  {
    "content": "tures in the data they are trained on. Further ev-\nidence of this exists in the performance of the\nBERT-masked embeddings - whereas these em-\nbeddings generally capture power poorly as com-\npared to the unmasked embeddings (Table 2),\nthey outperform the unmasked embeddings on this\ntask, and even outperform the frequency baseline\nin one setting. Nevertheless, they do not outper-\nform Field et al. (2019 ), likely because they do not\ncapture affect information as well as the unmasked\nembeddings (Table 2).\n4.3 Qualitative Document-level Analysis\nFinally, we qualitatively analyze how well our\nmethod captures affect dimensions by analyzing\nsingle documents in detail. We conduct this anal-\nysis in a domain where we expect entities to ful\ufb01ll\ntraditional power roles and where entity portray-\nals are known. Following Bamman et al. (2013 ),\nwe analyze the Wikipedia plot summary of the\nmovie The Dark Knight ,7focusing on Batman\n(protagonist),8the Joker (antagonist), Jim Gordan\n(law enforcement of\ufb01cer, ally to Batman), Har-\n7http://bit.ly/2XmhRDR\n8We consider Batman/Bruce Wayne to be the same entity.Power Scoreweakly Rachel Joker Dent Gordan Batmanpowerfully\nSentiment Scorenegative Joker Gordan Batman Dent Rachel positive\nAgency Scoredull Rachel Dent GordanBatman Joker scaryFigure 2: Power, sentiment, and agency scores for char-acters inThe Dark Nightas learned through ASP withELMo embeddings. These scores re\ufb02ect the same pat-terns as the regression model with greater separationbetween characters.vey Dent (ally to Batman who turns evil) andRachel Dawes (primary love interest). To facil-itate extracting example sentences, we score eachinstance of these entities in the narrative separatelyand average across instances to obtain an entityscore for the document.9To maximize our databy capturing every mention of an entity, we per-form co-reference resolution by hand. Addition-ally, based on our results from Table3as well asthe use of Wikipedia data in training the ELMomodel (Peters et al.,2018), we use ELMo embed-dings for our analysis.Figures1and2show results. For refer-ence, we show the entity scores as compared toone polar opposite pair identi\ufb01ed by ASP. Boththe regression model and ASP show similar pat-terns. Batman has high power, while Rachel haslow power. Additionally, the Joker is associatedwith the most negative sentiment, but the high-est agency. Throughout the plot summary, themovie progresses by the Joker taking an aggres-sive action and the other characters responding.We can see this dynamic re\ufb02ected in the Joker\u2019spro\ufb01le score, as a high-powered, high-agency,low-sentiment character, who is the primary plot-driver. In general, ASP shows a greater separationbetween characters than the regression model. Wehypothesize that this occurs because ASP isolatesthe dimensions of interest, while the regression ap-proach captures other confounds, such as that hu-9When we used this averaging metric in other evaluations,we found no signi\ufb01cant change in results. Thus, in other sce-narios, we compute scores over averaged embeddings, ratherthan averaging scores separately computed for each embed-ding to reduce computationally complexity.\nFigure 22.13 Power (dominance), sentiment (valence) and agency (arousal) for characters\nin the movie The Dark Knight computed from embeddings trained on the NRC V AD Lexicon.\nNote the protagonist (Batman) and the antagonist (the Joker) have high power and agency",
    "metadata": {
      "source": "22",
      "chunk_id": 34,
      "token_count": 776,
      "chapter_title": ""
    }
  },
  {
    "content": "Figure 22.13 Power (dominance), sentiment (valence) and agency (arousal) for characters\nin the movie The Dark Knight computed from embeddings trained on the NRC V AD Lexicon.\nNote the protagonist (Batman) and the antagonist (the Joker) have high power and agency\nscores but differ in sentiment, while the love interest Rachel has low power and agency but\nhigh sentiment.\n22.9 Connotation Frames\nThe lexicons we\u2019ve described so far de\ufb01ne a word as a point in affective space. A\nconnotation frame , by contrast, is a lexicon that incorporates a richer kind of gram-connotation\nframe\nmatical structure, by combining affective lexicons with the frame semantic lexicons\nof Chapter 21. The basic insight of connotation frame lexicons is that a predicate\nlike a verb expresses connotations about the verb\u2019s arguments (Rashkin et al. 2016,\nRashkin et al. 2017).\nConsider sentences like:\n(22.15) Country A violated the sovereignty of Country B\n(22.16) the teenager ... survived the Boston Marathon bombing\u201d\nBy using the verb violate in (22.15), the author is expressing their sympathies with\nCountry B, portraying Country B as a victim, and expressing antagonism toward\nthe agent Country A. By contrast, in using the verb survive , the author of (22.16) is\nexpressing that the bombing is a negative experience, and the subject of the sentence,\nthe teenager, is a sympathetic character. These aspects of connotation are inherent\nin the meaning of the verbs violate andsurvive , as shown in Fig. 22.14.\nThe connotation frame lexicons of Rashkin et al. (2016) and Rashkin et al.\n(2017) also express other connotative aspects of the predicate toward each argu-\nment, including the effect (something bad happened to x) value : (x is valuable), and\nmental state : (x is distressed by the event). Connotation frames can also mark the\npower differential between the arguments (using the verb implore means that the\ntheme argument has greater power than the agent), and the agency of each argument\n(waited is low agency). Fig. 22.15 shows a visualization from Sap et al. (2017).\nConnotation frames can be built by hand (Sap et al., 2017), or they can be learned\nby supervised learning (Rashkin et al., 2016), for example using hand-labeled train-\ning data to supervise classi\ufb01ers for each of the individual relations, e.g., whether\nS(writer!Role1) is + or -, and then improving accuracy via global constraints\nacross all relations.",
    "metadata": {
      "source": "22",
      "chunk_id": 35,
      "token_count": 579,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 19",
    "metadata": {
      "source": "22",
      "chunk_id": 36,
      "token_count": 4,
      "chapter_title": ""
    }
  },
  {
    "content": "22.10 \u2022 S UMMARY 19\nWriter\nRole1\nRole2Role1 is asympathetic victimThere issome typeof hardship\nReader+_+__S(writer\u2192role1)S(writer\u2192role2)Connotation Frame for \u201cRole1 survives Role2\u201d S(role1\u2192role2)\nWriter\nRole1\nRole2Role1 is the antagonistRole2 is asympathetic victim\nReader+_+__S(writer\u2192role1)S(writer\u2192role2)Connotation Frame for \u201cRole1 violates Role2\u201d S(role1\u2192role2)\n(a) (b)\nFigure 22.14 Connotation frames for survive andviolate . (a) For survive , the writer and reader have positive\nsentiment toward Role1, the subject, and negative sentiment toward Role2, the direct object. (b) For violate , the\nwriter and reader have positive sentiment instead toward Role2, the direct object.\nAGENTTHEMEpower(AG < TH)VERBimploreHe implored the tribunal to show mercy.The princess waited for her prince.AGENTTHEMEagency(AG) = -VERBwaitFigure 2: The formal notation of the connotation\nframes of power and agency. The \ufb01rst example\nshows the relative power differential implied by\nthe verb \u201cimplored\u201d , i.e., the agent (\u201che\u201d) is in\na position of less power than the theme (\u201cthe tri-\nbunal\u201d). In contrast, \u201cHe demanded the tribunal\nshow mercy\u201d implies that the agent has authority\nover the theme. The second example shows the\nlow level of agency implied by the verb \u201cwaited\u201d .\ninteractive demo website of our \ufb01ndings (see Fig-\nure5in the appendix for a screenshot).2Further-\nmore, as will be seen in Section 4.1, connotation\nframes offer new insights that complement and de-\nviate from the well-known Bechdel test ( Bechdel ,\n1986 ). In particular, we \ufb01nd that high-agency\nwomen through the lens of connotation frames are\nrare in modern \ufb01lms. It is, in part, because some\nmovies (e.g., Snow White) accidentally pass the\nBechdel test and also because even movies with\nstrong female characters are not entirely free from\nthe deeply ingrained biases in social norms.\n2 Connotation Frames of Power and\nAgency\nWe create two new connotation relations, power\nandagency (examples in Figure 3), as an expan-\nsion of the existing connotation frame lexicons.3\nThree AMT crowdworkers annotated the verbs\nwith placeholders to avoid gender bias in the con-\ntext (e.g., Xrescued Y; an example task is shown\nin the appendix in Figure 7). We de\ufb01ne the anno-\ntated constructs as follows:\nPower Differentials Many verbs imply the au-\nthority levels of the agent and theme relative to\n2http://homes .cs.washington .edu/ \u02dcmsap/\nmovie-bias/ .\n3The lexicons and a demo are available at http://\nhomes .cs.washington .edu/ \u02dcmsap/movie-bias/ .power (AG<TH)power (AG>TH)\nagency (AG)=\u0000agency (AG)=+Figure 3: Sample verbs in the connotation frames\nwith high annotator agreement. Size is indicative\nof verb frequency in our corpus (bigger =more\nfrequent), color differences are only for legibility.\none another. For example, if the agent \u201cdom-\ninates\u201d the theme (denoted as power (AG>TH)),",
    "metadata": {
      "source": "22",
      "chunk_id": 37,
      "token_count": 771,
      "chapter_title": ""
    }
  },
  {
    "content": "the deeply ingrained biases in social norms.\n2 Connotation Frames of Power and\nAgency\nWe create two new connotation relations, power\nandagency (examples in Figure 3), as an expan-\nsion of the existing connotation frame lexicons.3\nThree AMT crowdworkers annotated the verbs\nwith placeholders to avoid gender bias in the con-\ntext (e.g., Xrescued Y; an example task is shown\nin the appendix in Figure 7). We de\ufb01ne the anno-\ntated constructs as follows:\nPower Differentials Many verbs imply the au-\nthority levels of the agent and theme relative to\n2http://homes .cs.washington .edu/ \u02dcmsap/\nmovie-bias/ .\n3The lexicons and a demo are available at http://\nhomes .cs.washington .edu/ \u02dcmsap/movie-bias/ .power (AG<TH)power (AG>TH)\nagency (AG)=\u0000agency (AG)=+Figure 3: Sample verbs in the connotation frames\nwith high annotator agreement. Size is indicative\nof verb frequency in our corpus (bigger =more\nfrequent), color differences are only for legibility.\none another. For example, if the agent \u201cdom-\ninates\u201d the theme (denoted as power (AG>TH)),\nthen the agent is implied to have a level of control\nover the theme. Alternatively, if the agent \u201chon-\nors\u201d the theme (denoted as power (AG<TH)), the\nwriter implies that the theme is more important or\nauthoritative. We used AMT crowdsourcing to la-\nbel 1700 transitive verbs for power differentials.\nWith three annotators per verb, the inter-annotator\nagreement is 0.34 (Krippendorff\u2019s \u21b5).\nAgency The agency attributed to the agent of the\nverb denotes whether the action being described\nimplies that the agent is powerful, decisive, and\ncapable of pushing forward their own storyline.\nFor example, a person who is described as \u201cex-\nperiencing\u201d things does not seem as active and de-\ncisive as someone who is described as \u201cdetermin-\ning\u201d things. AMT workers labeled 2000 transi-\ntive verbs for implying high/moderate/low agency\n(inter-annotator agreement of 0.27). We denote\nhigh agency as agency (AG)=+, and low agency\nasagency (AG)=\u0000.\nPairwise agreements on a hard constraint are\n56% and 51% for power and agency, respec-\ntively. Despite this, agreements reach 96% and\n94% when moderate labels are counted as agree-\ning with either high or low labels, showing that an-\nnotators rarely strongly disagree with one another.\nSome contributing factors in the lower KA scores\ninclude the subtlety of choosing between neutral\nFigure 22.15 The connotation frames of Sap et al. (2017), showing that the verb implore\nimplies the agent has lower power than the theme (in contrast, say, with a verb like demanded ),\nand showing the low level of agency of the subject of waited . Figure from Sap et al. (2017).\n22.10 Summary\n\u2022 Many kinds of affective states can be distinguished, including emotions ,moods ,\nattitudes (which include sentiment ),interpersonal stance , and personality .\n\u2022Emotion can be represented by \ufb01xed atomic units often called basic emo-\ntions , or as points in space de\ufb01ned by dimensions like valence andarousal .\n\u2022 Words have connotational aspects related to these affective states, and this",
    "metadata": {
      "source": "22",
      "chunk_id": 38,
      "token_count": 767,
      "chapter_title": ""
    }
  },
  {
    "content": "(inter-annotator agreement of 0.27). We denote\nhigh agency as agency (AG)=+, and low agency\nasagency (AG)=\u0000.\nPairwise agreements on a hard constraint are\n56% and 51% for power and agency, respec-\ntively. Despite this, agreements reach 96% and\n94% when moderate labels are counted as agree-\ning with either high or low labels, showing that an-\nnotators rarely strongly disagree with one another.\nSome contributing factors in the lower KA scores\ninclude the subtlety of choosing between neutral\nFigure 22.15 The connotation frames of Sap et al. (2017), showing that the verb implore\nimplies the agent has lower power than the theme (in contrast, say, with a verb like demanded ),\nand showing the low level of agency of the subject of waited . Figure from Sap et al. (2017).\n22.10 Summary\n\u2022 Many kinds of affective states can be distinguished, including emotions ,moods ,\nattitudes (which include sentiment ),interpersonal stance , and personality .\n\u2022Emotion can be represented by \ufb01xed atomic units often called basic emo-\ntions , or as points in space de\ufb01ned by dimensions like valence andarousal .\n\u2022 Words have connotational aspects related to these affective states, and this\nconnotational aspect of word meaning can be represented in lexicons.\n\u2022 Affective lexicons can be built by hand, using crowd sourcing to label the\naffective content of each word.\n\u2022 Lexicons can be built with semi-supervised , bootstrapping from seed words\nusing similarity metrics like embedding cosine.\n\u2022 Lexicons can be learned in a fully supervised manner, when a convenient\ntraining signal can be found in the world, such as ratings assigned by users on\na review site.\n\u2022 Words can be assigned weights in a lexicon by using various functions of word\ncounts in training texts, and ratio metrics like log odds ratio informative\nDirichlet prior .\n\u2022 Affect can be detected, just like sentiment, by using standard supervised text\nclassi\ufb01cation techniques, using all the words or bigrams in a text as features.",
    "metadata": {
      "source": "22",
      "chunk_id": 39,
      "token_count": 455,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 20",
    "metadata": {
      "source": "22",
      "chunk_id": 40,
      "token_count": 4,
      "chapter_title": ""
    }
  },
  {
    "content": "20 CHAPTER 22 \u2022 L EXICONS FOR SENTIMENT , AFFECT ,AND CONNOTATION\nAdditional features can be drawn from counts of words in lexicons.\n\u2022 Lexicons can also be used to detect affect in a rule-based classi\ufb01er by picking\nthe simple majority sentiment based on counts of words in each lexicon.\n\u2022Connotation frames express richer relations of affective meaning that a pred-\nicate encodes about its arguments.\nBibliographical and Historical Notes\nThe idea of formally representing the subjective meaning of words began with Os-\ngood et al. (1957), the same pioneering study that \ufb01rst proposed the vector space\nmodel of meaning described in Chapter 6. Osgood et al. (1957) had participants rate\nwords on various scales, and ran factor analysis on the ratings. The most signi\ufb01cant\nfactor they uncovered was the evaluative dimension, which distinguished between\npairs like good/bad ,valuable/worthless ,pleasant/unpleasant . This work in\ufb02uenced\nthe development of early dictionaries of sentiment and affective meaning in the \ufb01eld\nofcontent analysis (Stone et al., 1966).\nWiebe (1994) began an in\ufb02uential line of work on detecting subjectivity in text, subjectivity\nbeginning with the task of identifying subjective sentences and the subjective char-\nacters who are described in the text as holding private states, beliefs or attitudes.\nLearned sentiment lexicons such as the polarity lexicons of Hatzivassiloglou and\nMcKeown (1997) were shown to be a useful feature in subjectivity detection (Hatzi-\nvassiloglou and Wiebe 2000, Wiebe 2000).\nThe term sentiment seems to have been introduced in 2001 by Das and Chen\n(2001), to describe the task of measuring market sentiment by looking at the words in\nstock trading message boards. In the same paper Das and Chen (2001) also proposed\nthe use of a sentiment lexicon. The list of words in the lexicon was created by\nhand, but each word was assigned weights according to how much it discriminated\na particular class (say buy versus sell) by maximizing across-class variation and\nminimizing within-class variation. The term sentiment , and the use of lexicons,\ncaught on quite quickly (e.g., inter alia, Turney 2002). Pang et al. (2002) \ufb01rst showed\nthe power of using all the words without a sentiment lexicon; see also Wang and\nManning (2012).\nMost of the semi-supervised methods we describe for extending sentiment dic-\ntionaries drew on the early idea that synonyms and antonyms tend to co-occur in the\nsame sentence (Miller and Charles 1991, Justeson and Katz 1991, Riloff and Shep-\nherd 1997). Other semi-supervised methods for learning cues to affective mean-\ning rely on information extraction techniques, like the AutoSlog pattern extractors\n(Riloff and Wiebe, 2003). Graph based algorithms for sentiment were \ufb01rst sug-\ngested by Hatzivassiloglou and McKeown (1997), and graph propagation became\na standard method (Zhu and Ghahramani 2002, Zhu et al. 2003, Zhou et al. 2004,\nVelikovich et al. 2010). Crowdsourcing can also be used to improve precision by\n\ufb01ltering the result of semi-supervised lexicon learning (Riloff and Shepherd 1997,\nFast et al. 2016).",
    "metadata": {
      "source": "22",
      "chunk_id": 41,
      "token_count": 767,
      "chapter_title": ""
    }
  },
  {
    "content": "caught on quite quickly (e.g., inter alia, Turney 2002). Pang et al. (2002) \ufb01rst showed\nthe power of using all the words without a sentiment lexicon; see also Wang and\nManning (2012).\nMost of the semi-supervised methods we describe for extending sentiment dic-\ntionaries drew on the early idea that synonyms and antonyms tend to co-occur in the\nsame sentence (Miller and Charles 1991, Justeson and Katz 1991, Riloff and Shep-\nherd 1997). Other semi-supervised methods for learning cues to affective mean-\ning rely on information extraction techniques, like the AutoSlog pattern extractors\n(Riloff and Wiebe, 2003). Graph based algorithms for sentiment were \ufb01rst sug-\ngested by Hatzivassiloglou and McKeown (1997), and graph propagation became\na standard method (Zhu and Ghahramani 2002, Zhu et al. 2003, Zhou et al. 2004,\nVelikovich et al. 2010). Crowdsourcing can also be used to improve precision by\n\ufb01ltering the result of semi-supervised lexicon learning (Riloff and Shepherd 1997,\nFast et al. 2016).\nMuch recent work focuses on ways to learn embeddings that directly encode sen-\ntiment or other properties, such as the D ENSIFIER algorithm of Rothe et al. (2016)\nthat learns to transform the embedding space to focus on sentiment (or other) infor-\nmation.",
    "metadata": {
      "source": "22",
      "chunk_id": 42,
      "token_count": 338,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 21\n\nEXERCISES 21\nExercises\n22.1 Show that the relationship between a word wand a category cin the Potts\nScore in Eq. 22.6 is a variant of the pointwise mutual information pmi (w;c)\nwithout the log term.",
    "metadata": {
      "source": "22",
      "chunk_id": 43,
      "token_count": 61,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 22",
    "metadata": {
      "source": "22",
      "chunk_id": 44,
      "token_count": 4,
      "chapter_title": ""
    }
  },
  {
    "content": "22 Chapter 22 \u2022 Lexicons for Sentiment, Affect, and Connotation\nAn, J., H. Kwak, and Y .-Y . Ahn. 2018. SemAxis: A\nlightweight framework to characterize domain-speci\ufb01c\nword semantics beyond sentiment. ACL.\nBaccianella, S., A. Esuli, and F. Sebastiani. 2010. Senti-\nwordnet 3.0: An enhanced lexical resource for sentiment\nanalysis and opinion mining. LREC .\nBarrett, L. F., B. Mesquita, K. N. Ochsner, and J. J. Gross.\n2007. The experience of emotion. Annual Review of Psy-\nchology , 58:373\u2013403.\nBrysbaert, M., A. B. Warriner, and V . Kuperman. 2014.\nConcreteness ratings for 40 thousand generally known\nEnglish word lemmas. Behavior Research Methods ,\n46(3):904\u2013911.\nDas, S. R. and M. Y . Chen. 2001. Yahoo! for Ama-\nzon: Sentiment parsing from small talk on the web.\nEFA 2001 Barcelona Meetings. http://ssrn.com/\nabstract=276189 .\nEkman, P. 1999. Basic emotions. In T. Dalgleish and M. J.\nPower, eds, Handbook of Cognition and Emotion , 45\u201360.\nWiley.\nFast, E., B. Chen, and M. S. Bernstein. 2016. Empath: Un-\nderstanding Topic Signals in Large-Scale Text. CHI.\nField, A. and Y . Tsvetkov. 2019. Entity-centric contextual\naffective analysis. ACL.\nHamilton, W. L., K. Clark, J. Leskovec, and D. Jurafsky.\n2016. Inducing domain-speci\ufb01c sentiment lexicons from\nunlabeled corpora. EMNLP .\nHatzivassiloglou, V . and K. McKeown. 1997. Predicting the\nsemantic orientation of adjectives. ACL.\nHatzivassiloglou, V . and J. Wiebe. 2000. Effects of adjec-\ntive orientation and gradability on sentence subjectivity.\nCOLING .\nHellrich, J., S. Buechel, and U. Hahn. 2019. Modeling word\nemotion in historical language: Quantity beats supposed\nstability in seed word selection. 3rd Joint SIGHUM Work-\nshop on Computational Linguistics for Cultural Heritage,\nSocial Sciences, Humanities and Literature .\nHu, M. and B. Liu. 2004. Mining and summarizing customer\nreviews. SIGKDD-04 .\nJurafsky, D., V . Chahuneau, B. R. Routledge, and N. A.\nSmith. 2014. Narrative framing of consumer sentiment\nin online restaurant reviews. First Monday , 19(4).\nJusteson, J. S. and S. M. Katz. 1991. Co-occurrences of\nantonymous adjectives and their contexts. Computational\nlinguistics , 17(1):1\u201319.\nKim, S. M. and E. H. Hovy. 2004. Determining the sentiment\nof opinions. COLING .\nKiritchenko, S. and S. M. Mohammad. 2017. Best-worst\nscaling more reliable than rating scales: A case study on\nsentiment intensity annotation. ACL.",
    "metadata": {
      "source": "22",
      "chunk_id": 45,
      "token_count": 757,
      "chapter_title": ""
    }
  },
  {
    "content": "tive orientation and gradability on sentence subjectivity.\nCOLING .\nHellrich, J., S. Buechel, and U. Hahn. 2019. Modeling word\nemotion in historical language: Quantity beats supposed\nstability in seed word selection. 3rd Joint SIGHUM Work-\nshop on Computational Linguistics for Cultural Heritage,\nSocial Sciences, Humanities and Literature .\nHu, M. and B. Liu. 2004. Mining and summarizing customer\nreviews. SIGKDD-04 .\nJurafsky, D., V . Chahuneau, B. R. Routledge, and N. A.\nSmith. 2014. Narrative framing of consumer sentiment\nin online restaurant reviews. First Monday , 19(4).\nJusteson, J. S. and S. M. Katz. 1991. Co-occurrences of\nantonymous adjectives and their contexts. Computational\nlinguistics , 17(1):1\u201319.\nKim, S. M. and E. H. Hovy. 2004. Determining the sentiment\nof opinions. COLING .\nKiritchenko, S. and S. M. Mohammad. 2017. Best-worst\nscaling more reliable than rating scales: A case study on\nsentiment intensity annotation. ACL.\nLouviere, J. J., T. N. Flynn, and A. A. J. Marley. 2015. Best-\nworst scaling: Theory, methods and applications . Cam-\nbridge University Press.\nMairesse, F. and M. A. Walker. 2008. Trainable generation of\nbig-\ufb01ve personality styles through data-driven parameter\nestimation. ACL.\nMiller, G. A. and W. G. Charles. 1991. Contextual corre-\nlates of semantics similarity. Language and Cognitive\nProcesses , 6(1):1\u201328.Mohammad, S. M. 2018a. Obtaining reliable human ratings\nof valence, arousal, and dominance for 20,000 English\nwords. ACL.\nMohammad, S. M. 2018b. Word affect intensities. LREC .\nMohammad, S. M. and P. D. Turney. 2013. Crowdsourcing a\nword-emotion association lexicon. Computational Intel-\nligence , 29(3):436\u2013465.\nMonroe, B. L., M. P. Colaresi, and K. M. Quinn. 2008.\nFightin\u2019words: Lexical feature selection and evaluation\nfor identifying the content of political con\ufb02ict. Political\nAnalysis , 16(4):372\u2013403.\nMoors, A., P. C. Ellsworth, K. R. Scherer, and N. H. Frijda.\n2013. Appraisal theories of emotion: State of the art and\nfuture development. Emotion Review , 5(2):119\u2013124.\nOsgood, C. E., G. J. Suci, and P. H. Tannenbaum. 1957. The\nMeasurement of Meaning . University of Illinois Press.\nPang, B., L. Lee, and S. Vaithyanathan. 2002. Thumbs\nup? Sentiment classi\ufb01cation using machine learning tech-\nniques. EMNLP .\nPennebaker, J. W., R. J. Booth, and M. E. Francis. 2007.\nLinguistic Inquiry and Word Count: LIWC 2007 . Austin,\nTX.",
    "metadata": {
      "source": "22",
      "chunk_id": 46,
      "token_count": 753,
      "chapter_title": ""
    }
  },
  {
    "content": "word-emotion association lexicon. Computational Intel-\nligence , 29(3):436\u2013465.\nMonroe, B. L., M. P. Colaresi, and K. M. Quinn. 2008.\nFightin\u2019words: Lexical feature selection and evaluation\nfor identifying the content of political con\ufb02ict. Political\nAnalysis , 16(4):372\u2013403.\nMoors, A., P. C. Ellsworth, K. R. Scherer, and N. H. Frijda.\n2013. Appraisal theories of emotion: State of the art and\nfuture development. Emotion Review , 5(2):119\u2013124.\nOsgood, C. E., G. J. Suci, and P. H. Tannenbaum. 1957. The\nMeasurement of Meaning . University of Illinois Press.\nPang, B., L. Lee, and S. Vaithyanathan. 2002. Thumbs\nup? Sentiment classi\ufb01cation using machine learning tech-\nniques. EMNLP .\nPennebaker, J. W., R. J. Booth, and M. E. Francis. 2007.\nLinguistic Inquiry and Word Count: LIWC 2007 . Austin,\nTX.\nPicard, R. W. 1995. Affective computing. Technical Re-\nport 321, MIT Media Lab Perceputal Computing Techni-\ncal Report. Revised November 26, 1995.\nPlutchik, R. 1962. The emotions: Facts, theories, and a new\nmodel . Random House.\nPlutchik, R. 1980. A general psychoevolutionary theory of\nemotion. In R. Plutchik and H. Kellerman, eds, Emotion:\nTheory, Research, and Experience, Volume 1 , 3\u201333. Aca-\ndemic Press.\nPotts, C. 2011. On the negativity of negation. In N. Li and\nD. Lutz, eds, Proceedings of Semantics and Linguistic\nTheory 20 , 636\u2013659. CLC Publications, Ithaca, NY .\nRashkin, H., E. Bell, Y . Choi, and S. V olkova. 2017. Multi-\nlingual connotation frames: A case study on social media\nfor targeted sentiment analysis and forecast. ACL.\nRashkin, H., S. Singh, and Y . Choi. 2016. Connotation\nframes: A data-driven investigation. ACL.\nRiloff, E. and J. Shepherd. 1997. A corpus-based approach\nfor building semantic lexicons. EMNLP .\nRiloff, E. and J. Wiebe. 2003. Learning extraction patterns\nfor subjective expressions. EMNLP .\nRothe, S., S. Ebert, and H. Sch \u00a8utze. 2016. Ultradense Word\nEmbeddings by Orthogonal Transformation. NAACL\nHLT.\nRussell, J. A. 1980. A circumplex model of affect. Journal\nof personality and social psychology , 39(6):1161\u20131178.\nSap, M., M. C. Prasettio, A. Holtzman, H. Rashkin, and\nY . Choi. 2017. Connotation frames of power and agency\nin modern \ufb01lms. EMNLP .\nScherer, K. R. 2000. Psychological models of emotion. In\nJ. C. Borod, ed., The neuropsychology of emotion , 137\u2013",
    "metadata": {
      "source": "22",
      "chunk_id": 47,
      "token_count": 769,
      "chapter_title": ""
    }
  },
  {
    "content": "lingual connotation frames: A case study on social media\nfor targeted sentiment analysis and forecast. ACL.\nRashkin, H., S. Singh, and Y . Choi. 2016. Connotation\nframes: A data-driven investigation. ACL.\nRiloff, E. and J. Shepherd. 1997. A corpus-based approach\nfor building semantic lexicons. EMNLP .\nRiloff, E. and J. Wiebe. 2003. Learning extraction patterns\nfor subjective expressions. EMNLP .\nRothe, S., S. Ebert, and H. Sch \u00a8utze. 2016. Ultradense Word\nEmbeddings by Orthogonal Transformation. NAACL\nHLT.\nRussell, J. A. 1980. A circumplex model of affect. Journal\nof personality and social psychology , 39(6):1161\u20131178.\nSap, M., M. C. Prasettio, A. Holtzman, H. Rashkin, and\nY . Choi. 2017. Connotation frames of power and agency\nin modern \ufb01lms. EMNLP .\nScherer, K. R. 2000. Psychological models of emotion. In\nJ. C. Borod, ed., The neuropsychology of emotion , 137\u2013\n162. Oxford.\nSchwartz, H. A., J. C. Eichstaedt, M. L. Kern, L. Dziurzyn-\nski, S. M. Ramones, M. Agrawal, A. Shah, M. Kosin-\nski, D. Stillwell, M. E. P. Seligman, and L. H. Ungar.\n2013. Personality, gender, and age in the language of\nsocial media: The open-vocabulary approach. PloS one ,\n8(9):e73791.",
    "metadata": {
      "source": "22",
      "chunk_id": 48,
      "token_count": 401,
      "chapter_title": ""
    }
  },
  {
    "content": "## Page 23\n\nExercises 23\nStone, P., D. Dunphry, M. Smith, and D. Ogilvie. 1966.\nThe General Inquirer: A Computer Approach to Content\nAnalysis . MIT Press.\nTomkins, S. S. 1962. Affect, imagery, consciousness: Vol. I.\nThe positive affects . Springer.\nTurney, P. D. 2002. Thumbs up or thumbs down? Semantic\norientation applied to unsupervised classi\ufb01cation of re-\nviews. ACL.\nTurney, P. D. and M. Littman. 2003. Measuring praise and\ncriticism: Inference of semantic orientation from associ-\nation. ACM Transactions on Information Systems (TOIS) ,\n21:315\u2013346.\nVelikovich, L., S. Blair-Goldensohn, K. Hannan, and R. Mc-\nDonald. 2010. The viability of web-derived polarity lexi-\ncons. NAACL HLT .\nWang, S. and C. D. Manning. 2012. Baselines and bigrams:\nSimple, good sentiment and topic classi\ufb01cation. ACL.\nWiebe, J. 1994. Tracking point of view in narrative. Compu-\ntational Linguistics , 20(2):233\u2013287.\nWiebe, J. 2000. Learning subjective adjectives from corpora.\nAAAI .\nWiebe, J., R. F. Bruce, and T. P. O\u2019Hara. 1999. Develop-\nment and use of a gold-standard data set for subjectivity\nclassi\ufb01cations. ACL.\nWilson, T., J. Wiebe, and P. Hoffmann. 2005. Recogniz-\ning contextual polarity in phrase-level sentiment analysis.\nEMNLP .\nZhou, D., O. Bousquet, T. N. Lal, J. Weston, and\nB. Sch \u00a8olkopf. 2004. Learning with local and global con-\nsistency. NeurIPS .\nZhu, X. and Z. Ghahramani. 2002. Learning from labeled\nand unlabeled data with label propagation. Technical Re-\nport CMU-CALD-02, CMU.\nZhu, X., Z. Ghahramani, and J. Lafferty. 2003. Semi-\nsupervised learning using gaussian \ufb01elds and harmonic\nfunctions. ICML .",
    "metadata": {
      "source": "22",
      "chunk_id": 49,
      "token_count": 524,
      "chapter_title": ""
    }
  }
]