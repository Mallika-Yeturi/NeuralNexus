# 24

## Page 1

Speech and Language Processing. Daniel Jurafsky & James H. Martin. Copyright ©2024. All
rights reserved. Draft of January 12, 2025.
CHAPTER
24Discourse Coherence
And even in our wildest and most wandering reveries, nay in our very dreams,
we shall ﬁnd, if we reﬂect, that the imagination ran not altogether at adven-
tures, but that there was still a connection upheld among the different ideas,
which succeeded each other. Were the loosest and freest conversation to be
transcribed, there would immediately be transcribed, there would immediately
be observed something which connected it in all its transitions.
David Hume, An enquiry concerning human understanding , 1748
Orson Welles’ movie Citizen Kane was groundbreaking in many ways, perhaps most
notably in its structure. The story of the life of ﬁctional media magnate Charles
Foster Kane, the movie does not proceed in chronological order through Kane’s
life. Instead, the ﬁlm begins with Kane’s death (famously murmuring “Rosebud” )
and is structured around ﬂashbacks to his life inserted among scenes of a reporter
investigating his death. The novel idea that the structure of a movie does not have
to linearly follow the structure of the real timeline made apparent for 20th century
cinematography the inﬁnite possibilities and impact of different kinds of coherent
narrative structures.
But coherent structure is not just a fact about movies or works of art. Like
movies, language does not normally consist of isolated, unrelated sentences, but
instead of collocated, structured, coherent groups of sentences. We refer to such
a coherent structured group of sentences as a discourse , and we use the word co- discourse
herence to refer to the relationship between sentences that makes real discourses coherence
different than just random assemblages of sentences. The chapter you are now read-
ing is an example of a discourse, as is a news article, a conversation, a thread on
social media, a Wikipedia page, and your favorite novel.
What makes a discourse coherent? If you created a text by taking random sen-
tences each from many different sources and pasted them together, would that be a
coherent discourse? Almost certainly not. Real discourses exhibit both local coher- local
ence andglobal coherence . Let’s consider three ways in which real discourses are global
locally coherent;
First, sentences or clauses in real discourses are related to nearby sentences in
systematic ways. Consider this example from Hobbs (1979):
(24.1) John took a train from Paris to Istanbul. He likes spinach.
This sequence is incoherent because it is unclear to a reader why the second
sentence follows the ﬁrst; what does liking spinach have to do with train trips? In
fact, a reader might go to some effort to try to ﬁgure out how the discourse could be
coherent; perhaps there is a French spinach shortage? The very fact that hearers try
to identify such connections suggests that human discourse comprehension involves
the need to establish this kind of coherence.
By contrast, in the following coherent example:
(24.2) Jane took a train from Paris to Istanbul. She had to attend a conference.

## Page 2

2CHAPTER 24 • D ISCOURSE COHERENCE
the second sentence gives a REASON for Jane’s action in the ﬁrst sentence. Struc-
tured relationships like REASON that hold between text units are called coherence
relations , and coherent discourses are structured by many such coherence relations.coherence
relations
Coherence relations are introduced in Section 24.1.
A second way a discourse can be locally coherent is by virtue of being “about”
someone or something. In a coherent discourse some entities are salient , and the
discourse focuses on them and doesn’t go back and forth between multiple entities.
This is called entity-based coherence . Consider the following incoherent passage,
in which the salient entity seems to wildly swing from John to Jenny to the piano
store to the living room, back to Jenny, then the piano again:
(24.3) John wanted to buy a piano for his living room.
Jenny also wanted to buy a piano.
He went to the piano store.
It was nearby.
The living room was on the second ﬂoor.
She didn’t ﬁnd anything she liked.
The piano he bought was hard to get up to that ﬂoor.
Entity-based coherence models measure this kind of coherence by tracking salient
entities across a discourse. For example Centering Theory (Grosz et al., 1995), theCentering
Theory
most inﬂuential theory of entity-based coherence, keeps track of which entities in
the discourse model are salient at any point (salient entities are more likely to be
pronominalized or to appear in prominent syntactic positions like subject or object).
In Centering Theory, transitions between sentences that maintain the same salient
entity are considered more coherent than ones that repeatedly shift between entities.
The entity grid model of coherence (Barzilay and Lapata, 2008) is a commonly entity grid
used model that realizes some of the intuitions of the Centering Theory framework.
Entity-based coherence is introduced in Section 24.3.
Finally, discourses can be locally coherent by being topically coherent : nearbytopically
coherent
sentences are generally about the same topic and use the same or similar vocab-
ulary to discuss these topics. Because topically coherent discourses draw from a
single semantic ﬁeld or topic, they tend to exhibit the surface property known as
lexical cohesion (Halliday and Hasan, 1976): the sharing of identical or semanti- lexical cohesion
cally related words in nearby sentences. For example, the fact that the words house ,
chimney ,garret ,closet , and window — all of which belong to the same semantic
ﬁeld— appear in the two sentences in (24.4), or that they share the identical word
shingled , is a cue that the two are tied together as a discourse:
(24.4) Before winter I built a chimney , and shingled the sides of my house ...
I have thus a tight shingled and plastered house ... with a garret and a
closet , a large window on each side....
In addition to the local coherence between adjacent or nearby sentences, dis-
courses also exhibit global coherence . Many genres of text are associated with
particular conventional discourse structures. Academic articles might have sections
describing the Methodology or Results. Stories might follow conventional plotlines
or motifs. Persuasive essays have a particular claim they are trying to argue for,
and an essay might express this claim together with a structured set of premises that
support the argument and demolish potential counterarguments. We’ll introduce
versions of each of these kinds of global coherence.
Why do we care about the local or global coherence of a discourse? Since co-
herence is a property of a well-written text, coherence detection plays a part in any

## Page 3

24.1 • C OHERENCE RELATIONS 3
task that requires measuring the quality of a text. For example coherence can help
in pedagogical tasks like essay grading or essay quality measurement that are trying
to grade how well-written a human essay is (Somasundaran et al. 2014, Feng et al.
2014, Lai and Tetreault 2018). Coherence can also help for summarization; knowing
the coherence relationship between sentences can help know how to select informa-
tion from them. Finally, detecting incoherent text may even play a role in mental
health tasks like measuring symptoms of schizophrenia or other kinds of disordered
language (Ditman and Kuperberg 2010, Elvev ˚ag et al. 2007, Bedi et al. 2015, Iter
et al. 2018).
24.1 Coherence Relations
Recall from the introduction the difference between passages (24.5) and (24.6).
(24.5) Jane took a train from Paris to Istanbul. She likes spinach.
(24.6) Jane took a train from Paris to Istanbul. She had to attend a conference.
The reason (24.6) is more coherent is that the reader can form a connection be-
tween the two sentences, in which the second sentence provides a potential REASON
for the ﬁrst sentences. This link is harder to form for (24.5). These connections
between text spans in a discourse can be speciﬁed as a set of coherence relations .coherence
relation
The next two sections describe two commonly used models of coherence relations
and associated corpora: Rhetorical Structure Theory (RST), and the Penn Discourse
TreeBank (PDTB).
24.1.1 Rhetorical Structure Theory
The most commonly used model of discourse organization is Rhetorical Structure
Theory (RST ) (Mann and Thompson, 1987). In RST relations are deﬁned between RST
two spans of text, generally a nucleus and a satellite . The nucleus is the unit that nucleus
satellite is more central to the writer’s purpose and that is interpretable independently; the
satellite is less central and generally is only interpretable with respect to the nucleus.
Some symmetric relations, however, hold between two nuclei.
Below are a few examples of RST coherence relations, with deﬁnitions adapted
from the RST Treebank Manual (Carlson and Marcu, 2001).
Reason: The nucleus is an action carried out by an animate agent and the satellite
is the reason for the nucleus.
(24.7) [ NUC Jane took a train from Paris to Istanbul.] [ SATShe had to attend a
conference.]
Elaboration: The satellite gives additional information or detail about the situation
presented in the nucleus.
(24.8) [ NUC Dorothy was from Kansas.] [ SATShe lived in the midst of the great
Kansas prairies.]
Evidence: The satellite gives additional information or detail about the situation
presented in the nucleus. The information is presented with the goal of convince the
reader to accept the information presented in the nucleus.
(24.9) [ NUC Kevin must be here.] [ SATHis car is parked outside.]

## Page 4

4CHAPTER 24 • D ISCOURSE COHERENCE
Attribution: The satellite gives the source of attribution for an instance of reported
speech in the nucleus.
(24.10) [ SATAnalysts estimated] [ NUC that sales at U.S. stores declined in the
quarter, too]
List: In this multinuclear relation, a series of nuclei is given, without contrast or
explicit comparison:
(24.11) [ NUC Billy Bones was the mate; ] [ NUC Long John, he was quartermaster]
RST relations are traditionally represented graphically; the asymmetric Nucleus-
Satellite relation is represented with an arrow from the satellite to the nucleus:
Kevin must be here.His car is parked outsideevidence
We can also talk about the coherence of a larger text by considering the hierar-
chical structure between coherence relations. Figure 24.1 shows the rhetorical struc-
ture of a paragraph from Marcu (2000a) for the text in (24.12) from the Scientiﬁc
American magazine.
(24.12) With its distant orbit–50 percent farther from the sun than Earth–and slim
atmospheric blanket, Mars experiences frigid weather conditions. Surface
temperatures typically average about -60 degrees Celsius (-76 degrees
Fahrenheit) at the equator and can dip to -123 degrees C near the poles. Only
the midday sun at tropical latitudes is warm enough to thaw ice on occasion,
but any liquid water formed in this way would evaporate almost instantly
because of the low atmospheric pressure.
Title
(1)
Mars2-9
evidence
2-3
background
  (2)
WIth its 
distant orbit  
<p> -- 50
 percent 
farther from 
the sun than 
Earth -- </p> 
and slim 
atmospheric 
blanket,(3)
Mars
experiences
frigid weather
conditions.4-9
elaboration-additional
(4)
Surface 
temperatures
 typically average 
about -60 
degrees Celsius
 <p> (-76 degrees
Fahrenheit)</p>
 at the equator4-5
List
(5)
and can dip
to -123
degrees C
near the
poles.6-9
Contrast
6-7
(6)
Only the
midday sun at
tropical latitudes
is warm enough(7)
to thaw ice
on occasion,purpose8-9
explanation-argumentative
(8)
but any liquid water
formed in this way 
would evaporate 
almost instantly(9)
because of
the low
atmospheric
pressure.
Figure 24.1 A discourse tree for the Scientiﬁc American text in (24.12), from Marcu (2000a). Note that
asymmetric relations are represented with a curved arrow from the satellite to the nucleus.
The leaves in the Fig. 24.1 tree correspond to text spans of a sentence, clause or
phrase that are called elementary discourse units orEDU s in RST; these units can EDU
also be referred to as discourse segments . Because these units may correspond to
arbitrary spans of text, determining the boundaries of an EDU is an important task
for extracting coherence relations. Roughly speaking, one can think of discourse

## Page 5

24.1 • C OHERENCE RELATIONS 5
segments as being analogous to constituents in sentence syntax, and indeed as we’ll
see in Section 24.2 we generally draw on parsing algorithms to infer discourse struc-
ture.
There are corpora for many discourse coherence models; the RST Discourse
TreeBank (Carlson et al., 2001) is the largest available discourse corpus. It con-
sists of 385 English language documents selected from the Penn Treebank, with full
RST parses for each one, using a large set of 78 distinct relations, grouped into 16
classes. RST treebanks exist also for Spanish, German, Basque, Dutch and Brazilian
Portuguese (Braud et al., 2017).
Now that we’ve seen examples of coherence, we can see more clearly how a
coherence relation can play a role in summarization or information extraction. For
example, the nuclei of a text presumably express more important information than
the satellites, which might be dropped in a summary.
24.1.2 Penn Discourse TreeBank (PDTB)
The Penn Discourse TreeBank (PDTB ) is a second commonly used dataset that PDTB
embodies another model of coherence relations (Miltsakaki et al. 2004, Prasad et al.
2008, Prasad et al. 2014). PDTB labeling is lexically grounded . Instead of asking
annotators to directly tag the coherence relation between text spans, they were given
a list of discourse connectives , words that signal discourse relations, like because ,discourse
connectives
although ,when ,since , oras a result . In a part of a text where these words marked a
coherence relation between two text spans, the connective and the spans were then
annotated, as in Fig. 24.13, where the phrase as a result signals a causal relationship
between what PDTB calls Arg1 (the ﬁrst two sentences, here in italics) and Arg2
(the third sentence, here in bold).
(24.13) Jewelry displays in department stores were often cluttered and uninspired.
And the merchandise was, well, fake. As a result , marketers of faux gems
steadily lost space in department stores to more fashionable
rivals—cosmetics makers.
(24.14) In July, the Environmental Protection Agency imposed a gradual ban on
virtually all uses of asbestos. (implicit=as a result )By 1997, almost all
remaining uses of cancer-causing asbestos will be outlawed.
Not all coherence relations are marked by an explicit discourse connective, and
so the PDTB also annotates pairs of neighboring sentences with no explicit signal,
like (24.14). The annotator ﬁrst chooses the word or phrase that could have been its
signal (in this case as a result ), and then labels its sense. For example for the am-
biguous discourse connective since annotators marked whether it is using a C AUSAL
or a T EMPORAL sense.
The ﬁnal dataset contains roughly 18,000 explicit relations and 16,000 implicit
relations. Fig. 24.2 shows examples from each of the 4 major semantic classes, while
Fig. 24.3 shows the full tagset.
Unlike the RST Discourse Treebank, which integrates these pairwise coherence
relations into a global tree structure spanning an entire discourse, the PDTB does not
annotate anything above the span-pair level, making no commitment with respect to
higher-level discourse structure.
There are also treebanks using similar methods for other languages; (24.15)
shows an example from the Chinese Discourse TreeBank (Zhou and Xue, 2015).
Because Chinese has a smaller percentage of explicit discourse connectives than
English (only 22% of all discourse relations are marked with explicit connectives,

## Page 6

6CHAPTER 24 • D ISCOURSE COHERENCE
Class Type Example
TEMPORAL SYNCHRONOUS The parishioners of St. Michael and All Angels stop to chat at
the church door, as members here always have. (Implicit while )
In the tower, ﬁve men and women pull rhythmically on ropes
attached to the same ﬁve bells that ﬁrst sounded here in 1614.
CONTINGENCY REASON Also unlike Mr. Ruder, Mr. Breeden appears to be in a position
to get somewhere with his agenda. (implicit=because )As a for-
mer White House aide who worked closely with Congress,
he is savvy in the ways of Washington.
COMPARISON CONTRAST The U.S. wants the removal of what it perceives as barriers to
investment; Japan denies there are real barriers.
EXPANSION CONJUNCTION Not only do the actors stand outside their characters and make
it clear they are at odds with them, but they often literally stand
on their heads.
Figure 24.2 The four high-level semantic distinctions in the PDTB sense hierarchy
Temporal Comparison
Asynchronous Contrast (Juxtaposition, Opposition)
Synchronous (Precedence, Succession) Pragmatic Contrast (Juxtaposition, Opposition)
Concession (Expectation, Contra-expectation)
Pragmatic Concession
Contingency Expansion
Cause (Reason, Result) Exception
Pragmatic Cause (Justiﬁcation) Instantiation
Condition (Hypothetical, General, Unreal
Present/Past, Factual Present/Past)Restatement (Speciﬁcation, Equivalence, Generalization)
Pragmatic Condition (Relevance, Implicit As-
sertion)Alternative (Conjunction, Disjunction, Chosen Alterna-
tive)
List
Figure 24.3 The PDTB sense hierarchy. There are four top-level c¯lasses, 16 types, and 23 subtypes (not all
types have subtypes). 11 of the 16 types are commonly used for implicit argument classiﬁcation; the 5 types in
italics are too rare in implicit labeling to be used.
compared to 47% in English), annotators labeled this corpus by directly mapping
pairs of sentences to 11 sense tags, without starting with a lexical discourse connec-
tor.
(24.15) [ Conn为] [Arg2推动图们江地区开发]，[Arg1韩国捐款一百万美元
设立了图们江发展基金]
“[In order to] [ Arg2 promote the development of the Tumen River region],
[Arg1 South Korea donated one million dollars to establish the Tumen
River Development Fund].”
These discourse treebanks have been used for shared tasks on multilingual dis-
course parsing (Xue et al., 2016).
24.2 Discourse Structure Parsing
Given a sequence of sentences, how can we automatically determine the coherence
relations between them? This task is often called discourse parsing (even thoughdiscourse
parsing
for PDTB we are only assigning labels to leaf spans and not building a full parse

## Page 7

24.2 • D ISCOURSE STRUCTURE PARSING 7
tree as we do for RST).
24.2.1 EDU segmentation for RST parsing
RST parsing is generally done in two stages. The ﬁrst stage, EDU segmentation ,
extracts the start and end of each EDU. The output of this stage would be a labeling
like the following:
(24.16) [Mr. Rambo says] e1[that a 3.2-acre property] e2[overlooking the San
Fernando Valley] e3[is priced at $4 million] e4[because the late actor Erroll
Flynn once lived there.] e5
Since EDUs roughly correspond to clauses, early models of EDU segmentation
ﬁrst ran a syntactic parser, and then post-processed the output. Modern systems
generally use neural sequence models supervised by the gold EDU segmentation in
datasets like the RST Discourse Treebank. Fig. 24.4 shows an example architecture
simpliﬁed from the algorithm of Lukasik et al. (2020) that predicts for each token
whether or not it is a break. Here the input sentence is passed through an encoder
and then passed through a linear layer and a softmax to produce a sequence of 0s
and 1, where 1 indicates the start of an EDU.
Mr.RambosaysthatENCODER…0001linear layersoftmaxEDU break
Figure 24.4 Predicting EDU segment beginnings from encoded text.
24.2.2 RST parsing
Tools for building RST coherence structure for a discourse have long been based on
syntactic parsing algorithms like shift-reduce parsing (Marcu, 1999). Many modern
RST parsers since Ji and Eisenstein (2014) draw on the neural syntactic parsers we
saw in Chapter 20, using representation learning to build representations for each
span, and training a parser to choose the correct shift and reduce actions based on
the gold parses in the training set.
We’ll describe the shift-reduce parser of Yu et al. (2018). The parser state con-
sists of a stack and a queue, and produces this structure by taking a series of actions
on the states. Actions include:
•shift : pushes the ﬁrst EDU in the queue onto the stack creating a single-node
subtree.
•reduce (l,d): merges the top two subtrees on the stack, where lis the coherence
relation label, and dis the nuclearity direction, d2fNN ;NS ;SNg.
As well as the pop root operation, to remove the ﬁnal tree from the stack.
Fig. 24.6 shows the actions the parser takes to build the structure in Fig. 24.5.

## Page 8

8CHAPTER 24 • D ISCOURSE COHERENCE
560e1 e2 e3 e4attr elabelab e1: American Telephone & Telegraph Co. said it
e2: will lay off 75 to 85 technicians here , effective Nov. 1.
e3: The workers install , maintain and repair its private branch exchanges,
e4: which are large intracompany telephone networks.
Figure 1: An example of RST discourse tree, where {e1,e2,e3,e4}are EDUs, attr andelab are
discourse relation labels, and arrows indicate the nuclearities of discourse relations.
RST discourse parsing. Other studies still adopt discrete syntax features proposed by statistical models,
feeding them into neural network models (Braud et al., 2016; Braud et al., 2017).
The above approaches model syntax trees in an explicit way, requiring discrete syntax parsing outputs
as inputs for RST parsing. These approaches may suffer from the error propagation problem. Syntax trees
produced by a supervised syntax parsing model could have errors, which may propagate into discourse
parsing models. The problem could be extremely serious when inputs of discourse parsing have different
distributions with the training data of the supervised syntax parser. Recently, Zhang et al. (2017) suggest
an alternative method, which extracts syntax features from a Bi-Afﬁne dependency parser (Dozat and
Manning, 2016), and the method gives competitive performances on relation extraction. It actually
represents syntax trees implicitly, thus it can reduce the error propagation problem.
In this work, we investigate the implicit syntax feature extraction approach for RST parsing. In ad-
dition, we propose a transition-based neural model for this task, which is able to incorporate various
features ﬂexibly. We exploit hierarchical bi-directional LSTMs (Bi-LSTMs) to encode texts, and further
enhance the transition-based model with dynamic oracle. Based on the proposed model, we study the
effectiveness of our proposed implicit syntax features. We conduct experiments on a standard RST dis-
course TreeBank (Carlson et al., 2003). First, we evaluate the performance of our proposed transition-
based baseline, ﬁnding that the model is able to achieve strong performances after applying dynamic
oracle. Then we evaluate the effectiveness of implicit syntax features extracted from a Bi-Afﬁne depen-
dency parser. Results show that the implicit syntax features are effective, giving better performances than
explicit Tree-LSTM (Li et al., 2015b). Our codes will be released for public under the Apache License
2.0 at https://github.com/yunan4nlp/NNDisParser .
In summary, we mainly make the following two contributions in this work: (1) we propose a transition-
based neural RST discourse parsing model with dynamic oracle, (2) we compare three different syntactic
integration approaches proposed by us. The rest of the paper is organized as follows. Section 2 describes
our proposed models including the transition-based neural model, the dynamic oracle strategy and the
implicit syntax feature extraction approach. Section 3 presents the experiments to evaluate our models.
Section 4 shows the related work. Finally, section 5 draws conclusions.
2 Transition-based Discourse Parsing
We follow Ji and Eisenstein (2014), exploiting a transition-based framework for RST discourse parsing.
The framework is conceptually simple and ﬂexible to support arbitrary features, which has been widely
used in a number of NLP tasks (Zhu et al., 2013; Dyer et al., 2015; Zhang et al., 2016). In addition, a
transition-based model formalizes a certain task into predicting a sequence of actions, which is essential
similar to sequence-to-sequence models proposed recently (Bahdanau et al., 2014). In the following,
we ﬁrst describe the transition system for RST discourse parsing, and then introduce our neural network
model by its encoder and decoder parts, respectively. Thirdly, we present our proposed dynamic oracle
strategy aiming to enhance the transition-based model. Then we introduce the integration method of
implicit syntax features. Finally we describe the training method of our neural network models.
2.1 The Transition-based System
The transition-based framework converts a structural learning problem into a sequence of action predic-
tions, whose key point is a transition system. A transition system consists of two parts: states and actions.
The states are used to store partially-parsed results and the actions are used to control state transitions.
Figure 24.5 Example RST discourse tree, showing four EDUs. Figure from Yu et al. (2018).
561Step Stack Queue Action Relation
1 ?e1,e2,e3,e4 SH ?
2 e1 e2,e3,e4 SH ?
3 e1,e2 e3,e4 RD(attr,SN) ?
4 e1:2 e3,e4 SH de1e2
5 e1:2,e3 e4 SH de1e2
6 e1:2,e3,e4 ?RD(elab,NS) de1e2
7 e1:2,e3:4 ?RD(elab,SN) de1e2,de3e4
8 e1:4 ? PR de1e2,de3e4,\e1:2e3:4
Table 1: An example of the transition-based system for RST discourse parsing.
The initial state is an empty state, and the ﬁnal state represents a full result. There are three kinds of
actions in our transition system:
•Shift (SH), which removes the ﬁrst EDU in the queue onto the stack, forming a single-node subtree.
•Reduce (RD) ( l,d), which merges the top two subtrees on the stack, where lis a discourse relation
label, and d2{NN,NS,SN}indicates the relation nuclearity (nuclear (N) or satellite (S)).
•Pop Root (PR), which pops out the top tree on the stack, marking the decoding being completed,
when the stack holds only one subtree and the queue is empty.
Given the RST tree as shown in Figure 1, it can be generated by the following action sequence: {SH,
SH, RD (attr,SN) , SH, SH, RD (elab,NS) , RD (elab,SN) , PR}. Table 1 shows the decoding
process in detail. By this way, we naturally convert RST discourse parsing into predicting a sequence of
transition actions, where each line includes a state and next step action referring to the tree.
2.2 Encoder-Decoder
Previous transition-based RST discourse parsing studies exploit statistical models, using manually-
designed discrete features (Sagae, 2009; Heilman and Sagae, 2015; Wang et al., 2017). In this work, we
propose a transition-based neural model for RST discourse parsing, which follows an encoder-decoder
framework. Given an input sequence of EDUs {e1,e2,. . . ,e n}, the encoder computes the input represen-
tations {he
1,he
2,. . . ,he
n}, and the decoder predicts next step actions conditioned on the encoder outputs.
2.2.1 Encoder
We follow Li et al. (2016), using hierarchical Bi-LSTMs to encode the source EDU inputs, where the
ﬁrst-layer is used to represent sequencial words inside of EDUs, and the second layer is used to represent
sequencial EDUs. Given an input sentence {w1,w2,. . . ,w m}, ﬁrst we represent each word by its form
(e.g., wi) and POS tag (e.g. ti), concatenating their neural embeddings. By this way, the input vectors
of the ﬁrst-layer Bi-LSTM are {xw
1,xw
2,. . . ,xw
m}, where xw
i=emb (wi) emb (ti), and then we apply
Bi-LSTM directly, obtaining:
{hw
1,hw
2,. . . ,hw
m}=Bi-LSTM ({xw
1,xw
2,. . . ,xw
m}) (1)
The second-layer Bi-LSTM is built over sequential EDUs. We should ﬁrst obtain a suitable representa-
tion for each EDU, which is composed by a span of words inside a certain sentence. Assuming an EDU
with its words by {ws,ws+1,. . . ,w t}, after applying the ﬁrst-layer Bi-LSTM, we obtain their representa-
tions by {hw
s,hw
s+1...,hw
t}, then we calculate the EDU representation by average pooling:
xe=1
t s+1tX
shw
k (2)
When the EDU representations are ready, we apply the second-layer Bi-LSTM directly, resulting:
{he
1,he
2,. . . ,he
n}=Bi-LSTM ({xe
1,xe
2,. . . ,xe
n}) (3)
Figure 24.6 Parsing the example of Fig. 24.5 using a shift-reduce parser. Figure from Yu
et al. (2018).
The Yu et al. (2018) uses an encoder-decoder architecture, where the encoder
represents the input span of words and EDUs using a hierarchical biLSTM. The
ﬁrst biLSTM layer represents the words inside an EDU, and the second represents
the EDU sequence. Given an input sentence w1;w2; :::;wm, the words can be repre-
sented as usual (by static embeddings, combinations with character embeddings or
tags, or contextual embeddings) resulting in an input word representation sequence
xw
1;xw
2; :::;xw
m. The result of the word-level biLSTM is then a sequence of hwvalues:
hw
1;hw
2; :::;hw
m=biLSTM (xw
1;xw
2; :::;xw
m) (24.17)
An EDU of span ws;ws+1; :::;wtthen has biLSTM output representation hw
s;hw
s+1; :::;hw
t,
and is represented by average pooling:
xe=1
t s+1tX
k=shw
k (24.18)
The second layer uses this input to compute a ﬁnal representation of the sequence of
EDU representations he:
he
1;he
2; :::;he
n=biLSTM (xe
1;xe
2; :::;xe
n) (24.19)
The decoder is then a feedforward network Wthat outputs an action obased on a
concatenation of the top three subtrees on the stack ( so;s1;s2) plus the ﬁrst EDU in
the queue (q0):
o=W(ht
s0;ht
s1;ht
s2;he
q0) (24.20)
where the representation of the EDU on the queue he
q0comes directly from the
encoder, and the three hidden vectors representing partial trees are computed by
average pooling over the encoder output for the EDUs in those trees:
hts=1
j i+1jX
k=ihe
k (24.21)

## Page 9

24.2 • D ISCOURSE STRUCTURE PARSING 9
Training ﬁrst maps each RST gold parse tree into a sequence of oracle actions, and
then uses the standard cross-entropy loss (with l2regularization) to train the system
to take such actions. Give a state Sand oracle action a, we ﬁrst compute the decoder
output using Eq. 24.20, apply a softmax to get probabilities:
pa=exp(oa)P
a02Aexp(oa0)(24.22)
and then computing the cross-entropy loss:
LCE() = log(pa)+l
2jjQjj2(24.23)
RST discourse parsers are evaluated on the test section of the RST Discourse Tree-
bank, either with gold EDUs or end-to-end, using the RST-Pareval metrics (Marcu,
2000b). It is standard to ﬁrst transform the gold RST trees into right-branching bi-
nary trees, and to report four metrics: trees with no labels (S for Span), labeled
with nuclei (N), with relations (R), or both (F for Full), for each metric computing
micro-averaged F 1over all spans from all documents (Marcu 2000b, Morey et al.
2017).
24.2.3 PDTB discourse parsing
PDTB discourse parsing, the task of detecting PDTB coherence relations between
spans, is sometimes called shallow discourse parsing because the task just involvesshallow
discourse
parsingﬂat relationships between text spans, rather than the full trees of RST parsing.
The set of four subtasks for PDTB discourse parsing was laid out by Lin et al.
(2014) in the ﬁrst complete system, with separate tasks for explicit (tasks 1-3) and
implicit (task 4) connectives:
1. Find the discourse connectives (disambiguating them from non-discourse uses)
2. Find the two spans for each connective
3. Label the relationship between these spans
4. Assign a relation between every adjacent pair of sentences
Many systems have been proposed for Task 4: taking a pair of adjacent sentences
as input and assign a coherence relation sense label as output. The setup often fol-
lows Lin et al. (2009) in assuming gold sentence span boundaries and assigning each
adjacent span one of the 11 second-level PDTB tags or none (removing the 5 very
rare tags of the 16 shown in italics in Fig. 24.3).
A simple but very strong algorithm for Task 4 is to represent each of the two
spans by BERT embeddings and take the last layer hidden state corresponding to
the position of the [CLS] token, pass this through a single layer tanh feedforward
network and then a softmax for sense classiﬁcation (Nie et al., 2019).
Each of the other tasks also have been addressed. Task 1 is to disambiguat-
ing discourse connectives from their non-discourse use. For example as Pitler and
Nenkova (2009) point out, the word andis a discourse connective linking the two
clauses by an elaboration/expansion relation in (24.24) while it’s a non-discourse
NP conjunction in (24.25):
(24.24) Selling picked up as previous buyers bailed out of their positions and
aggressive short sellers—anticipating further declines—moved in.
(24.25) My favorite colors are blue and green.

## Page 10

10 CHAPTER 24 • D ISCOURSE COHERENCE
Similarly, once is a discourse connective indicating a temporal relation in (24.26),
but simply a non-discourse adverb meaning ‘formerly’ and modifying used in (24.27):
(24.26) The asbestos ﬁber, crocidolite, is unusually resilient once it enters the
lungs, with even brief exposures to it causing symptoms that show up
decades later, researchers said.
(24.27) A form of asbestos once used to make Kent cigarette ﬁlters has caused a
high percentage of cancer deaths among a group of workers exposed to it
more than 30 years ago, researchers reported.
Determining whether a word is a discourse connective is thus a special case
of word sense disambiguation. Early work on disambiguation showed that the 4
PDTB high-level sense classes could be disambiguated with high (94%) accuracy
used syntactic features from gold parse trees (Pitler and Nenkova, 2009). Recent
work performs the task end-to-end from word inputs using a biLSTM-CRF with
BIO outputs ( B-CONN ,I-CONN ,O) (Yu et al., 2019).
For task 2, PDTB spans can be identiﬁed with the same sequence models used to
ﬁnd RST EDUs: a biLSTM sequence model with pretrained contextual embedding
(BERT) inputs (Muller et al., 2019). Simple heuristics also do pretty well as a base-
line at ﬁnding spans, since 93% of relations are either completely within a single
sentence or span two adjacent sentences, with one argument in each sentence (Biran
and McKeown, 2015).
24.3 Centering and Entity-Based Coherence
A second way a discourse can be coherent is by virtue of being “about” some entity.
This idea that at each point in the discourse some entity is salient, and a discourse
is coherent by continuing to discuss the same entity, appears early in functional lin-
guistics and the psychology of discourse (Chafe 1976, Kintsch and Van Dijk 1978),
and soon made its way to computational models. In this section we introduce two
models of this kind of entity-based coherence :Centering Theory (Grosz et al., entity-based
1995), and the entity grid model of Barzilay and Lapata (2008).
24.3.1 Centering
Centering Theory (Grosz et al., 1995) is a theory of both discourse salience andCentering
Theory
discourse coherence. As a model of discourse salience, Centering proposes that at
any given point in the discourse one of the entities in the discourse model is salient:
it is being “centered” on. As a model of discourse coherence, Centering proposes
that discourses in which adjacent sentences CONTINUE to maintain the same salient
entity are more coherent than those which SHIFT back and forth between multiple
entities (we will see that CONTINUE and SHIFT are technical terms in the theory).
The following two texts from Grosz et al. (1995) which have exactly the same
propositional content but different saliences, can help in understanding the main
Centering intuition.
(24.28) a. John went to his favorite music store to buy a piano.
b. He had frequented the store for many years.
c. He was excited that he could ﬁnally buy a piano.
d. He arrived just as the store was closing for the day.

## Page 11

24.3 • C ENTERING AND ENTITY -BASED COHERENCE 11
(24.29) a. John went to his favorite music store to buy a piano.
b. It was a store John had frequented for many years.
c. He was excited that he could ﬁnally buy a piano.
d. It was closing just as John arrived.
While these two texts differ only in how the two entities (John and the store) are
realized in the sentences, the discourse in (24.28) is intuitively more coherent than
the one in (24.29). As Grosz et al. (1995) point out, this is because the discourse
in (24.28) is clearly about one individual, John, describing his actions and feelings.
The discourse in (24.29), by contrast, focuses ﬁrst on John, then the store, then back
to John, then to the store again. It lacks the “aboutness” of the ﬁrst discourse.
Centering Theory realizes this intuition by maintaining two representations for
each utterance Un. The backward-looking center ofUn, denoted as Cb(Un), rep-backward-
looking
centerresents the current salient entity, the one being focused on in the discourse after Un
is interpreted. The forward-looking centers ofUn, denoted as Cf(Un), are a setforward-looking
center
of potential future salient entities, the discourse entities evoked by Unany of which
could serve as Cb(the salient entity) of the following utterance, i.e. Cb(Un+1).
The set of forward-looking centers Cf(Un)are ranked according to factors like
discourse salience and grammatical role (for example subjects are higher ranked
than objects, which are higher ranked than all other grammatical roles). We call the
highest-ranked forward-looking center Cp(for “preferred center”). Cpis a kind of
prediction about what entity will be talked about next. Sometimes the next utterance
indeed talks about this entity, but sometimes another entity becomes salient instead.
We’ll use here the algorithm for centering presented in Brennan et al. (1987),
which deﬁnes four intersentential relationships between a pair of utterances Unand
Un+1that depend on the relationship between Cb(Un+1),Cb(Un), and Cp(Un+1);
these are shown in Fig. 24.7.
Cb(Un+1) =Cb(Un) Cb(Un+1)6=Cb(Un)
or undeﬁned Cb(Un)
Cb(Un+1) =Cp(Un+1) Continue Smooth-Shift
Cb(Un+1)6=Cp(Un+1) Retain Rough-Shift
Figure 24.7 Centering Transitions for Rule 2 from Brennan et al. (1987).
The following rules are used by the algorithm:
Rule 1: If any element of Cf(Un)is realized by a pronoun in utterance
Un+1, then Cb(Un+1)must be realized as a pronoun also.
Rule 2 :Transition states are ordered. Continue is preferred to Retain is
preferred to Smooth-Shift is preferred to Rough-Shift.
Rule 1 captures the intuition that pronominalization (including zero-anaphora)
is a common way to mark discourse salience. If there are multiple pronouns in an
utterance realizing entities from the previous utterance, one of these pronouns must
realize the backward center Cb; if there is only one pronoun, it must be Cb.
Rule 2 captures the intuition that discourses that continue to center the same en-
tity are more coherent than ones that repeatedly shift to other centers. The transition
table is based on two factors: whether the backward-looking center Cbis the same
from UntoUn+1and whether this discourse entity is the one that is preferred ( Cp)
in the new utterance Un+1. If both of these hold, a CONTINUE relation, the speaker
has been talking about the same entity and is going to continue talking about that

## Page 12

12 CHAPTER 24 • D ISCOURSE COHERENCE
entity. In a RETAIN relation, the speaker intends to SHIFT to a new entity in a future
utterance and meanwhile places the current entity in a lower rank Cf. In a SHIFT
relation, the speaker is shifting to a new salient entity.
Let’s walk though the start of (24.28) again, repeated as (24.30), showing the
representations after each utterance is processed.
(24.30) John went to his favorite music store to buy a piano. ( U1)
He was excited that he could ﬁnally buy a piano. ( U2)
He arrived just as the store was closing for the day. ( U3)
It was closing just as John arrived ( U4)
Using the grammatical role hierarchy to order the C f, for sentence U1we get:
Cf(U1):fJohn, music store, piano g
Cp(U1): John
Cb(U1): undeﬁned
and then for sentence U2:
Cf(U2):fJohn, pianog
Cp(U2): John
Cb(U2): John
Result: Continue ( Cp(U2)=Cb(U2);Cb(U1)undeﬁned)
The transition from U1toU2is thus a CONTINUE . Completing this example is left
as exercise (1) for the reader
24.3.2 Entity Grid model
Centering embodies a particular theory of how entity mentioning leads to coher-
ence: that salient entities appear in subject position or are pronominalized, and that
discourses are salient by means of continuing to mention the same entity in such
ways.
The entity grid model of Barzilay and Lapata (2008) is an alternative way to entity grid
capture entity-based coherence: instead of having a top-down theory, the entity-grid
model using machine learning to induce the patterns of entity mentioning that make
a discourse more coherent.
The model is based around an entity grid , a two-dimensional array that repre-
sents the distribution of entity mentions across sentences. The rows represent sen-
tences, and the columns represent discourse entities (most versions of the entity grid
model focus just on nominal mentions). Each cell represents the possible appearance
of an entity in a sentence, and the values represent whether the entity appears and its
grammatical role. Grammatical roles are subject ( S), object ( O), neither ( X), or ab-
sent (–); in the implementation of Barzilay and Lapata (2008), subjects of passives
are represented with O, leading to a representation with some of the characteristics
of thematic roles.
Fig. 24.8 from Barzilay and Lapata (2008) shows a grid for the text shown in
Fig. 24.9. There is one row for each of the six sentences. The second column, for
the entity ‘trial’, is O– – – X, showing that the trial appears in the ﬁrst sentence as
direct object, in the last sentence as an oblique, and does not appear in the middle
sentences. The third column, for the entity Microsoft, shows that it appears as sub-
ject in sentence 1 (it also appears as the object of the preposition against , but entities
that appear multiple times are recorded with their highest-ranked grammatical func-
tion). Computing the entity grids requires extracting entities and doing coreference

## Page 13

24.3 • C ENTERING AND ENTITY -BASED COHERENCE 13
Computational Linguistics Volume 34, Number 1
these patterns can be encoded as feature vectors appropriate for performing coherence-
related ranking and classiﬁcation tasks.
3.1 The Entity-Grid Discourse Representation
Each text is represented by an entity grid ,at w o - d i m e n s i o n a la r r a yt h a tc a p t u r e s
the distribution of discourse entities across text sentences. We follow Miltsakaki and
Kukich (2000) in assuming that our unit of analysis is the traditional sentence (i.e., a
main clause with accompanying subordinate and adjunct clauses). The rows of the
grid correspond to sentences, and the columns correspond to discourse entities. By
discourse entity we mean a class of coreferent noun phrases (we explain in Section 3.3
how coreferent entities are identiﬁed). For each occurrence of a discourse entity in the
text, the corresponding grid cell contains information about its presence or absence
in a sequence of sentences. In addition, for entities present in a given sentence, grid
cells contain information about their syntactic role. Such information can be expressed
in many ways (e.g., using constituent labels or thematic role information). Because
grammatical relations ﬁgure prominently in entity-based theories of local coherence (see
Section 2), they serve as a logical point of departure. Each grid cell thus corresponds to
a string from a set of categories reﬂecting whether the entity in question is a subject ( S),
object ( O), or neither ( X). Entities absent from a sentence are signaled by gaps ( –).
Grammatical role information can be extracted from the output of a broad-coverage
dependency parser (Lin 2001; Briscoe and Carroll 2002) or any state-of-the art statistical
parser (Collins 1997; Charniak 2000). We discuss how this information was computed
for our experiments in Section 3.3.
Table 1 illustrates a fragment of an entity grid constructed for the text in Table 2.
Because the text contains six sentences, the grid columns are of length six. Consider
for instance the grid column for the entity trial ,[O–––– X].I tr e c o r d st h a t trial is
present in sentences 1 and 6 (as Oand X,r e s p e c t i v e l y )b u ti sa b s e n tf r o mt h er e s to ft h e
sentences. Also note that the grid in Table 1 takes coreference resolution into account.
Even though the same entity appears in different linguistic forms, for example, Microsoft
Corp. ,Microsoft ,a n d the company , it is mapped to a single entry in the grid (see the
column introduced by Microsoft in Table 1).
Table 1
A fragment of the entity grid. Noun phrases are represented by their head nouns. Grid cells
correspond to grammatical roles: subjects ( S), objects ( O), or neither ( X).Department
Trial
Microsoft
Evidence
Competitors
Markets
Products
Brands
Case
Netscape
Software
Tactics
Government
Suit
Earnings
1SO SXO –––––––––– 1
2–– O–– XSO –––– ––– 2
3–– SO –––– SOO ––– – 3
4–– S–––––––– S––– 4
5–––––––––––– SO –5
6–XS ––––– ––– – – – O6
6
Figure 24.8 Part of the entity grid for the text in Fig. 24.9. Entities are listed by their head
noun; each cell represents whether an entity appears as subject ( S), object ( O), neither ( X), or
is absent (–). Figure from Barzilay and Lapata (2008).
Barzilay and Lapata Modeling Local Coherence
Table 2
Summary augmented with syntactic annotations for grid computation.
1 [The Justice Department]Sis conducting an [anti-trust trial]Oagainst [Microsoft Corp.]X
with [evidence]Xthat [the company]Sis increasingly attempting to crush [competitors]O.
2[ M i c r o s o f t ]Ois accused of trying to forcefully buy into [markets]Xwhere [its own
products]Sare not competitive enough to unseat [established brands]O.
3[ T h e c a s e ]Srevolves around [evidence]Oof [Microsoft]Saggressively pressuring
[Netscape]Ointo merging [browser software]O.
4[ M i c r o s o f t ]Sclaims [its tactics]Sare commonplace and good economically.
5 [The government]Smay ﬁle [a civil suit]Oruling that [conspiracy]Sto curb [competition]O
through [collusion]Xis [a violation of the Sherman Act]O.
6[ M i c r o s o f t ]Scontinues to show [increased earnings]Odespite [the trial]X.
When a noun is attested more than once with a different grammatical role in the
same sentence, we default to the role with the highest grammatical ranking: subjects are
ranked higher than objects, which in turn are ranked higher than the rest. For example,
the entity Microsoft is mentioned twice in Sentence 1 with the grammatical roles x(for
Microsoft Corp. )a n d s(forthe company ), but is represented only by sin the grid (see
Tables 1 and 2).
3.2 Entity Grids as Feature Vectors
Af u n d a m e n t a la s s u m p t i o nu n d e r l y i n go u ra p p r o a c hi st h a tt h ed i s t r i b u t i o no fe n t i t i e s
in coherent texts exhibits certain regularities reﬂected in grid topology. Some of these
regularities are formalized in Centering Theory as constraints on transitions of the
local focus in adjacent sentences. Grids of coherent texts are likely to have some dense
columns (i.e., columns with just a few gaps, such as Microsoft in Table 1) and many
sparse columns which will consist mostly of gaps (see markets andearnings in Table 1).
One would further expect that entities corresponding to dense columns are more often
subjects or objects. These characteristics will be less pronounced in low-coherence texts.
Inspired by Centering Theory, our analysis revolves around patterns of local entity
transitions. A local entity transition is a sequence {S,O,X,–}nthat represents entity
occurrences and their syntactic roles in nadjacent sentences. Local transitions can be
easily obtained from a grid as continuous subsequences of each column. Each transition
will have a certain probability in a given grid. For instance, the probability of the
transition [S–]in the grid from Table 1 is 0 .08 (computed as a ratio of its frequency
[i.e., six] divided by the total number of transitions of length two [i.e., 75]). Each text
can thus be viewed as a distribution deﬁned over transition types.
We can now go one step further and represent each text by a ﬁxed set of transition
sequences using a standard feature vector notation. Each grid rendering jof a document
dicorresponds to a feature vector Φ(xij)=(p1(xij),p2(xij),... ,pm(xij)), where mis the
number of all predeﬁned entity transitions, and pt(xij)t h ep r o b a b i l i t yo ft r a n s i t i o n t
in grid xij.T h i sf e a t u r ev e c t o rr e p r e s e n t a t i o ni su s e f u l l ya m e n a b l et om a c h i n el e a r n i n g
algorithms (see our experiments in Sections 4–6). Furthermore, it allows the consid-
eration of large numbers of transitions which could potentially uncover novel entity
distribution patterns relevant for coherence assessment or other coherence-related tasks.
Note that considerable latitude is available when specifying the transition types to
be included in a feature vector. These can be all transitions of a given length (e.g., two
or three) or the most frequent transitions within a document collection. An example of
7
Figure 24.9 A discourse with the entities marked and annotated with grammatical func-
tions. Figure from Barzilay and Lapata (2008).
resolution to cluster them into discourse entities (Chapter 23) as well as parsing the
sentences to get grammatical roles.
In the resulting grid, columns that are dense (like the column for Microsoft) in-
dicate entities that are mentioned often in the texts; sparse columns (like the column
for earnings) indicate entities that are mentioned rarely.
In the entity grid model, coherence is measured by patterns of local entity tran-
sition . For example, Department is a subject in sentence 1, and then not men-
tioned in sentence 2; this is the transition [ S–]. The transitions are thus sequences
fS,O X, –gnwhich can be extracted as continuous cells from each column. Each
transition has a probability; the probability of [ S–] in the grid from Fig. 24.8 is 0.08
(it occurs 6 times out of the 75 total transitions of length two). Fig. 24.10 shows the
distribution over transitions of length 2 for the text of Fig. 24.9 (shown as the ﬁrst
rowd1), and 2 other documents.
Computational Linguistics Volume 34, Number 1
af e a t u r es p a c ew i t ht r a n s i t i o n so fl e n g t ht w oi si l l u s t r a t e di nT a b l e3 .T h es e c o n dr o w
(introduced by d1)i st h ef e a t u r ev e c t o rr e p r e s e n t a t i o no ft h eg r i di nT a b l e1 .
3.3 Grid Construction: Linguistic Dimensions
One of the central research issues in developing entity-based models of coherence is
determining what sources of linguistic knowledge are essential for accurate prediction,
and how to encode them succinctly in a discourse representation. Previous approaches
tend to agree on the features of entity distribution related to local coherence—the
disagreement lies in the way these features are modeled.
Our study of alternative encodings is not a mere duplication of previous ef-
forts (Poesio et al. 2004) that focus on linguistic aspects of parameterization. Because we
are interested in an automatically constructed model, we have to take into account com-
putational and learning issues when considering alternative representations. Therefore,
our exploration of the parameter space is guided by three considerations: the linguistic
importance of a parameter, the accuracy of its automatic computation, and the size of the
resulting feature space. From the linguistic side, we focus on properties of entity distri-
bution that are tightly linked to local coherence, and at the same time allow for multiple
interpretations during the encoding process. Computational considerations prevent us
from considering discourse representations that cannot be computed reliably by exist-
ing tools. For instance, we could not experiment with the granularity of an utterance—
sentence versus clause—because available clause separators introduce substantial noise
into a grid construction. Finally, we exclude representations that will explode the size of
the feature space, thereby increasing the amount of data required for training the model.
Entity Ex traction. The accurate computation of entity classes is key to computing mean-
ingful entity grids. In previous implementations of entity-based models, classes of coref-
erent nouns have been extracted manually (Miltsakaki and Kukich 2000; Karamanis
et al. 2004; Poesio et al. 2004), but this is not an option for our model. An obvious
solution for identifying entity classes is to employ an automatic coreference resolution
tool that determines which noun phrases refer to the same entity in a document.
Current approaches recast coreference resolution as a classiﬁcation task. A pair
of NPs is classiﬁed as coreferring or not based on constraints that are learned from
an annotated corpus. A separate clustering mechanism then coordinates the possibly
contradictory pairwise classiﬁcations and constructs a partition on the set of NPs. In
our experiments, we employ Ng and Cardie’s (2002) coreference resolution system.
The system decides whether two NPs are coreferent by exploiting a wealth of lexical,
grammatical, semantic, and positional features. It is trained on the MUC (6–7) data sets
and yields state-of-the-art performance (70.4 F-measure on MUC-6 and 63.4 on MUC-7).
Table 3
Example of a feature-vector document representation using all transitions of length two given
syntactic categories S,O,X,a n d –.
SS SO SX S –OS OO OX O –XS XO XX X –– S–O–X––
d1.01 .01 0 .08 .01 0 0 .09 0 0 0 .03 .05 .07 .03 .59
d2.02 .01 .01 .02 0 .07 0 .02 .14 .14 .06 .04 .03 .07 0.1 .36
d3.02 0 0 .03 .09 0 .09 .06 0 0 0 .05 .03 .07 .17 .39
8
Figure 24.10 A feature vector for representing documents using all transitions of length 2.
Document d1is the text in Fig. 24.9. Figure from Barzilay and Lapata (2008).
The transitions and their probabilities can then be used as features for a machine
learning model. This model can be a text classiﬁer trained to produce human-labeled
coherence scores (for example from humans labeling each text as coherent or inco-
herent). But such data is expensive to gather. Barzilay and Lapata (2005) introduced
a simplifying innovation: coherence models can be trained by self-supervision :
trained to distinguish the natural original order of sentences in a discourse from

## Page 14

14 CHAPTER 24 • D ISCOURSE COHERENCE
a modiﬁed order (such as a randomized order). We turn to these evaluations in the
next section.
24.3.3 Evaluating Neural and Entity-based coherence
Entity-based coherence models, as well as the neural models we introduce in the
next section, are generally evaluated in one of two ways.
First, we can have humans rate the coherence of a document and train a classiﬁer
to predict these human ratings, which can be categorial (high/low, or high/mid/low)
or continuous. This is the best evaluation to use if we have some end task in mind,
like essay grading, where human raters are the correct deﬁnition of the ﬁnal label.
Alternatively, since it’s very expensive to get human labels, and we might not
yet have an end-task in mind, we can use natural texts to do self-supervision. In
self-supervision we pair up a natural discourse with a pseudo-document created by
changing the ordering. Since naturally-ordered discourses are more coherent than
random permutation (Lin et al., 2011), a successful coherence algorithm should pre-
fer the original ordering.
Self-supervision has been implemented in 3 ways. In the sentence order dis-
crimination task (Barzilay and Lapata, 2005), we compare a document to a random
permutation of its sentences. A model is considered correct for an (original, per-
muted) test pair if it ranks the original document higher. Given kdocuments, we can
compute npermutations, resulting in knpairs each with one original document and
one permutation, to use in training and testing.
In the sentence insertion task (Chen et al., 2007) we take a document, remove
one of the nsentences s, and create n 1 copies of the document with sinserted into
each position. The task is to decide which of the ndocuments is the one with the
original ordering, distinguishing the original position for sfrom all other positions.
Insertion is harder than discrimination since we are comparing documents that differ
by only one sentence.
Finally, in the sentence order reconstruction task (Lapata, 2003), we take a
document, randomize the sentences, and train the model to put them back in the
correct order. Again given kdocuments, we can compute npermutations, resulting
inknpairs each with one original document and one permutation, to use in training
and testing. Reordering is of course a much harder task than simple classiﬁcation.
24.4 Representation learning models for local coherence
The third kind of local coherence is topical or semantic ﬁeld coherence. Discourses
cohere by talking about the same topics and subtopics, and drawing on the same
semantic ﬁelds in doing so.
The ﬁeld was pioneered by a series of unsupervised models in the 1990s of this
kind of coherence that made use of lexical cohesion (Halliday and Hasan, 1976): lexical cohesion
the sharing of identical or semantically related words in nearby sentences. Morris
and Hirst (1991) computed lexical chains of words (like pine,bush trees ,trunk ) that
occurred through a discourse and that were related in Roget’s Thesaurus (by being in
the same category, or linked categories). They showed that the number and density
of chain correlated with the topic structure. The TextTiling algorithm of Hearst TextTiling
(1997) computed the cosine between neighboring text spans (the normalized dot
product of vectors of raw word counts), again showing that sentences or paragraph in

## Page 15

24.4 • R EPRESENTATION LEARNING MODELS FOR LOCAL COHERENCE 15
a subtopic have high cosine with each other, but not with sentences in a neighboring
subtopic.
A third early model, the LSA Coherence method of Foltz et al. (1998) was the
ﬁrst to use embeddings, modeling the coherence between two sentences as the co-
sine between their LSA sentence embedding vectors1, computing embeddings for a
sentence sby summing the embeddings of its words w:
sim(s;t) = cos(s;t)
=cos(X
w2sw;X
w2tw) (24.31)
and deﬁning the overall coherence of a text as the average similarity over all pairs of
adjacent sentences siandsi+1:
coherence (T) =1
n 1n 1X
i=1cos(si;si+1) (24.32)
Modern neural representation-learning coherence models, beginning with Li et al.
(2014), draw on the intuitions of these early unsupervised models for learning sen-
tence representations and measuring how they change between neighboring sen-
tences. But the new models also draw on the idea pioneered by Barzilay and Lapata
(2005) of self-supervision. That is, unlike say coherence relation models, which
train on hand-labeled representations for RST or PDTB, these models are trained to
distinguish natural discourses from unnatural discourses formed by scrambling the
order of sentences, thus using representation learning to discover the features that
matter for at least the ordering aspect of coherence.
Here we present one such model, the local coherence discriminator (LCD) (Xu
et al., 2019). Like early models, LCD computes the coherence of a text as the av-
erage of coherence scores between consecutive pairs of sentences. But unlike the
early unsupervised models, LCD is a self-supervised model trained to discriminate
consecutive sentence pairs (si;si+1)in the training documents (assumed to be coher-
ent) from (constructed) incoherent pairs (si;s0). All consecutive pairs are positive
examples, and the negative (incoherent) partner for a sentence siis another sentence
uniformly sampled from the same document as si.
Fig. 24.11 describes the architecture of the model fq, which takes a sentence
pair and returns a score, higher scores for more coherent pairs. Given an input
sentence pair sandt, the model computes sentence embeddings sandt(using any
sentence embeddings algorithm), and then concatenates four features of the pair: (1)
the concatenation of the two vectors (2) their difference s t; (3) the absolute value
of their difference js tj; (4) their element-wise product st. These are passed
through a one-layer feedforward network to output the coherence score.
The model is trained to make this coherence score higher for real pairs than for
negative pairs. More formally, the training objective for a corpus Cof documents d,
each of which consists of a list of sentences si, is:
Lq=X
d2CX
si2dE
p(s0jsi)[L(fq(si;si+1);fq(si;s0))] (24.33)
Ep(s0jsi)is the expectation with respect to the negative sampling distribution con-
ditioned on si: given a sentence sithe algorithms samples a negative sentence s0
1See Chapter 6 for more on LSA embeddings; they are computed by applying SVD to the term-
document matrix (each cell weighted by log frequency and normalized by entropy), and then the ﬁrst
300 dimensions are used as the embedding.

## Page 16

16 CHAPTER 24 • D ISCOURSE COHERENCE
681Loss function: The role of the loss function is
to encourage f+=f✓(si,si+1)to be high while
f =f✓(si,s0)to be low. Common losses such as
margin or log loss can all be used. Through exper-
imental validation, we found that margin loss to
be superior for this problem. Speciﬁcally, Ltakes
on the form: L(f+,f ) = max(0 ,⌘ f++f )
where ⌘is the margin hyperparameter.
Negative samples: Technically, we are free to
choose any sentence s0to form a negative pair
with si. However, because of potential differ-
ences in genre, topic and writing style, such neg-
atives might cause the discriminative model to
learn cues unrelated to coherence. Therefore, we
only select sentences from the same document to
construct negative pairs. Speciﬁcally, suppose si
comes from document dkwith length nk, then
p(s0|si)is a uniform distribution over the nk 1
sentences {sj}j6=ifrom dk. For a document with
nsentences, there are n 1positive pairs, and
(n 1)⇤(n 2)/2negative pairs. It turns out that
the quadratic number of negatives provides a rich
enough learning signal, while at the same time, is
not too prohibitively large to be effectively cov-
ered by a sampling procedure. In practice, we
sample a new set of negatives each time we see
a document, hence after many epochs, we can ef-
fectively cover the space for even very long doc-
uments. Section 5.7discusses further details on
sampling.
4.1 Model Architecture
The speciﬁc neural architecture that we use for f✓
is illustrated in Figure 1. We assume the use of
some pre-trained sentence encoder, which is dis-
cussed in the next section.
Given an input sentence pair, the sentence en-
coder maps the sentences to real-valued vectors S
andT. We then compute the concatenation of the
following features: (1)concatenation of the two
vectors (S, T);(2)element-wise difference S T;
(3)element-wise product S⇤T;(4)absolute value
of element-wise difference |S T|. The concate-
nated feature representation is then fed to a one-
layer MLP to output the coherence score.
In practice, we make our overall coherence
model bidirectional, by training a forward model
with input (S, T)and a backward model with in-
put(T,S)with the same architecture but separate
parameters. The coherence score is then the aver-
age from the two models.
Figure 1: Generic architecture for our proposed model.
4.2 Pre-trained Generative Model as the
Sentence Encoder
Our model can work with any pre-trained sen-
tence encoder, ranging from the most simplistic
average GloVe ( Pennington et al. ,2014 ) embed-
dings to more sophisticated supervised or unsu-
pervised pre-trained sentence encoders ( Conneau
et al. ,2017 ). As mentioned in the introduction,
since generative models can often be turned into
sentence encoder, generative coherence model can
be leveraged by our model to beneﬁt from the
advantages of both generative and discriminative
training, similar to ( Kiros et al. ,2015 ;Peters et al. ,
2018 ). After initialization, we freeze the genera-
tive model parameters to avoid overﬁtting.
In Section 5, we will experimentally show that
while we do beneﬁt from strong pre-trained en-
coders, the fact that our local discriminative model
improves over previous methods is independent of
the choice of sentence encoder.
5 Experiments
5.1 Evaluation Tasks
Following Nguyen and Joty (2017 ) and other pre-
vious work, we evaluate our models on the dis-
crimination and insertion tasks. Additionally, we
evaluate on the paragraph reconstruction task in
open-domain settings, in a similar manner to Li
and Jurafsky (2017 ).
In the discrimination task, a document is com-
pared to a random permutation of its sentences,
and the model is considered correct if it scores the
original document higher than the permuted one.
Twenty permutations are used in the test set in ac-
cordance with previous work.
Figure 24.11 The architecture of the LCD model of document coherence, showing the
computation of the score for a pair of sentences sandt. Figure from Xu et al. (2019).
uniformly over the other sentences in the same document. Lis a loss function that
takes two scores, one for a positive pair and one for a negative pair, with the goal of
encouraging f+=fq(si;si+1)to be high and f =fq(si;s0))to be low. Fig. 24.11
use the margin loss l(f+;f ) =max(0;h f++f )where his the margin hyper-
parameter.
Xu et al. (2019) also give a useful baseline algorithm that itself has quite high
performance in measuring perplexity: train an RNN language model on the data,
and compute the log likelihood of sentence siin two ways, once given the preceding
context (conditional log likelihood) and once with no context (marginal log likeli-
hood). The difference between these values tells us how much the preceding context
improved the predictability of si, a predictability measure of coherence.
Training models to predict longer contexts than just consecutive pairs of sen-
tences can result in even stronger discourse representations. For example a Trans-
former language model trained with a contrastive sentence objective to predict text
up to a distance of 2 sentences improves performance on various discourse coher-
ence tasks (Iter et al., 2020).
Language-model style models are generally evaluated by the methods of Sec-
tion 24.3.3, although they can also be evaluated on the RST and PDTB coherence
relation tasks.
24.5 Global Coherence
A discourse must also cohere globally rather than just at the level of pairs of sen-
tences. Consider stories, for example. The narrative structure of stories is one of
the oldest kinds of global coherence to be studied. In his inﬂuential Morphology of
the Folktale , Propp (1968) models the discourse structure of Russian folktales via
a kind of plot grammar. His model includes a set of character categories he called
dramatis personae , like Hero, Villain, Donor, or Helper, and a set of events he
called functions (like “Villain commits kidnapping”, “Donor tests Hero”, or “Hero
is pursued”) that have to occur in particular order, along with other components.
Propp shows that the plots of each of the fairy tales he studies can be represented as

## Page 17

24.5 • G LOBAL COHERENCE 17
a sequence of these functions, different tales choosing different subsets of functions,
but always in the same order. Indeed Lakoff (1972) showed that Propp’s model
amounted to a discourse grammar of stories, and in recent computational work Fin-
layson (2016) demonstrates that some of these Proppian functions could be induced
from corpora of folktale texts by detecting events that have similar actions across
stories. Bamman et al. (2013) showed that generalizations over dramatis personae
could be induced from movie plot summaries on Wikipedia. Their model induced
latent personae from features like the actions the character takes (e.g., Villains stran-
gle), the actions done to them (e.g., Villains are foiled and arrested) or the descriptive
words used of them (Villains are evil).
In this section we introduce two kinds of such global discourse structure that
have been widely studied computationally. The ﬁrst is the structure of arguments:
the way people attempt to convince each other in persuasive essays by offering
claims and supporting premises. The second is somewhat related: the structure of
scientiﬁc papers, and the way authors present their goals, results, and relationship to
prior work in their papers.
24.5.1 Argumentation Structure
The ﬁrst type of global discourse structure is the structure of arguments . Analyzing
people’s argumentation computationally is often called argumentation mining .argumentation
mining
The study of arguments dates back to Aristotle, who in his Rhetorics described
three components of a good argument: pathos (appealing to the emotions of the pathos
listener), ethos (appealing to the speaker’s personal character), and logos (the logical ethos
logos structure of the argument).
Most of the discourse structure studies of argumentation have focused on logos ,
particularly via building and training on annotated datasets of persuasive essays or
other arguments (Reed et al. 2008, Stab and Gurevych 2014a, Peldszus and Stede
2016, Habernal and Gurevych 2017, Musi et al. 2018). Such corpora, for exam-
ple, often include annotations of argumentative components like claims (the central claims
component of the argument that is controversial and needs support) and premises premises
(the reasons given by the author to persuade the reader by supporting or attacking
the claim or other premises), as well as the argumentative relations between themargumentative
relations
like SUPPORT and ATTACK .
Consider the following example of a persuasive essay from Stab and Gurevych
(2014b). The ﬁrst sentence (1) presents a claim (in bold). (2) and (3) present two
premises supporting the claim. (4) gives a premise supporting premise (3).
“(1) Museums and art galleries provide a better understanding
about arts than Internet. (2) In most museums and art galleries, de-
tailed descriptions in terms of the background, history and author are
provided. (3) Seeing an artwork online is not the same as watching it
with our own eyes, as (4) the picture online does not show the texture
or three-dimensional structure of the art, which is important to study.”
Thus this example has three argumentative relations: SUPPORT (2,1), SUPPORT (3,1)
and SUPPORT (4,3). Fig. 24.12 shows the structure of a much more complex argu-
ment.
While argumentation mining is clearly related to rhetorical structure and other
kinds of coherence relations, arguments tend to be much less local; often a persua-
sive essay will have only a single main claim, with premises spread throughout the
text, without the local coherence we see in coherence relations.

## Page 18

18 CHAPTER 24 • D ISCOURSE COHERENCE
Stab and Gurevych Parsing Argumentation Structures
cloning. This example illustrates that knowing argumentative relations is important for
separating several arguments in a paragraph. The example also shows that argument
components frequently exhibit preceding text units that are not relevant to the argument
but helpful for recognizing the argument component type. For example, preceding dis-
course connectors like “therefore”, “consequently”, or “thus” can signal a subsequent
claim. Discourse markers like “because”, “since”, or “furthermore” could indicate a
premise. Formally, these preceding tokens of an argument component starting at token
tiare deﬁned as the tokens ti m,...,ti 1that are not covered by another argument
component in the sentence s=t1,t2,...,tnwhere 1 inand i m 1. The third body
paragraph illustrates a contra argument and argumentative attack relations:
Admittedly, [ cloning could bemisused formilitary purposes] Claim 5. For example,
[:it:::::could:::be:::::used::to::::::::::manipulate:::::::human::::::genes::in::::::order::to::::::create::::::::obedient:::::::soldiers
::::with::::::::::::extraordinary:::::::abilities] Premise 9. However, because [::::moral::::and:::::::ethical::::::values:::are
::::::::::::internationally::::::shared] Premise 10,[:it:::is::::very::::::::unlikely::::that:::::::cloning::::will::be::::::::misused:::for
::::::militant:::::::::objectives] Premise 11.
The paragraph begins with Claim 5, which attacks the stance of the author. It is supported
byPremise 9in the second sentence. The third sentence includes two premises, both of
which defend the stance of the author. Premise 11is an attack of Claim 5, and Premise 10
supports Premise 11. The last paragraph (conclusion) restates the major claim and sum-
marizes the main aspects of the essay:
To sum up, although [ permitting cloning might bear some risks like misuse for
military purposes] Claim 6, I strongly believe that [ this technology is beneﬁcial to
humanity ]MajorClaim 2. It is likely that [ thistechnologybears some important cures which
will significantly improve lifeconditions] Claim 7.
The conclusion of the essay starts with an attacking claim followed by the restatement of
the major claim. The last sentence includes another claim that summarizes the most im-
portant points of the author’s argumentation. Figure 2 shows the entire argumentation
structure of the example essay.
Figure 2Argumentation structure of the example essay. Arrows indicate argumentative relations.Arrowheads denote argumentative support relations and circleheads attack relations. Dashedlines indicate relations that are encoded in the stance attributes of claims. “P” denotes premises.629
Figure 24.12 Argumentation structure of a persuasive essay. Arrows indicate argumentation relations, ei-
ther of SUPPORT (with arrowheads) or ATTACK (with circleheads); P denotes premises. Figure from Stab and
Gurevych (2017).
Algorithms for detecting argumentation structure often include classiﬁers for
distinguishing claims, premises, or non-argumentation, together with relation clas-
siﬁers for deciding if two spans have the SUPPORT ,ATTACK , or neither relation
(Peldszus and Stede, 2013). While these are the main focus of much computational
work, there is also preliminary efforts on annotating and detecting richer semantic
relationships (Park and Cardie 2014, Hidey et al. 2017) such as detecting argumen-
tation schemes , larger-scale structures for argument like argument from example ,argumentation
schemes
orargument from cause to effect , orargument from consequences (Feng and
Hirst, 2011).
Another important line of research is studying how these argument structure (or
other features) are associated with the success or persuasiveness of an argument
(Habernal and Gurevych 2016, Tan et al. 2016, Hidey et al. 2017. Indeed, while it
is Aristotle’s logos that is most related to discourse structure, Aristotle’s ethos and
pathos techniques are particularly relevant in the detection of mechanisms of this
sort of persuasion . For example scholars have investigated the linguistic realization persuasion
of features studied by social scientists like reciprocity (people return favors), social
proof (people follow others’ choices), authority (people are inﬂuenced by those
with power), and scarcity (people value things that are scarce), all of which can
be brought up in a persuasive argument (Cialdini, 1984). Rosenthal and McKeown
(2017) showed that these features could be combined with argumentation structure
to predict who inﬂuences whom on social media, Althoff et al. (2014) found that
linguistic models of reciprocity and authority predicted success in online requests,
while the semisupervised model of Yang et al. (2019) detected mentions of scarcity,
commitment, and social identity to predict the success of peer-to-peer lending plat-
forms.
See Stede and Schneider (2018) for a comprehensive survey of argument mining.
24.5.2 The structure of scientiﬁc discourse
Scientiﬁc papers have a very speciﬁc global structure: somewhere in the course of
the paper the authors must indicate a scientiﬁc goal, develop a method for a solu-
tion, provide evidence for the solution, and compare to prior work. One popular

## Page 19

24.6 • S UMMARY 19
annotation scheme for modeling these rhetorical goals is the argumentative zon-
ingmodel of Teufel et al. (1999) and Teufel et al. (2009), which is informed by theargumentative
zoning
idea that each scientiﬁc paper tries to make a knowledge claim about a new piece
of knowledge being added to the repository of the ﬁeld (Myers, 1992). Sentences
in a scientiﬁc paper can be assigned one of 15 tags; Fig. 24.13 shows 7 (shortened)
examples of labeled sentences.
Category Description Example
AIM Statement of speciﬁc research goal, or
hypothesis of current paper“The aim of this process is to examine the role that
training plays in the tagging process”
OWNMETHOD New Knowledge claim, own work:
methods“In order for it to be useful for our purposes, the
following extensions must be made:”
OWNRESULTS Measurable/objective outcome of own
work“All the curves have a generally upward trend but
always lie far below backoff (51% error rate)”
USE Other work is used in own work “We use the framework for the allocation and
transfer of control of Whittaker....”
GAPWEAK Lack of solution in ﬁeld, problem with
other solutions“Here, we will produce experimental evidence
suggesting that this simple model leads to serious
overestimates”
SUPPORT Other work supports current work or is
supported by current work“Work similar to that described here has been car-
ried out by Merialdo (1994), with broadly similar
conclusions.”
ANTISUPPORT Clash with other’s results or theory; su-
periority of own work“This result challenges the claims of...”
Figure 24.13 Examples for 7 of the 15 labels from the Argumentative Zoning labelset (Teufel et al., 2009).
Teufel et al. (1999) and Teufel et al. (2009) develop labeled corpora of scientiﬁc
articles from computational linguistics and chemistry, which can be used as supervi-
sion for training standard sentence-classiﬁcation architecture to assign the 15 labels.
24.6 Summary
In this chapter we introduced local and global models for discourse coherence .
• Discourses are not arbitrary collections of sentences; they must be coherent .
Among the factors that make a discourse coherent are coherence relations
between the sentences, entity-based coherence, and topical coherence.
• Various sets of coherence relations andrhetorical relations have been pro-
posed. The relations in Rhetorical Structure Theory ( RST ) hold between
spans of text and are structured into a tree. Because of this, shift-reduce
and other parsing algorithms are generally used to assign these structures.
The Penn Discourse Treebank ( PDTB ) labels only relations between pairs of
spans, and the labels are generally assigned by sequence models.
•Entity-based coherence captures the intuition that discourses are about an
entity, and continue mentioning the entity from sentence to sentence. Cen-
tering Theory is a family of models describing how salience is modeled for
discourse entities, and hence how coherence is achieved by virtue of keeping
the same discourse entities salient over the discourse. The entity grid model
gives a more bottom-up way to compute which entity realization transitions
lead to coherence.

## Page 20

20 CHAPTER 24 • D ISCOURSE COHERENCE
• Many different genres have different types of global coherence . Persuasive
essays have claims and premises that are extracted in the ﬁeld of argument
mining , scientiﬁc articles have structure related to aims, methods, results, and
comparisons.
Bibliographical and Historical Notes
Coherence relations arose from the independent development of a number of schol-
ars, including Hobbs (1979) idea that coherence relations play an inferential role for
the hearer, and the investigations by Mann and Thompson (1987) of the discourse
structure of large texts. Other approaches to coherence relations and their extrac-
tion include Segmented Discourse Representation Theory ( SDRT ) (Asher and Las- SDRT
carides 2003, Baldridge et al. 2007) and the Linguistic Discourse Model (Polanyi
1988, Scha and Polanyi 1988, Polanyi et al. 2004). Wolf and Gibson (2005) argue
that coherence structure includes crossed bracketings, which make it impossible to
represent as a tree, and propose a graph representation instead. A compendium of
over 350 relations that have been proposed in the literature can be found in Hovy
(1990).
RST parsing was ﬁrst proposed by Marcu (1997), and early work was rule-based,
focused on discourse markers (Marcu, 2000a). The creation of the RST Discourse
TreeBank (Carlson et al. 2001, Carlson and Marcu 2001) enabled a wide variety
of machine learning algorithms, beginning with the shift-reduce parser of Marcu
(1999) that used decision trees to choose actions, and continuing with a wide variety
of machine learned parsing methods (Soricut and Marcu 2003, Sagae 2009, Hernault
et al. 2010, Feng and Hirst 2014, Surdeanu et al. 2015, Joty et al. 2015) and chunkers
(Sporleder and Lapata, 2005). Subba and Di Eugenio (2009) integrated sophisticated
semantic information into RST parsing. Ji and Eisenstein (2014) ﬁrst applied neural
models to RST parsing neural models, leading to the modern set of neural RST
models (Li et al. 2014, Li et al. 2016, Braud et al. 2017, Yu et al. 2018, inter alia) as
well as neural segmenters (Wang et al. 2018). and neural PDTB parsing models (Ji
and Eisenstein 2015, Qin et al. 2016, Qin et al. 2017).
Barzilay and Lapata (2005) pioneered the idea of self-supervision for coher-
ence: training a coherence model to distinguish true orderings of sentences from
random permutations. Li et al. (2014) ﬁrst applied this paradigm to neural sentence-
representation, and many neural self-supervised models followed (Li and Jurafsky
2017, Logeswaran et al. 2018, Lai and Tetreault 2018, Xu et al. 2019, Iter et al.
2020)
Another aspect of global coherence is the global topic structure of a text, the way
the topics shift over the course of the document. Barzilay and Lee (2004) introduced
an HMM model for capturing topics for coherence, and later work expanded this
intuition (Soricut and Marcu 2006, Elsner et al. 2007, Louis and Nenkova 2012, Li
and Jurafsky 2017).
The relationship between explicit and implicit discourse connectives has been
a fruitful one for research. Marcu and Echihabi (2002) ﬁrst proposed to use sen-
tences with explicit relations to help provide training data for implicit relations, by
removing the explicit relations and trying to re-predict them as a way of improv-
ing performance on implicit connectives; this idea was reﬁned by Sporleder and
Lascarides (2005), (Pitler et al., 2009), and Rutherford and Xue (2015). This rela-

## Page 21

BIBLIOGRAPHICAL AND HISTORICAL NOTES 21
tionship can also be used as a way to create discourse-aware representations. The
DisSent algorithm (Nie et al., 2019) creates the task of predicting explicit discourse
markers between two sentences. They show that representations learned to be good
at this task also function as powerful sentence representations for other discourse
tasks.
The idea of entity-based coherence seems to have arisen in multiple ﬁelds in the
mid-1970s, in functional linguistics (Chafe, 1976), in the psychology of discourse
processing (Kintsch and Van Dijk, 1978), and in the roughly contemporaneous work
of Grosz, Sidner, Joshi, and their colleagues. Grosz (1977) addressed the focus of
attention that conversational participants maintain as the discourse unfolds. She de-
ﬁned two levels of focus; entities relevant to the entire discourse were said to be in
global focus, whereas entities that are locally in focus (i.e., most central to a partic-
ular utterance) were said to be in immediate focus. Sidner 1979; 1983 described a
method for tracking (immediate) discourse foci and their use in resolving pronouns
and demonstrative noun phrases. She made a distinction between the current dis-
course focus and potential foci, which are the predecessors to the backward- and
forward-looking centers of Centering theory, respectively. The name and further
roots of the centering approach lie in papers by Joshi and Kuhn (1979) and Joshi
and Weinstein (1981), who addressed the relationship between immediate focus and
the inferences required to integrate the current utterance into the discourse model.
Grosz et al. (1983) integrated this work with the prior work of Sidner and Grosz.
This led to a manuscript on centering which, while widely circulated since 1986,
remained unpublished until Grosz et al. (1995). A collection of centering papers ap-
pears in Walker et al. (1998). See Karamanis et al. (2004) and Poesio et al. (2004) for
a deeper exploration of centering and its parameterizations, and the History section
of Chapter 23 for more on the use of centering on coreference.
The grid model of entity-based coherence was ﬁrst proposed by Barzilay and
Lapata (2005) drawing on earlier work by Lapata (2003) and Barzilay, and then
extended by them Barzilay and Lapata (2008) and others with additional features
(Elsner and Charniak 2008, 2011, Feng et al. 2014, Lin et al. 2011) a model that
projects entities into a global graph for the discourse (Guinaudeau and Strube 2013,
Mesgar and Strube 2016), and a convolutional model to capture longer-range entity
dependencies (Nguyen and Joty, 2017).
Theories of discourse coherence have also been used in algorithms for interpret-
ing discourse-level linguistic phenomena, including verb phrase ellipsis and gap-
ping (Asher 1993, Kehler 1993), and tense interpretation (Lascarides and Asher
1993, Kehler 1994, Kehler 2000). An extensive investigation into the relationship
between coherence relations and discourse connectives can be found in Knott and
Dale (1994).
Useful surveys of discourse processing and structure include Stede (2011) and
Webber et al. (2012).
Andy Kehler wrote the Discourse chapter for the 2000 ﬁrst edition of this text-
book, which we used as the starting point for the second-edition chapter, and there
are some remnants of Andy’s lovely prose still in this third-edition coherence chap-
ter.

## Page 22

22 CHAPTER 24 • D ISCOURSE COHERENCE
Exercises
24.1 Finish the Centering Theory processing of the last two utterances of (24.30),
and show how (24.29) would be processed. Does the algorithm indeed mark
(24.29) as less coherent?
24.2 Select an editorial column from your favorite newspaper, and determine the
discourse structure for a 10–20 sentence portion. What problems did you
encounter? Were you helped by superﬁcial cues the speaker included (e.g.,
discourse connectives) in any places?

## Page 23

Exercises 23
Althoff, T., C. Danescu-Niculescu-Mizil, and D. Jurafsky.
2014. How to ask for a favor: A case study on the suc-
cess of altruistic requests. ICWSM 2014 .
Asher, N. 1993. Reference to Abstract Objects in Dis-
course . Studies in Linguistics and Philosophy (SLAP)
50, Kluwer.
Asher, N. and A. Lascarides. 2003. Logics of Conversation .
Cambridge University Press.
Baldridge, J., N. Asher, and J. Hunter. 2007. Annotation for
and robust parsing of discourse structure on unrestricted
texts. Zeitschrift f ¨ur Sprachwissenschaft , 26:213–239.
Bamman, D., B. O’Connor, and N. A. Smith. 2013. Learning
latent personas of ﬁlm characters. ACL.
Barzilay, R. and M. Lapata. 2005. Modeling local coherence:
An entity-based approach. ACL.
Barzilay, R. and M. Lapata. 2008. Modeling local coher-
ence: An entity-based approach. Computational Linguis-
tics, 34(1):1–34.
Barzilay, R. and L. Lee. 2004. Catching the drift: Prob-
abilistic content models, with applications to generation
and summarization. HLT-NAACL .
Bedi, G., F. Carrillo, G. A. Cecchi, D. F. Slezak, M. Sig-
man, N. B. Mota, S. Ribeiro, D. C. Javitt, M. Copelli,
and C. M. Corcoran. 2015. Automated analysis of free
speech predicts psychosis onset in high-risk youths. npj
Schizophrenia , 1.
Biran, O. and K. McKeown. 2015. PDTB discourse parsing
as a tagging task: The two taggers approach. SIGDIAL .
Braud, C., M. Coavoux, and A. Søgaard. 2017. Cross-lingual
RST discourse parsing. EACL .
Brennan, S. E., M. W. Friedman, and C. Pollard. 1987. A
centering approach to pronouns. ACL.
Carlson, L. and D. Marcu. 2001. Discourse tagging manual.
Technical Report ISI-TR-545, ISI.
Carlson, L., D. Marcu, and M. E. Okurowski. 2001. Building
a discourse-tagged corpus in the framework of rhetorical
structure theory. SIGDIAL .
Chafe, W. L. 1976. Givenness, contrastiveness, deﬁniteness,
subjects, topics, and point of view. In C. N. Li, ed., Sub-
ject and Topic , 25–55. Academic Press.
Chen, E., B. Snyder, and R. Barzilay. 2007. Incre-
mental text structuring with online hierarchical ranking.
EMNLP/CoNLL .
Cialdini, R. B. 1984. Inﬂuence: The psychology of persua-
sion. Morrow.
Ditman, T. and G. R. Kuperberg. 2010. Building coherence:
A framework for exploring the breakdown of links across
clause boundaries in schizophrenia. Journal of neurolin-
guistics , 23(3):254–269.
Elsner, M., J. Austerweil, and E. Charniak. 2007. A uniﬁed
local and global model for discourse coherence. NAACL-
HLT.
Elsner, M. and E. Charniak. 2008. Coreference-inspired co-
herence modeling. ACL.
Elsner, M. and E. Charniak. 2011. Extending the entity grid
with entity-speciﬁc features. ACL.Elvev ˚ag, B., P. W. Foltz, D. R. Weinberger, and T. E. Gold-
berg. 2007. Quantifying incoherence in speech: an auto-
mated methodology and novel application to schizophre-
nia.Schizophrenia research , 93(1-3):304–316.
Feng, V . W. and G. Hirst. 2011. Classifying arguments by
scheme. ACL.
Feng, V . W. and G. Hirst. 2014. A linear-time bottom-up
discourse parser with constraints and post-editing. ACL.
Feng, V . W., Z. Lin, and G. Hirst. 2014. The impact of deep
hierarchical discourse structures in the evaluation of text
coherence. COLING .
Finlayson, M. A. 2016. Inferring Propp’s functions from se-
mantically annotated text. The Journal of American Folk-
lore, 129(511):55–77.
Foltz, P. W., W. Kintsch, and T. K. Landauer. 1998. The
measurement of textual coherence with latent semantic
analysis. Discourse processes , 25(2-3):285–307.
Grosz, B. J. 1977. The representation and use of focus in
a system for understanding dialogs. IJCAI-77 . Morgan
Kaufmann.
Grosz, B. J., A. K. Joshi, and S. Weinstein. 1983. Provid-
ing a uniﬁed account of deﬁnite noun phrases in English.
ACL.
Grosz, B. J., A. K. Joshi, and S. Weinstein. 1995. Center-
ing: A framework for modeling the local coherence of
discourse. Computational Linguistics , 21(2):203–225.
Guinaudeau, C. and M. Strube. 2013. Graph-based local co-
herence modeling. ACL.
Habernal, I. and I. Gurevych. 2016. Which argument is more
convincing? Analyzing and predicting convincingness of
Web arguments using bidirectional LSTM. ACL.
Habernal, I. and I. Gurevych. 2017. Argumentation mining
in user-generated web discourse. Computational Linguis-
tics, 43(1):125–179.
Halliday, M. A. K. and R. Hasan. 1976. Cohesion in English .
Longman. English Language Series, Title No. 9.
Hearst, M. A. 1997. Texttiling: Segmenting text into multi-
paragraph subtopic passages. Computational Linguistics ,
23:33–64.
Hernault, H., H. Prendinger, D. A. duVerle, and M. Ishizuka.
2010. Hilda: A discourse parser using support vector ma-
chine classiﬁcation. Dialogue & Discourse , 1(3).
Hidey, C., E. Musi, A. Hwang, S. Muresan, and K. McKe-
own. 2017. Analyzing the semantic types of claims and
premises in an online persuasive forum. 4th Workshop on
Argument Mining .
Hobbs, J. R. 1979. Coherence and coreference. Cognitive
Science , 3:67–90.
Hovy, E. H. 1990. Parsimonious and proﬂigate approaches to
the question of discourse structure relations. Proceedings
of the 5th International Workshop on Natural Language
Generation .
Iter, D., K. Guu, L. Lansing, and D. Jurafsky. 2020. Pretrain-
ing with contrastive sentence objectives improves dis-
course performance of language models. ACL.
Iter, D., J. Yoon, and D. Jurafsky. 2018. Automatic detec-
tion of incoherent speech for diagnosing schizophrenia.
Fifth Workshop on Computational Linguistics and Clini-
cal Psychology .

## Page 24

24 Chapter 24 • Discourse Coherence
Ji, Y . and J. Eisenstein. 2014. Representation learning for
text-level discourse parsing. ACL.
Ji, Y . and J. Eisenstein. 2015. One vector is not enough:
Entity-augmented distributed semantics for discourse re-
lations. TACL , 3:329–344.
Joshi, A. K. and S. Kuhn. 1979. Centered logic: The role
of entity centered sentence representation in natural lan-
guage inferencing. IJCAI-79 .
Joshi, A. K. and S. Weinstein. 1981. Control of inference:
Role of some aspects of discourse structure – centering.
IJCAI-81 .
Joty, S., G. Carenini, and R. T. Ng. 2015. CODRA: A novel
discriminative framework for rhetorical analysis. Compu-
tational Linguistics , 41(3):385–435.
Karamanis, N., M. Poesio, C. Mellish, and J. Oberlander.
2004. Evaluating centering-based metrics of coherence
for text structuring using a reliably annotated corpus.
ACL.
Kehler, A. 1993. The effect of establishing coherence in el-
lipsis and anaphora resolution. ACL.
Kehler, A. 1994. Temporal relations: Reference or discourse
coherence? ACL.
Kehler, A. 2000. Coherence, Reference, and the Theory of
Grammar . CSLI Publications.
Kintsch, W. and T. A. Van Dijk. 1978. Toward a model of
text comprehension and production. Psychological re-
view, 85(5):363–394.
Knott, A. and R. Dale. 1994. Using linguistic phenomena
to motivate a set of coherence relations. Discourse Pro-
cesses , 18(1):35–62.
Lai, A. and J. Tetreault. 2018. Discourse coherence in the
wild: A dataset, evaluation and methods. SIGDIAL .
Lakoff, G. 1972. Structural complexity in fairy tales. In The
Study of Man , 128–50. School of Social Sciences, Uni-
versity of California, Irvine, CA.
Lapata, M. 2003. Probabilistic text structuring: Experiments
with sentence ordering. ACL.
Lascarides, A. and N. Asher. 1993. Temporal interpretation,
discourse relations, and common sense entailment. Lin-
guistics and Philosophy , 16(5):437–493.
Li, J. and D. Jurafsky. 2017. Neural net models of open-
domain discourse coherence. EMNLP .
Li, J., R. Li, and E. H. Hovy. 2014. Recursive deep models
for discourse parsing. EMNLP .
Li, Q., T. Li, and B. Chang. 2016. Discourse parsing with
attention-based hierarchical neural networks. EMNLP .
Lin, Z., M.-Y . Kan, and H. T. Ng. 2009. Recognizing im-
plicit discourse relations in the Penn Discourse Treebank.
EMNLP .
Lin, Z., H. T. Ng, and M.-Y . Kan. 2011. Automatically eval-
uating text coherence using discourse relations. ACL.
Lin, Z., H. T. Ng, and M.-Y . Kan. 2014. A pdtb-styled end-
to-end discourse parser. Natural Language Engineering ,
20(2):151–184.
Logeswaran, L., H. Lee, and D. Radev. 2018. Sentence
ordering and coherence modeling using recurrent neural
networks. AAAI .Louis, A. and A. Nenkova. 2012. A coherence model based
on syntactic patterns. EMNLP .
Lukasik, M., B. Dadachev, K. Papineni, and G. Sim ˜oes.
2020. Text segmentation by cross segment attention.
EMNLP .
Mann, W. C. and S. A. Thompson. 1987. Rhetorical structure
theory: A theory of text organization. Technical Report
RS-87-190, Information Sciences Institute.
Marcu, D. 1997. The rhetorical parsing of natural language
texts. ACL.
Marcu, D. 1999. A decision-based approach to rhetorical
parsing. ACL.
Marcu, D. 2000a. The rhetorical parsing of unrestricted
texts: A surface-based approach. Computational Linguis-
tics, 26(3):395–448.
Marcu, D., ed. 2000b. The Theory and Practice of Discourse
Parsing and Summarization . MIT Press.
Marcu, D. and A. Echihabi. 2002. An unsupervised approach
to recognizing discourse relations. ACL.
Mesgar, M. and M. Strube. 2016. Lexical coherence graph
modeling using word embeddings. ACL.
Miltsakaki, E., R. Prasad, A. K. Joshi, and B. L. Webber.
2004. The Penn Discourse Treebank. LREC .
Morey, M., P. Muller, and N. Asher. 2017. How much
progress have we made on RST discourse parsing? a
replication study of recent results on the rst-dt. EMNLP .
Morris, J. and G. Hirst. 1991. Lexical cohesion computed by
thesaural relations as an indicator of the structure of text.
Computational Linguistics , 17(1):21–48.
Muller, P., C. Braud, and M. Morey. 2019. ToNy: Contextual
embeddings for accurate multilingual discourse segmen-
tation of full documents. Workshop on Discourse Relation
Parsing and Treebanking .
Musi, E., M. Stede, L. Kriese, S. Muresan, and A. Rocci.
2018. A multi-layer annotated corpus of argumenta-
tive text: From argument schemes to discourse relations.
LREC .
Myers, G. 1992. “In this paper we report...”: Speech acts and
scientiﬁc facts. Journal of Pragmatics , 17(4):295–313.
Nguyen, D. T. and S. Joty. 2017. A neural local coherence
model. ACL.
Nie, A., E. Bennett, and N. Goodman. 2019. DisSent: Learn-
ing sentence representations from explicit discourse rela-
tions. ACL.
Park, J. and C. Cardie. 2014. Identifying appropriate support
for propositions in online user comments. First workshop
on argumentation mining .
Peldszus, A. and M. Stede. 2013. From argument diagrams
to argumentation mining in texts: A survey. International
Journal of Cognitive Informatics and Natural Intelligence
(IJCINI) , 7(1):1–31.
Peldszus, A. and M. Stede. 2016. An annotated corpus of
argumentative microtexts. 1st European Conference on
Argumentation .
Pitler, E., A. Louis, and A. Nenkova. 2009. Automatic sense
prediction for implicit discourse relations in text. ACL
IJCNLP .
Pitler, E. and A. Nenkova. 2009. Using syntax to disam-
biguate explicit discourse connectives in text. ACL IJC-
NLP.

## Page 25

Exercises 25
Poesio, M., R. Stevenson, B. Di Eugenio, and J. Hitzeman.
2004. Centering: A parametric theory and its instantia-
tions. Computational Linguistics , 30(3):309–363.
Polanyi, L. 1988. A formal model of the structure of dis-
course. Journal of Pragmatics , 12.
Polanyi, L., C. Culy, M. van den Berg, G. L. Thione, and
D. Ahn. 2004. A rule based approach to discourse pars-
ing. Proceedings of SIGDIAL .
Prasad, R., N. Dinesh, A. Lee, E. Miltsakaki, L. Robaldo,
A. K. Joshi, and B. L. Webber. 2008. The Penn Discourse
TreeBank 2.0. LREC .
Prasad, R., B. L. Webber, and A. Joshi. 2014. Reﬂections on
the Penn Discourse Treebank, comparable corpora, and
complementary annotation. Computational Linguistics ,
40(4):921–950.
Propp, V . 1968. Morphology of the Folktale , 2nd edition.
University of Texas Press. Original Russian 1928. Trans-
lated by Laurence Scott.
Qin, L., Z. Zhang, and H. Zhao. 2016. A stacking gated
neural architecture for implicit discourse relation classiﬁ-
cation. EMNLP .
Qin, L., Z. Zhang, H. Zhao, Z. Hu, and E. Xing. 2017. Ad-
versarial connective-exploiting networks for implicit dis-
course relation classiﬁcation. ACL.
Reed, C., R. Mochales Palau, G. Rowe, and M.-F. Moens.
2008. Language resources for studying argument. LREC .
Rosenthal, S. and K. McKeown. 2017. Detecting inﬂuencers
in multiple online genres. ACM Transactions on Internet
Technology (TOIT) , 17(2).
Rutherford, A. and N. Xue. 2015. Improving the inference
of implicit discourse relations via classifying explicit dis-
course connectives. NAACL HLT .
Sagae, K. 2009. Analysis of discourse structure with syn-
tactic dependencies and data-driven shift-reduce parsing.
IWPT-09 .
Scha, R. and L. Polanyi. 1988. An augmented context free
grammar for discourse. COLING .
Sidner, C. L. 1979. Towards a computational theory of deﬁ-
nite anaphora comprehension in English discourse. Tech-
nical Report 537, MIT Artiﬁcial Intelligence Laboratory,
Cambridge, MA.
Sidner, C. L. 1983. Focusing in the comprehension of deﬁ-
nite anaphora. In M. Brady and R. C. Berwick, eds, Com-
putational Models of Discourse , 267–330. MIT Press.
Somasundaran, S., J. Burstein, and M. Chodorow. 2014.
Lexical chaining for measuring discourse coherence qual-
ity in test-taker essays. COLING .
Soricut, R. and D. Marcu. 2003. Sentence level discourse
parsing using syntactic and lexical information. HLT-
NAACL .
Soricut, R. and D. Marcu. 2006. Discourse generation using
utility-trained coherence models. COLING/ACL .
Sporleder, C. and A. Lascarides. 2005. Exploiting linguistic
cues to classify rhetorical relations. RANLP-05 .
Sporleder, C. and M. Lapata. 2005. Discourse chunking and
its application to sentence compression. EMNLP .
Stab, C. and I. Gurevych. 2014a. Annotating argument com-
ponents and relations in persuasive essays. COLING .Stab, C. and I. Gurevych. 2014b. Identifying argumentative
discourse structures in persuasive essays. EMNLP .
Stab, C. and I. Gurevych. 2017. Parsing argumentation struc-
tures in persuasive essays. Computational Linguistics ,
43(3):619–659.
Stede, M. 2011. Discourse processing . Morgan & Claypool.
Stede, M. and J. Schneider. 2018. Argumentation Mining .
Morgan & Claypool.
Subba, R. and B. Di Eugenio. 2009. An effective discourse
parser that uses rich linguistic information. NAACL HLT .
Surdeanu, M., T. Hicks, and M. A. Valenzuela-Escarcega.
2015. Two practical rhetorical structure theory parsers.
NAACL HLT .
Tan, C., V . Niculae, C. Danescu-Niculescu-Mizil, and
L. Lee. 2016. Winning arguments: Interaction dynam-
ics and persuasion strategies in good-faith online discus-
sions. WWW-16 .
Teufel, S., J. Carletta, and M. Moens. 1999. An annotation
scheme for discourse-level argumentation in research ar-
ticles. EACL .
Teufel, S., A. Siddharthan, and C. Batchelor. 2009. To-
wards domain-independent argumentative zoning: Ev-
idence from chemistry and computational linguistics.
EMNLP .
Walker, M. A., A. K. Joshi, and E. Prince, eds. 1998. Cen-
tering in Discourse . Oxford University Press.
Wang, Y ., S. Li, and J. Yang. 2018. Toward fast and accurate
neural discourse segmentation. EMNLP .
Webber, B. L., M. Egg, and V . Kordoni. 2012. Discourse
structure and language technology. Natural Language
Engineering , 18(4):437–490.
Wolf, F. and E. Gibson. 2005. Representing discourse coher-
ence: A corpus-based analysis. Computational Linguis-
tics, 31(2):249–287.
Xu, P., H. Saghir, J. S. Kang, T. Long, A. J. Bose, Y . Cao,
and J. C. K. Cheung. 2019. A cross-domain transferable
neural coherence model. ACL.
Xue, N., H. T. Ng, S. Pradhan, A. Rutherford, B. L. Web-
ber, C. Wang, and H. Wang. 2016. CoNLL 2016 shared
task on multilingual shallow discourse parsing. CoNLL-
16 shared task .
Yang, D., J. Chen, Z. Yang, D. Jurafsky, and E. H. Hovy.
2019. Let’s make your request more persuasive: Model-
ing persuasive strategies via semi-supervised neural nets
on crowdfunding platforms. NAACL HLT .
Yu, N., M. Zhang, and G. Fu. 2018. Transition-based neural
RST parsing with implicit syntax features. COLING .
Yu, Y ., Y . Zhu, Y . Liu, Y . Liu, S. Peng, M. Gong, and
A. Zeldes. 2019. GumDrop at the DISRPT2019 shared
task: A model stacking approach to discourse unit seg-
mentation and connective detection. Workshop on Dis-
course Relation Parsing and Treebanking 2019 .
Zhou, Y . and N. Xue. 2015. The Chinese Discourse Tree-
Bank: a Chinese corpus annotated with discourse rela-
tions. Language Resources and Evaluation , 49(2):397–
431.

